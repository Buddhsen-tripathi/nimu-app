================
CODE SNIPPETS
================
### Install Miniflare using npm

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Installs Miniflare as a development dependency in your Node.js project using npm.

```bash
npm install --save-dev miniflare
```

--------------------------------

### Create TanStack Start Project

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/tanstack

Command to clone the TanStack Start basic project, navigate into it, and install dependencies. You can replace 'start-basic' with other examples provided by TanStack.

```bash
npx degit --force tanstack/start/examples/start-basic my-tanstack-app
cd my-tanstack-app
npm install
# or
yarn
# or
pnpm install
```

--------------------------------

### Install Dependencies with pnpm

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

Installs project dependencies using pnpm. pnpm is known for its efficiency and disk space saving.

```bash
pnpm install
```

--------------------------------

### Install Dependencies with npm

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

Installs project dependencies using npm. This is a common first step in setting up a Node.js project.

```bash
npm install
```

--------------------------------

### Basic package.json Example

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

A minimal `package.json` file for a Node.js project, including scripts for development and building.

```json
{
  "name": "my-worker",
  "version": "1.0.0",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview",
    "deploy": "wrangler deploy"
  },
  "dependencies": {
    "@cloudflare/workers-types": "^4.20240117.0",
    "vite": "^5.0.0",
    "vite-plugin-cloudflare": "^0.0.1"
  }
}
```

--------------------------------

### Install KV Asset Handler

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-existing

Installs the necessary `@cloudflare/kv-asset-handler` package, which is required for serving static assets from Cloudflare KV storage within your Worker.

```bash
npm install @cloudflare/kv-asset-handler
# or
yarn add @cloudflare/kv-asset-handler
```

--------------------------------

### Install Dependencies

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-scratch

Installs all project dependencies defined in `package.json`. This step is crucial after cloning the repository to ensure all required packages are available.

```bash
npm install
```

--------------------------------

### Install Dependencies with Yarn

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

Installs project dependencies using Yarn. Yarn is an alternative package manager for Node.js projects.

```bash
yarn install
```

--------------------------------

### Start Miniflare with HTTPS Server (Custom Certificate)

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Starts Miniflare using an HTTPS server with a custom certificate and key loaded from the file system.

```javascript
const mf = new Miniflare({
  scriptPath: 'worker.js',
  httpsKeyPath: './key.pem',
  httpsCertPath: './cert.pem'
});
```

--------------------------------

### Start Miniflare with HTTPS Server (Certificate from Strings)

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Starts Miniflare using an HTTPS server with a custom certificate and key provided as strings.

```javascript
const mf = new Miniflare({
  scriptPath: 'worker.js',
  httpsKey: '-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----',
  httpsCert: '-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----'
});
```

--------------------------------

### Create Static Site Worker Project with C3 CLI

Source: https://developers.cloudflare.com/workers/static-assets/get-started

This snippet demonstrates how to create a new Cloudflare Worker project for a static site using the C3 CLI. It outlines the command to run and the configuration options to select for a TypeScript-based 'Hello World' example.

```bash
npm create cloudflare@latest
# or
yarn create cloudflare
# or
pnpm create cloudflare
```

--------------------------------

### Build Application Command

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

Builds the Cloudflare Worker application for production deployment using Vite.

```bash
npm run build
```

--------------------------------

### Preview or Deploy Worker Site

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-existing

Commands to preview your Cloudflare Worker site locally or deploy it to Cloudflare. Wrangler handles the bundling and uploading of your static assets.

```bash
wrangler dev
# or
npx wrangler deploy
```

--------------------------------

### Cloudflare Worker Entry File Example

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

A simple JavaScript file for a Cloudflare Worker that returns a greeting message.

```javascript
export default {
  async fetch(request) {
    return new Response('Running in Cloudflare-Workers!');
  },
};
```

--------------------------------

### Start Miniflare with HTTPS Server (Default Certificate)

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Starts Miniflare using an HTTPS server with the default shared self-signed certificate.

```javascript
const mf = new Miniflare({
  scriptPath: 'worker.js',
  https: true
});
```

--------------------------------

### Preview Application Command

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

Previews the built Cloudflare Worker application locally using Vite's preview server.

```bash
npm run preview
```

--------------------------------

### Start Local Development Server for Gatsby

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/gatsby

Run this command within your Gatsby project directory to start a local development server. This allows you to preview your application in real-time as you make changes.

```bash
npm run dev
```

```bash
yarn dev
```

```bash
pnpm dev
```

--------------------------------

### Start Local Development Server for Nuxt

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/nuxt

Run this command within your Nuxt project directory to start a local development server. This allows you to preview your application in real-time during the development process.

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
```

--------------------------------

### Start Local Development Server for SolidJS

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/solid

Run this command within your project directory to start a local development server. This allows you to preview your SolidJS application during the development process.

```bash
npm run dev
```

```bash
yarn dev
```

```bash
pnpm dev
```

--------------------------------

### Development Server Command

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

Starts the Vite development server for local testing and development of the Cloudflare Worker.

```bash
npm run dev
```

--------------------------------

### Cloudflare Worker Configuration Example (JSONC)

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

Defines the name and entry point for a Cloudflare Worker. The 'name' field is also used for the Vite Environment.

```json
{
  "name": "my-worker",
  "main": "./src/index.js",
  "compatibility_date": "2024-01-17"
}
```

--------------------------------

### Create a new Cloudflare Worker project using C3

Source: https://developers.cloudflare.com/workers/tutorials/using-prisma-postgres-with-workers

This command initializes a new Cloudflare Worker project. Ensure you have C3 installed globally. It creates a basic project structure to get started.

```bash
npx c3 --template "Basic Cloudflare Worker"
```

--------------------------------

### Wait for Miniflare HTTP Server Ready

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Waits for the Miniflare HTTP server to be ready before proceeding.

```javascript
await mf.ready;
```

--------------------------------

### Cloudflare Worker Configuration Example (TOML)

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

Defines the name and entry point for a Cloudflare Worker using TOML format. The 'name' field is also used for the Vite Environment.

```toml
[build]

[build.upload]

[env.dev]
name = "my-worker"
main = "./src/index.js"
compatibility_date = "2024-01-17"
```

--------------------------------

### Create Full-Stack Application Worker Project with C3 CLI

Source: https://developers.cloudflare.com/workers/static-assets/get-started

This snippet demonstrates how to create a new Cloudflare Worker project for a full-stack application using the C3 CLI. It details the command and selection prompts for a TypeScript-based 'Hello World' SSR example.

```bash
npm create cloudflare@latest
# or
yarn create cloudflare
# or
pnpm create cloudflare
```

--------------------------------

### Initialize a new Worker project

Source: https://developers.cloudflare.com/workers/tutorials/generate-youtube-thumbnails-with-workers-and-images

This section outlines the steps to create a new Cloudflare Worker project using npm, yarn, or pnpm. It guides the user through setup options, including selecting a 'Hello World example' template and 'Worker only' configuration, choosing JavaScript as the language, and setting up Git version control.

```bash
npm create cloudflare@latest
# or
yarn create cloudflare@latest
# or
pnpm create cloudflare@latest
```

--------------------------------

### Wrangler Configuration Example

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/tanstack

Example configuration for wrangler.jsonc, specifying the output directory, main entry point, and KV namespace bindings for Cloudflare Workers deployment.

```json
{
  "$schema": "https://json.schemastore.org/wrangler",
  "compatibilityDate": "2023-05-03",
  "main": ".output/server/index.mjs",
  "directory": ".output/public",
  "kv_namespaces": [
    {
      "binding": "CACHE",
      "id": "your-kv-namespace-id"
    }
  ]
}
```

--------------------------------

### Deploy to Cloudflare Command

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

Deploys the Cloudflare Worker application to the Cloudflare network using Wrangler.

```bash
npm run deploy
```

--------------------------------

### Create Waku Project with Cloudflare Workers Assets

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/waku

Command to initiate a new Waku project using the create-cloudflare CLI, setting it up for Cloudflare Workers Assets. This command guides the user through project setup options including framework selection and git integration.

```bash
npm create cloudflare@latest
```

```bash
yarn create cloudflare
```

```bash
pnpm create cloudflare
```

--------------------------------

### Basic Cloudflare Worker 'Hello World' Example

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/using-bigquery-with-workers-ai

This is a standard 'Hello World' example for a Cloudflare Worker. It demonstrates the basic structure of a Worker script that responds with a simple text message. This serves as a starting point before integrating external data sources.

```javascript
export default {
	async fetch(request, env, ctx) {
		return new Response("Hello World!");
	},
};
```

--------------------------------

### Initialize Wrangler Project

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-existing

Initializes a new Cloudflare Worker project using the Wrangler CLI. This command generates essential project files like `wrangler.jsonc`, `package.json`, `tsconfig.json`, and a basic `src/index.ts`.

```bash
wrangler init
```

--------------------------------

### Preview Site Locally

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-scratch

Starts a local development server to preview your Workers Sites project. This command allows you to see your site in action before deploying it to Cloudflare.

```bash
wrangler dev
```

--------------------------------

### Install ai-utils Package with npm, yarn, or pnpm

Source: https://developers.cloudflare.com/workers/-ai/features/function-calling/embedded/get-started

This section provides the commands to install the Worker AI utilities package, ai-utils, using popular package managers like npm, yarn, and pnpm. This package is essential for leveraging Workers AI features, including embedded function calling.

```npm
npm install @cloudflare/ai-utils
```

```yarn
yarn add @cloudflare/ai-utils
```

```pnpm
pnpm add @cloudflare/ai-utils
```

--------------------------------

### Create SolidJS Project with Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/solid

Use the create-cloudflare CLI (C3) to scaffold a new SolidJS project configured for Cloudflare Workers. This command initiates the project setup and offers an option for instant deployment.

```bash
npm create cloudflare@latest -- --template solid
```

```bash
yarn create cloudflare --template solid
```

```bash
pnpm create cloudflare --template solid
```

--------------------------------

### Develop Static Site Worker Locally

Source: https://developers.cloudflare.com/workers/static-assets/get-started

This snippet shows the command to start a local development server for a Cloudflare Worker project. Running `wrangler dev` allows you to preview your static site locally during the development process.

```bash
wrangler dev
```

--------------------------------

### Dispatch Fetch Event

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Dispatches a fetch event to a Miniflare worker.

```javascript
const res = await mf.getWorker().fetch('https://example.com');
```

--------------------------------

### Create a Worker Project with npm

Source: https://developers.cloudflare.com/workers/-ai/get-started/workers-wrangler

Initializes a new Cloudflare Worker project named 'hello-ai' using the create-cloudflare CLI (C3) with the 'Hello World example' template and TypeScript. This command also installs Wrangler, the Cloudflare Developer Platform CLI.

```bash
npm create cloudflare@latest
```

--------------------------------

### Vite Configuration with Cloudflare Plugin

Source: https://developers.cloudflare.com/workers/vite-plugin/get-started

Configures Vite to use the Cloudflare plugin. This setup automatically detects `wrangler.jsonc`, `wrangler.json`, or `wrangler.toml`.

```javascript
import { defineConfig } from 'vite';

export default defineConfig({
  plugins: [
    // Cloudflare Vite plugin doesn't require configuration by default
  ],
});
```

--------------------------------

### Initialize Miniflare with a String Script

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Initializes a Miniflare instance with a worker script provided as a string. Assumes Node.js is running in ES module mode.

```javascript
import Miniflare from 'miniflare';

const mf = new Miniflare({
  script: `export default {
    async fetch(request, env, ctx) {
      return new Response('Hello Worker!');
    }
  }`
});
```

--------------------------------

### Preview and Test Worker Locally with Wrangler

Source: https://developers.cloudflare.com/workers/get-started/dashboard

This command allows you to preview and test your Cloudflare Worker application in your local development environment using the Wrangler CLI. Ensure you have Wrangler installed and configured for your project.

```bash
wrangler dev
```

--------------------------------

### Monorepo Deployment with Turborepo

Source: https://developers.cloudflare.com/workers/ci-cd/builds/advanced-setups

This example demonstrates how to configure a monorepo deployment using Turborepo, specifying unique deploy commands for different services within the repository. It assumes a project structure where services like 'product-service' have their own configurations.

```bash
turbo deploy -F product-service
```

--------------------------------

### Initialize Miniflare with a File Path Script

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Initializes a Miniflare instance using a worker script located in a file (e.g., worker.js).

```javascript
import Miniflare from 'miniflare';

const mf = new Miniflare({
  scriptPath: 'worker.js'
});
```

--------------------------------

### Clone Worker Sites Template

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-scratch

Clones the `worker-sites-template` starter repository to create a new project. This command initializes your project with the necessary structure for Workers Sites.

```bash
git clone https://github.com/cloudflare/worker-sites-template.git my-site
```

--------------------------------

### Deploy Site to Cloudflare

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-scratch

Deploys your Workers Sites project to Cloudflare. This command handles the build process and uploads your site to the Cloudflare network.

```bash
wrangler publish
```

--------------------------------

### Example GitHub Actions Workflow for Worker Deployment

Source: https://developers.cloudflare.com/workers/ci-cd/external-cicd/gitlab-cicd

This example demonstrates a GitHub Actions workflow for deploying a Cloudflare Worker. It includes steps for checking out the code, setting up Node.js, installing dependencies, and deploying the worker using Wrangler.

```yaml
name: Deploy Worker

on:
  push:
    branches: [ main ]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: 18
      - name: Install dependencies
        run: npm install
      - name: Deploy Worker
        uses: cloudflare/wrangler-action@v1
        with:
          apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          accountId: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        env:
          NODE_ENV: production
```

--------------------------------

### Provide Custom cf Object via Filepath

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Provides a custom cf object to Miniflare using a specified file path.

```javascript
const mf = new Miniflare({
  scriptPath: 'worker.js',
  cfPath: './cf.json'
});
```

--------------------------------

### Hello Cloudflare Workers Example

Source: https://developers.cloudflare.com/workers/playground

This is a default multi-module Worker example that demonstrates receiving a request, logging a message to the console, and returning a response body from 'welcome.html'. It utilizes the Fetch handler.

```javascript
/**
 * Welcome to Cloudflare Workers!
 *
 * This is a template for a Scheduled Worker. In this template, you will find
 * - "scheduled" which will be called once when the worker is first deployed.
 *
 * How to run this worker:
 *
 * 1. Create a Cloudflare account: https://dash.cloudflare.com/sign-up
 * 2. Create a new Worker project: https://dash.cloudflare.com/workers/new
 *
 * Then copy and paste this code into the `index.js` file of your new worker.
 *
 * Learn more at: https://developers.cloudflare.com/workers/examples/hello-world/
 */

addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

/**
 * Respond to the request
 * @param {Request} request */
async function handleRequest(request) {
  return new Response('Hello worker!', {
    headers: {
      'content-type': 'text/plain',
    },
  })
}
```

```html
<!-- welcome.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Welcome</title>
</head>
<body>
    <h1>Welcome to your Worker!</h1>
    <p>This content is served from welcome.html.</p>
</body>
</html>
```

--------------------------------

### Start Local Development Server for Qwik

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/qwik

To preview your Qwik project locally during the development phase, run this command within your project directory. This starts a local server that reflects your changes in real-time.

```bash
npm run dev
```

```bash
yarn dev
```

```bash
pnpm dev
```

--------------------------------

### Start Local Development Server for Waku Project

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/waku

Command to run a local development server for a Waku project. This allows for previewing and testing the application locally during the development phase before deployment.

```bash
npm run dev
```

```bash
yarn dev
```

```bash
pnpm dev
```

--------------------------------

### Develop Full-Stack Application Worker Locally

Source: https://developers.cloudflare.com/workers/static-assets/get-started

This snippet shows the command to start a local development server for a full-stack Cloudflare Worker application. `wrangler dev` enables local previewing and development of SSR applications.

```bash
wrangler dev
```

--------------------------------

### Deploy Static Site Worker Project

Source: https://developers.cloudflare.com/workers/static-assets/get-started

This snippet provides the command to build and deploy your Cloudflare Worker project. It's used for deploying static sites to a *.workers.dev subdomain or a Custom Domain.

```bash
wrangler deploy
```

--------------------------------

### Install node-postgres Types for TypeScript

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/xata

If you are using TypeScript, you need to install the types package for `node-postgres` to get type definitions. These commands show how to install the types using npm, yarn, or pnpm.

```bash
npm install --save-dev @types/pg
```

```bash
yarn add --dev @types/pg
```

```bash
pnpm add --save-dev @types/pg
```

--------------------------------

### Dispose Miniflare Instance

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Cleans up and stops a Miniflare instance from listening for requests.

```javascript
await mf.dispose();
```

--------------------------------

### Configure Route for Custom Domain

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-existing

Adds a `route` property to the Wrangler configuration file to associate your Worker with a custom domain managed by Cloudflare.

```json
{
  "site": {
    "bucket": "public",
    "entry-point": "worker.js"
  },
  "routes": [
    {
      "pattern": "your-domain.com/*",
      "zone_id": "YOUR_ZONE_ID"
    }
  ]
}
```

--------------------------------

### Dispatch Scheduled Event

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Dispatches a scheduled event to a Miniflare worker.

```javascript
await mf.getWorker().scheduled('my-cron', 'my-cron-handler');
```

--------------------------------

### Example Build and Deploy Commands for Cloudflare Workers

Source: https://developers.cloudflare.com/workers/ci-cd/builds/configuration

These examples demonstrate how to configure build and deploy commands for Cloudflare Workers. The build command is used for projects requiring a build step, while the deploy command handles the deployment process. Examples include deploying static assets and using environment-specific deployments.

```bash
npx wrangler deploy --assets ./public/
npx wrangler deploy --env staging
```

```bash
yarn exec wrangler versions upload
npx wrangler versions upload --env staging
```

--------------------------------

### Enable Miniflare Logging

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Enables Miniflare logs by setting the 'log' property to an instance of the Log class with a specified log level.

```javascript
import Miniflare, { Log } from 'miniflare';

const mf = new Miniflare({
  scriptPath: 'worker.js',
  log: new Log(Log.Levels.INFO)
});
```

--------------------------------

### Update Miniflare Options

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Updates the options of an existing Miniflare instance and reloads the worker with the new configuration.

```javascript
await mf.setOptions({
  scriptPath: 'worker.js',
  // ... other options
});
```

--------------------------------

### Configure Wrangler for Static Assets (TOML)

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-existing

Specifies the build or output directory of your static site generator within the Wrangler configuration file using TOML format. This tells Wrangler where to find the assets to upload.

```toml
[site]
bucket = "public"
```

--------------------------------

### Navigate to Project Directory

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/solid

After creating the SolidJS project, change into the newly created project directory to begin development.

```bash
cd <your-project-name>
```

--------------------------------

### Dispatch Queues Event

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Dispatches a queues event to a Miniflare worker.

```javascript
await mf.getWorker().queues.queue('my-queue').send({ body: 'Hello!' });
```

--------------------------------

### Configure Wrangler for Static Assets

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-existing

Specifies the build or output directory of your static site generator within the Wrangler configuration file. This tells Wrangler where to find the assets to upload.

```json
{
  "site": {
    "bucket": "public"
  }
}
```

--------------------------------

### Cloudflare Workers AI Prompt Example

Source: https://developers.cloudflare.com/workers/get-started/prompting

This prompt is designed to guide AI models in generating Cloudflare Workers applications. It includes structured XML tags, API usage examples, and instructions for generating configuration files like `wrangler.jsonc`. It also suggests Cloudflare products for state management.

```plaintext
<xml>
<context>
  <product>Cloudflare Workers</product>
  <use_case>Boilerplate code generation, iteration, and debugging</use_case>
  <guidelines>
    <structure>Use XML tags for prompt structuring.</structure>
    <examples>Include API and usage examples for products and use-cases.</examples>
    <configuration>Generate configuration (e.g., `wrangler.jsonc`) as part of the response.</configuration>
    <recommendations>Recommend Cloudflare products for specific storage or state needs.</recommendations>
  </guidelines>
</context>
<user_prompt>
  <!-- Insert your specific prompt here -->
</user_prompt>
</xml>
```

--------------------------------

### Cloudflare Worker for Static Sites (TypeScript)

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-existing

A basic Cloudflare Worker script written in TypeScript that utilizes the `@cloudflare/kv-asset-handler` to serve static assets. It requires configuration for the asset directory and KV namespace.

```typescript
import {
	withDefaults,
	createHeaders,
} from '@cloudflare/kv-asset-handler';

export default {
	async fetch(request: Request, env: Env, ctx: ExecutionContext) {
		const url = new URL(request.url);
		const assetKey = url.pathname.substring(1);

		// If the request is for the root, serve index.html
		if (assetKey === '') {
			return fetch(new Request(new URL('index.html', request.url)));
		}

		const asset = await env.ASSETS.get(assetKey);

		if (asset) {
			const headers = {
				'Content-Type': asset.type,
			};
			return new Response(asset.body, {
				headers,
			});
		}

		return new Response('Not Found', {
			status: 404,
		});
	},
};

interface Env {
	ASSETS: Fetcher;
}
```

--------------------------------

### Configure Route for Custom Domain (TOML)

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-existing

Adds a `route` property to the Wrangler configuration file using TOML format to associate your Worker with a custom domain managed by Cloudflare.

```toml
[site]
bucket = "public"
entry-point = "worker.js"

[[routes]]
pattern = "your-domain.com/*"
zone_id = "YOUR_ZONE_ID"
```

--------------------------------

### Cloudflare Worker API Endpoint Example

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/react

Defines a basic backend API endpoint within a Cloudflare Worker. This example demonstrates a single endpoint, `/api/`, which returns a text response that can be fetched by the React frontend.

```typescript
export interface Env {
  // Example binding definition
  // MY_VARIABLE: string;
}

export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
    const url = new URL(request.url);
    if (url.pathname.startsWith('/api/')) {
      return new Response('Hello from the Worker API!');
    }
    return new Response('Hello World!');
  },
};

```

--------------------------------

### Install OpenAI SDK

Source: https://developers.cloudflare.com/workers/examples/openai-sdk-streaming

To run the code, you need to install the OpenAI SDK. This command installs the necessary package using npm.

```bash
npm i openai
```

--------------------------------

### Starting a Local Development Server with Wrangler

Source: https://developers.cloudflare.com/workers/testing/miniflare/migrations/from-v2

To start a local development server with Miniflare v3, you should use Wrangler v3. This command initiates the development environment, leveraging Miniflare v3 by default.

```bash
wrangler dev
```

--------------------------------

### Python - Streaming Text Generation with Falcon-7B-Instruct

Source: https://developers.cloudflare.com/workers/-ai/models/falcon-7b-instruct

Example of how to perform streaming text generation using the Falcon-7B-Instruct model with Python. This code assumes you have the Cloudflare AI SDK installed and configured.

```python
from cloudflare.ai import Client

client = Client()

prompt = "Write a short story about a robot learning to love."

response = client.run(
    "@cf/tiiuae/falcon-7b-instruct",
    { "prompt": prompt, "stream": True },
    stream=True
)

for chunk in response:
    print(chunk, end="")

```

--------------------------------

### Create Gatsby Project with Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/gatsby

This command uses the create-cloudflare CLI (C3) to set up a new Gatsby project and configure it for deployment with Cloudflare Workers Assets. It initiates Gatsby's setup and offers instant deployment options.

```bash
npm create cloudflare@latest -- --template "gatsby-cloudflare"
```

```bash
yarn create cloudflare --template "gatsby-cloudflare"
```

```bash
pnpm create cloudflare --template "gatsby-cloudflare"
```

--------------------------------

### Create Cloudflare Worker Project with c3 CLI

Source: https://developers.cloudflare.com/workers/tutorials/create-finetuned-chatgpt-ai-models-with-r2

This snippet shows how to initialize a new Cloudflare Workers project using the c3 CLI. It guides through setup options including project type, language (TypeScript), and version control.

```bash
c3 --template "Worker only" --language "TypeScript"
```

--------------------------------

### Deploy Full-Stack Application Worker Project

Source: https://developers.cloudflare.com/workers/static-assets/get-started

This snippet provides the command to build and deploy your full-stack Cloudflare Worker project. It's used for deploying SSR applications to a *.workers.dev subdomain or a Custom Domain.

```bash
wrangler deploy
```

--------------------------------

### Python Usage Example for Qwen2.5-Coder-32B-Instruct

Source: https://developers.cloudflare.com/workers/-ai/models/qwen2

Provides a Python script to interact with the Qwen2.5-Coder-32B-Instruct model via Cloudflare Workers AI. This example covers setting up the request, sending it to the API, and processing the response, useful for backend integrations.

```python
import requests

api_url = "https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/qwen/qwen2.5-coder-32b-instruct"
headers = {
    "Authorization": f"Bearer YOUR_CLOUDFLARE_API_TOKEN",
    "Content-Type": "application/json"
}

prompt_text = "Write a Python function to calculate the Fibonacci sequence."

payload = {
    "prompt": prompt_text,
    "stream": False # Set to True for streaming
}

response = requests.post(api_url, headers=headers, json=payload)

if response.status_code == 200:
    if payload["stream"]:
        # Handle streaming response
        for chunk in response.iter_content(chunk_size=1024):
            if chunk:
                print(chunk.decode('utf-8'), end='')
    else:
        # Handle non-streaming response
        result = response.json()
        print(result['result']['text'])
else:
    print(f"Error: {response.status_code} - {response.text}")

```

--------------------------------

### Example Wrangler Configuration (TOML)

Source: https://developers.cloudflare.com/workers/vite-plugin/reference/cloudflare-environments

This is an example of a Wrangler configuration file in TOML format, illustrating the definition of different Cloudflare environments and their associated variables, such as MY_VAR.

```toml
[env.production]
MY_VAR = "Production var"

[env.staging]
MY_VAR = "Staging var"
```

--------------------------------

### Install Turso CLI

Source: https://developers.cloudflare.com/workers/tutorials/connect-to-turso-using-workers

Installs the Turso command-line interface (CLI) for creating and managing Turso databases. This is a prerequisite for interacting with Turso.

```bash
# For macOS and Linux
curl -fsSL https://install.turso.io | bash
```

```bash
# For Windows
Invoke-Expression -Command "$(irm https://install.turso.io)"
```

--------------------------------

### Create Qwik Project with Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/qwik

Use the create-cloudflare CLI (C3) to set up a new Qwik project. This command initiates Qwik's setup tool and offers instant deployment options. It's designed for creating Qwik projects specifically with Workers Assets.

```bash
npm create cloudflare@latest my-qwik-app -- --template qwik
```

```bash
yarn create cloudflare my-qwik-app --template qwik
```

```bash
pnpm create cloudflare my-qwik-app --template qwik
```

--------------------------------

### Install Prisma CLI and Accelerate client extension

Source: https://developers.cloudflare.com/workers/tutorials/using-prisma-postgres-with-workers

Installs the Prisma CLI as a development dependency and the Prisma Accelerate client extension, which is necessary for Prisma Postgres. Uses npm, yarn, or pnpm.

```bash
# npm
npm install prisma --save-dev
npm install @prisma/extension-accelerate

# yarn
yarn add prisma --dev
yarn add @prisma/extension-accelerate

# pnpm
pnpm add prisma --save-dev
pnpm add @prisma/extension-accelerate
```

--------------------------------

### Navigate to Project Directory

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/gatsby

After creating the Gatsby project, navigate into the newly created project directory to access its files and run development commands.

```bash
cd <your-project-name>
```

--------------------------------

### Install Hono and OpenAI Libraries for Worker

Source: https://developers.cloudflare.com/workers/tutorials/create-finetuned-chatgpt-ai-models-with-r2

Commands to install the necessary Node.js libraries for building the Cloudflare Worker: Hono for routing and middleware, and the OpenAI Node API library for interacting with OpenAI services.

```bash
npm install hono openai
# or
yarn add hono openai
# or
pnpm add hono openai
```

--------------------------------

### Basic Miniflare Test Setup

Source: https://developers.cloudflare.com/workers/testing/miniflare/writing-tests

Demonstrates the basic setup for testing a JavaScript Worker using Miniflare and the `node:test` framework. It initializes Miniflare with the Worker and uses `dispatchFetch` to send a request.

```javascript
import { Miniflare } from "miniflare";
import { test } from "node:test";
import assert from "node:assert";

test("Basic Worker Test", async () => {
  const mf = new Miniflare({
    script: `export default {
      async fetch(request, env, ctx) {
        return new Response("Hello World!");
      },
    }`,
  });

  const res = await mf.dispatchFetch("http://localhost:8787/");
  const text = await res.text();

  assert.strictEqual(text, "Hello World!");
});
```

--------------------------------

### Configure Wrangler Bucket (TOML)

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-scratch

Specifies the directory containing static assets for your Workers Sites project in the `wrangler.toml` configuration file. The `bucket` property points to the location of your site's static files.

```toml
[site]
bucket = "./public"
```

--------------------------------

### Python Text Generation with Gemma 3

Source: https://developers.cloudflare.com/workers/-ai/models/gemma-3-12b-it

This Python example shows how to interact with the Gemma 3 model for text generation. It assumes you have the necessary Cloudflare client libraries installed and configured for authentication.

```python
from clarip.ai import stream

async def generate_text():
    messages = [
        {"role": "user", "content": "Write a short story about a robot learning to paint."}
    ]

    stream_result = await stream("@cf/google/gemma-3-12b-it", {
        messages=messages,
        stream=True
    })

    async for chunk in stream_result.iter_chunks():
        print(chunk, end="", flush=True)

# To run this, you would typically call generate_text() within an async context.
```

--------------------------------

### Start Astro Local Development Server

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/astro

Starts a local development server for your Astro project after it has been created. This allows you to preview your site before deploying.

```npm
npm run dev
```

```yarn
yarn dev
```

```pnpm
pnpm dev
```

--------------------------------

### Example Wrangler Configuration (JSONC)

Source: https://developers.cloudflare.com/workers/vite-plugin/reference/cloudflare-environments

This is an example of a Wrangler configuration file in JSONC format, demonstrating how different Cloudflare environments can be defined. It shows how to set environment-specific variables like MY_VAR.

```json
{
  "$schema": "https://json.schemastore.org/wrangler",
  "name": "my-worker",
  "main": "src/index.js",
  "compatibility_date": "2023-10-18",
  "env": {
    "production": {
      "vars": {
        "MY_VAR": "Production var"
      }
    },
    "staging": {
      "vars": {
        "MY_VAR": "Staging var"
      }
    }
  }
}
```

--------------------------------

### Python Usage Example for sqlcoder-7b-2

Source: https://developers.cloudflare.com/workers/-ai/models/sqlcoder-7b-2

This Python snippet demonstrates how to interact with the sqlcoder-7b-2 model. It outlines the necessary steps for sending queries and receiving responses, serving as a basic integration example.

```python
from cloudflare.ai import Client

client = Client("your-api-token")

response = client.run(
    "@cf/defog/sqlcoder-7b-2",
    { 
        "prompt": "Translate the following natural language into SQL: 'show me all customers who live in california'"
    }
)

print(response["result"])
```

--------------------------------

### Build TanStack Start Application

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/tanstack

Commands to build your TanStack Start application for deployment. This step is required before deploying to Cloudflare Workers.

```bash
npm run build
# or
yarn build
# or
pnpm build
```

--------------------------------

### Create Cloudflare Worker Project with pnpm

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/build-a-retrieval-augmented-generation-ai

Initializes a new Cloudflare Worker project using pnpm and the C3 CLI. Selects 'Hello World example', 'Worker only' template, JavaScript, and Git version control.

```bash
pnpm create cloudflare my-rge-app
cd my-rge-app
```

--------------------------------

### Start Local Development Server

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/tanstack

Commands to start a local development server for your TanStack Start project. The server typically runs on http://localhost:3000/.

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
```

--------------------------------

### Install @types/node for nodejs_compat

Source: https://developers.cloudflare.com/workers/languages/typescript

If you are using the `nodejs_compat` compatibility flag in your Worker, you need to install the `@types/node` package to get the corresponding Node.js type definitions. This is an optional step but crucial for Node.js compatibility.

```bash
npm install -D @types/node
# or
yarn add -D @types/node
# or
pnpm add -D @types/node
```

--------------------------------

### Install Turso Client and Router Libraries

Source: https://developers.cloudflare.com/workers/tutorials/connect-to-turso-using-workers

Install the `@libsql/client` library for querying the Turso database and the `itty-router` library for handling incoming requests to the Worker. Choose your preferred package manager (npm, yarn, or pnpm).

```bash
npm install @libsql/client itty-router
```

```bash
yarn add @libsql/client itty-router
```

```bash
pnpm add @libsql/client itty-router
```

--------------------------------

### Create Cloudflare Worker Project with npm

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/build-a-retrieval-augmented-generation-ai

Initializes a new Cloudflare Worker project using npm and the C3 CLI. Selects 'Hello World example', 'Worker only' template, JavaScript, and Git version control.

```bash
npm create cloudflare@latest my-rge-app
cd my-rge-app
```

--------------------------------

### Deploy TanStack Start Application

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/tanstack

Commands to deploy your built TanStack Start application to Cloudflare Workers using the defined npm scripts or directly with Wrangler.

```bash
npm run deploy
# or
yarn deploy
# or
pnpm deploy

# Alternatively, deploy directly with Wrangler:
Wrangler deploy
```

--------------------------------

### Render Web Pages with Puppeteer

Source: https://developers.cloudflare.com/workers/prompt

This example shows how to use the BROWSER_RENDERING binding with Puppeteer to navigate to a URL, render the page, and extract its content. It includes setup for the binding and proper browser session management.

```javascript
      console.log(text);

      // Ensure we close the browser session
      await browser.close();

      return Response.json({
        bodyText: text,
      })
    } else {
      return Response.json({
          error: "Please add an ?url=https://example.com/ parameter"
      }, { status: 400 })
    }
  },
}

```

--------------------------------

### Worker - Streaming Text Generation with Falcon-7B-Instruct

Source: https://developers.cloudflare.com/workers/-ai/models/falcon-7b-instruct

Example of how to use the Falcon-7B-Instruct model for streaming text generation within a Cloudflare Worker. This utilizes the Workers AI runtime and requires no external setup.

```javascript
import { Ai } from "@cloudflare/ai";

export default {
  async fetch(request, env, ctx): Promise<Response> {
    const ai = new Ai(env.AI);
    const prompt = "Write a short story about a robot learning to love.";

    const stream = await ai.run(
      "@cf/tiiuae/falcon-7b-instruct",
      {
        prompt: prompt,
        stream: true
      }
    );

    return new Response(stream, {
      headers: {
        "content-type": "text/plain",
      },
    });
  },
};

```

--------------------------------

### Disable Request#cf Object Fetching

Source: https://developers.cloudflare.com/workers/testing/miniflare/get-started

Disables the default behavior of fetching the Request#cf object from a Cloudflare endpoint.

```javascript
const mf = new Miniflare({
  scriptPath: 'worker.js',
  cf: false
});
```

--------------------------------

### Create Worker Project using npm, yarn, or pnpm

Source: https://developers.cloudflare.com/workers/tutorials/github-sms-notifications-using-twilio

Instructions for creating a new Cloudflare Worker project using different package managers. It guides through setup options for a 'Hello World' template, 'Worker only' type, JavaScript language, and local Git setup.

```shell
npm create cloudflare@latest
yarn create cloudflare@latest
pnpm create cloudflare@latest
```

--------------------------------

### Python Integration for Text Generation

Source: https://developers.cloudflare.com/workers/-ai/models/llama-2-13b-chat-awq

This example shows how to interact with the Llama 2 13B Chat AWQ model using Python. It assumes you have the necessary libraries installed (e.g., `requests`) and your API credentials configured. The input is a prompt, and the output is the generated text.

```python
import requests

api_url = "https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@hf/thebloke/llama-2-13b-chat-awq"
api_token = "{API_TOKEN}"

headers = {
    "Authorization": f"Bearer {api_token}",
    "Content-Type": "application/json"
}

def generate_text(prompt):
    data = {
        "prompt": prompt
    }
    response = requests.post(api_url, headers=headers, json=data)
    return response.json()

# Example usage:
# prompt_text = "Write a short story about a robot learning to love."
# result = generate_text(prompt_text)
# print(result)
```

--------------------------------

### Configure Wrangler Bucket

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-scratch

Specifies the directory containing static assets for your Workers Sites project in the `wrangler.jsonc` configuration file. The `bucket` property points to the location of your site's static files.

```json
{
  "site": {
    "bucket": "./public"
  }
}
```

--------------------------------

### Run FastAPI Example in Python Workers

Source: https://developers.cloudflare.com/workers/languages/python/packages/fastapi

This snippet demonstrates how to clone the `cloudflare/python-workers-examples` repository and execute the FastAPI example within a Python Worker environment. It requires cloning the repository to access the example code.

```Shell
git clone https://github.com/cloudflare/python-workers-examples.git
cd python-workers-examples/fastapi
# Instructions to run the example would follow here, e.g., using wranger CLI
```

--------------------------------

### Navigate to Project Directory

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/nuxt

After creating the Nuxt project using the create-cloudflare CLI, change into the newly created project directory to proceed with development and deployment.

```bash
cd <your-project-name>
```

--------------------------------

### Local Development Server with Cloudflare Vite Plugin

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/react

Starts a local development server for the React + Cloudflare Workers project. This utilizes Vite and the Cloudflare Vite plugin to provide features like hot module replacement (HMR) and an environment that closely matches production.

```bash
npm run dev

```

```bash
yarn dev

```

```bash
pnpm dev

```

--------------------------------

### Install Turso CLI

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/turso

Installs the Turso CLI using either npm or a curl command. This tool is necessary for creating and populating Turso databases.

```bash
npm install -g @tursodatabase/turso
```

```bash
curl -fsSL https://install.turso.io | bash
```

--------------------------------

### cURL Usage Example for Qwen2.5-Coder-32B-Instruct

Source: https://developers.cloudflare.com/workers/-ai/models/qwen2

Illustrates how to invoke the Qwen2.5-Coder-32B-Instruct model using cURL. This command-line example is helpful for quick testing and scripting API interactions without writing extensive code.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/qwen/qwen2.5-coder-32b-instruct" \
     -H "Authorization: Bearer YOUR_CLOUDFLARE_API_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{ "prompt": "Explain the concept of recursion in programming.", "stream": false }'
```

--------------------------------

### Start a local development server with Wrangler

Source: https://developers.cloudflare.com/workers/get-started/guide

Run the `wrangler dev` command in your Worker project directory to start a local development server. This allows you to preview and test your Worker locally before deployment.

```bash
wrangler dev
```

--------------------------------

### Install Wrangler with pnpm

Source: https://developers.cloudflare.com/workers/wrangler/install-and-update

Installs the Wrangler CLI locally within your project using pnpm. pnpm offers efficient disk space usage and faster installations.

```bash
pnpm add wrangler --save-dev
```

--------------------------------

### Worker - Streaming Text Generation with Gemma 3

Source: https://developers.cloudflare.com/workers/-ai/models/gemma-3-12b-it

This example demonstrates how to use the Gemma 3 model for streaming text generation within a Cloudflare Worker. It requires no additional setup or authentication, allowing for instant preview and testing in the browser via the LLM Playground.

```javascript
import { stream } from "cloudflare:ai";

export default {
  async fetch(request) {
    const messages = [
      { role: "user", content: "Explain the concept of Cloudflare Workers."
    ];

    const streamResult = await stream("@cf/google/gemma-3-12b-it", {
      messages,
      stream: true
    });

    return new Response(streamResult.toReadableStream(), {
      headers: {
        "content-type": "text/plain"
      }
    });
  }
}
```

--------------------------------

### Create and Populate `example_users` Table

Source: https://developers.cloudflare.com/workers/tutorials/connect-to-turso-using-workers

Defines a schema for an `example_users` table with an `email` column and inserts a sample email address into it. This uses standard SQL syntax.

```sql
CREATE TABLE example_users (
  email text
);
INSERT INTO example_users (email) VALUES
  ('test@example.com');
```

--------------------------------

### Wrangler Configuration Example

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/hono

This is a sample `wrangler.jsonc` file, which is the configuration file for Wrangler, the Cloudflare deployment tool. It specifies the main entry point for the Worker, how to handle not found assets (e.g., for SPAs), and where to configure Cloudflare bindings.

```json
{
  "main": "src/worker/index.ts",
  "name": "my-hono-app",
  "compatibility_date": "2023-10-26",
  "assets": {
    "src/public": "/",
    "file": "index.html",
    "include": [
      "**/*"
    ],
    "exclude": [
      "**/*.js"
    ],
    "browser_check": "never",
    "not_found_handling": "single-page-application"
  },
  "queues_beta": true,
  "queues_producer": {
    "queue": "my-queue",
    "binding": "MY_QUEUE"
  },
  "d1_databases": [
    {
      "binding": "DB",
      "id": "your-database-id"
    }
  ]
}
```

--------------------------------

### curl Usage Example for llama-3.3-70b-instruct-fp8-fast

Source: https://developers.cloudflare.com/workers/-ai/models/llama-3

This example shows how to interact with the llama-3.3-70b-instruct-fp8-fast model using curl from the command line. It highlights the necessary headers and payload structure for sending a prompt.

```bash
curl -X POST \
  "https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/llama_3_3_70b_instruct_fp8_fast/completions" \
  -H "Authorization: Bearer YOUR_API_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Write a short poem about the ocean."
  }'
```

--------------------------------

### Initialize Hono Project with C3

Source: https://developers.cloudflare.com/workers/tutorials/build-a-slackbot

Instructions on using the create-cloudflare-cli (C3) to initialize a new Hono project. It guides the user through selecting project types, frameworks, and deployment options.

```bash
npm create cloudflare@latest
# or
yarn create cloudflare
# or
pnpm create cloudflare
```

--------------------------------

### Query PlanetScale Database in a Worker

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/planetscale

Example of how to query your PlanetScale database from a Cloudflare Worker using the installed driver and securely accessed credentials.

```javascript
import { createConnection } from '@planetscale/database';

export default {
  async fetch(request, env) {
    const connection = createConnection({
      host: env.PLANETSCALE_HOST,
      username: env.PLANETSCALE_USER,
      password: env.PLANETSCALE_PASSWORD,
    });

    const results = await connection.execute('SELECT * FROM products WHERE id = ?', [1]);
    return new Response(JSON.stringify(results.rows));
  },
};
```

--------------------------------

### React App Fetching Data from Worker API

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/react

Example of a React component making a `fetch()` request to the Cloudflare Worker's API endpoint. This demonstrates how the frontend retrieves data from the backend API to display in the UI.

```typescript
import { useState, useEffect } from 'react';

function App() {
  const [message, setMessage] = useState('');

  useEffect(() => {
    fetch('/api/')
      .then(res => res.text())
      .then(data => setMessage(data));
  }, []);

  return (
    <div>
      <h1>React App</h1>
      <p>{message}</p>
    </div>
  );
}

export default App;

```

--------------------------------

### Running Wrangler Build in Test Setup

Source: https://developers.cloudflare.com/workers/testing/miniflare/writing-tests

Demonstrates how to integrate a `wrangler build` command within a test setup hook using `node:test`. This ensures the Worker is built before testing.

```bash
import { Miniflare } from "miniflare";
import { test } from "node:test";
import assert from "node:assert";
import { spawn } from "child_process";

test("Test Worker with Wrangler Build", async () => {
  // Spawn wrangler build process
  const buildProcess = spawn("wrangler", ["build"]);

  // Wait for build to complete (or handle errors)
  await new Promise((resolve, reject) => {
    buildProcess.on('close', (code) => {
      if (code === 0) resolve();
      else reject(new Error(`Wrangler build failed with code ${code}`));
    });
    buildProcess.on('error', reject);
  });

  // Now that the worker is built, initialize Miniflare
  const mf = new Miniflare({
    scriptPath: "dist/index.js", // Assuming wrangler builds to dist/index.js
  });

  const res = await mf.dispatchFetch("http://localhost:8787/");
  const text = await res.text();

  assert.strictEqual(text, "Hello World!"); // Assuming built worker returns this
});
```

--------------------------------

### Example .env file structure

Source: https://developers.cloudflare.com/workers/wrangler/system-environment-variables

This snippet provides an example of how to structure a `.env` file for setting system environment variables. It shows common variables like `CLOUDFLARE_ACCOUNT_ID` and `CLOUDFLARE_API_TOKEN`.

```dotenv
CLOUDFLARE_ACCOUNT_ID=00000000000000000000000000000000
CLOUDFLARE_API_TOKEN=your-api-token
```

--------------------------------

### Start Local Development Server

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/nextjs

Starts the local development server for a Next.js application using npm, yarn, or pnpm.

```bash
npm run dev
```

```bash
yarn dev
```

```bash
pnpm dev
```

--------------------------------

### Deploy Cloudflare Worker with Wrangler

Source: https://developers.cloudflare.com/workers/get-started/dashboard

This command deploys your Cloudflare Worker application to the Cloudflare network using the Wrangler CLI. It handles the build and deployment process, making your Worker accessible via its `workers.dev` subdomain.

```bash
wrangler publish
```

--------------------------------

### Install OpenNext Cloudflare Adapter

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/nextjs

Installs the OpenNext Cloudflare adapter package using npm, yarn, or pnpm.

```bash
npm install @opennextjs/cloudflare
```

```bash
yarn add @opennextjs/cloudflare
```

```bash
pnpm add @opennextjs/cloudflare
```

--------------------------------

### JavaScript Worker Example

Source: https://developers.cloudflare.com/workers/testing/miniflare/writing-tests

An example of a simple JavaScript Worker that can be tested with Miniflare. This Worker exports a fetch handler.

```javascript
export default {
  async fetch(request, env, ctx) {
    return new Response("Hello World!");
  },
};
```

--------------------------------

### Example Worker Code (JavaScript)

Source: https://developers.cloudflare.com/workers/testing/vitest-integration/write-your-first-test

A simple Cloudflare Worker written in JavaScript that returns a 404 response for the `/404` path and "Hello World!" for all other paths.

```javascript
export default {
  async fetch(request) {
    const url = new URL(request.url);

    if (url.pathname === '/404') {
      return new Response('Not Found', {
        status: 404
      });
    }

    return new Response('Hello World!');
  }
};
```

--------------------------------

### Python Worker for DeepSeek R1 Distill Qwen 32B

Source: https://developers.cloudflare.com/workers/-ai/models/deepseek-r1-distill-qwen-32b

Example of a Python Cloudflare Worker to interact with the deepseek-r1-distill-qwen-32b model. This worker handles streaming responses and requires no external setup or authentication for testing.

```python
from js import Response
from cloudflare.workers import LLM

async def on_fetch(request):
    llm = LLM()
    prompt = await request.text()
    try:
        stream = await llm.chat.completions.create(
            model="@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
            messages=[{"role": "user", "content": prompt}],
            stream=True
        )
        return Response.new(stream.iter_lines())
    except Exception as e:
        return Response.new(f"Error: {e}", status=500)
```

--------------------------------

### Modify Full-Stack Application Worker Project

Source: https://developers.cloudflare.com/workers/static-assets/get-started

This snippet highlights the key files to modify for a full-stack Cloudflare Worker application. `src/index.ts` controls server-side behavior, and `public/index.html` (and other files in `public/`) manage static assets.

```typescript
// src/index.ts
// Modify this file to change the server-side behavior of your Worker.
```

```html
<!-- public/index.html -->
<!-- Modify this file, or anything else in public/, to change the static assets of your Worker. -->
```

--------------------------------

### Update Wrangler Compatibility Date (TOML)

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-scratch

Updates the `compatibility_date` in `wrangler.toml` to the current date. This ensures you can utilize the latest Cloudflare Workers features.

```toml
compatibility_date = "YYYY-MM-DD"
```

--------------------------------

### Node.js Example: Using Hyperdrive with Neon

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/neon

This JavaScript code snippet demonstrates how to create a Neon database client using Hyperdrive in a Cloudflare Worker. It assumes you have installed the 'node-postgres' driver and configured the Hyperdrive binding in your Wrangler configuration.

```javascript
import { Client } from 'pg';

export default {
  async fetch(request, env) {
    const client = new Client({ connectionString: env.YOUR_HYPERDRIVE_BINDING });
    await client.connect();
    const result = await client.query('SELECT $1::text as message', ['Hello from Hyperdrive!']);
    return new Response(result.rows[0].message);
  },
};
```

--------------------------------

### Install Dependencies for RedwoodSDK

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/redwoodsdk

Commands to install project dependencies after creating a new RedwoodSDK project.

```bash
npm install
```

```bash
yarn install
```

```bash
pnpm install
```

--------------------------------

### AI Prompting for TypeScript Workers

Source: https://developers.cloudflare.com/workers/get-started/prompting

This example demonstrates using the base prompt as a system prompt for AI models when generating TypeScript code for Cloudflare Workers. It guides the AI in structuring the output code specifically for TypeScript.

```typescript
// Example of how the AI might structure TypeScript output based on the prompt
// This is a conceptual example, not actual executable code from the prompt itself.

export interface Env {
  // If you wish to use durable objects, you may uncomment the following line
  // and add a durable object binding to your wrangler.toml file
  // KV: KVNamespace;
}

export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
    // Your Worker logic here
    return new Response('Hello from Cloudflare Workers (TypeScript)!', {
      headers: {
        'content-type': 'text/plain',
      },
    })
  },
}
```

--------------------------------

### Install Wrangler with npm

Source: https://developers.cloudflare.com/workers/wrangler/install-and-update

Installs the Wrangler CLI locally within your project using npm. This is the recommended method for managing Wrangler versions per project.

```bash
npm install wrangler --save-dev
```

--------------------------------

### Start Local Development Server for Svelte

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/svelte

Run this command within your Svelte project directory to start a local development server. This allows you to preview your application locally during the development process.

```bash
npm run dev
```

```bash
yarn dev
```

```bash
pnpm dev
```

--------------------------------

### Create Cloudflare Worker Project with yarn

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/build-a-retrieval-augmented-generation-ai

Initializes a new Cloudflare Worker project using yarn and the C3 CLI. Selects 'Hello World example', 'Worker only' template, JavaScript, and Git version control.

```bash
yarn create cloudflare my-rge-app
cd my-rge-app
```

--------------------------------

### Example Wrangler TOML Configuration

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/configuration

This snippet shows an example of a top-level configuration in a Wrangler TOML file. It demonstrates the basic structure for defining project settings that can be inherited by environments.

```toml
name = "my-worker"
main = "src/index.js"
compatibility_date = "2023-01-01"

[env.production]
kv_namespace = "my-kv-production"
route = "https://production.example.com/*"

[env.staging]
kv_namespace = "my-kv-staging"
route = "https://staging.example.com/*"
```

--------------------------------

### Create Nuxt Project with Cloudflare Workers Assets

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/nuxt

Use the create-cloudflare CLI (C3) to initialize a new Nuxt project and configure it for deployment with Workers Assets. This command sets up the project structure and offers immediate deployment options.

```bash
npm create cloudflare@latest
# or
yarn create cloudflare
# or
pnpm create cloudflare
```

--------------------------------

### Wrangler TOML Configuration Example

Source: https://developers.cloudflare.com/workers/vite-plugin/reference/vite-environments

This provides an example of a Wrangler configuration file in TOML format. It outlines essential settings for a Cloudflare Worker, such as its name, main entry point, and compatibility date, which can be integrated with Vite build processes.

```toml
[env.production]
vars = {
  MY_VARIABLE = "production_value"
}

[env.development]
vars = {
  MY_VARIABLE = "development_value"
}

[build]

[triggers]

[usage]

[routes]

[d1_databases]

[ai]

[queues]

[analytics_engine]

[r2]

[vectorize]

[durable_objects]

[kv_namespaces]

[logpush]

[wasm]

[services]

[site]

[pages]

[limits]

[dev]

[test]

[metrics]

[runtime]

[wasm_bindgen]

[wasm_modules]

[wasm_functions]

[wasm_imports]

[wasm_exports]

[wasm_exports_mutable]

[wasm_exports_immutable]

[wasm_exports_shared]

[wasm_exports_private]

[wasm_exports_public]

[wasm_exports_internal]

[wasm_exports_external]

[wasm_exports_global]

[wasm_exports_local]

[wasm_exports_static]

[wasm_exports_dynamic]

[wasm_exports_dynamic_mutable]

[wasm_exports_dynamic_immutable]

[wasm_exports_dynamic_shared]

[wasm_exports_dynamic_private]

[wasm_exports_dynamic_public]

[wasm_exports_dynamic_internal]

[wasm_exports_dynamic_external]

[wasm_exports_dynamic_global]

[wasm_exports_dynamic_local]

[wasm_exports_dynamic_static]

[wasm_exports_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_global]

[wasm_exports_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_global]

[wasm_exports_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_global]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_global]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_global]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_global]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_global]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_global]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_global]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_global]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_global]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_internal]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_external]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_local]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_static]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_mutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_immutable]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_shared]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_private]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_public]

[wasm_exports_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_dynamic_
```

--------------------------------

### TypeScript Example: Using Hyperdrive with Neon

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/neon

This TypeScript code snippet demonstrates how to create a Neon database client using Hyperdrive in a Cloudflare Worker. It assumes you have installed the 'node-postgres' driver and its types, and configured the Hyperdrive binding in your Wrangler configuration.

```typescript
import { Client } from 'pg';

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const client = new Client({ connectionString: env.YOUR_HYPERDRIVE_BINDING });
    await client.connect();
    const result = await client.query('SELECT $1::text as message', ['Hello from Hyperdrive!']);
    return new Response(result.rows[0].message);
  },
};
```

--------------------------------

### Rust Worker with start event

Source: https://developers.cloudflare.com/workers/languages/rust

This Rust code snippet illustrates how to execute code when a Worker first launches using the `start` event macro provided by `workers-rs`. This is useful for initialization tasks like setting up panic handlers.

```rust
#[event(start)]
fn start() {
    // Initialization logic, e.g., setting up panic hooks
}
```

--------------------------------

### Update Wrangler Compatibility Date

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-scratch

Updates the `compatibility_date` in `wrangler.jsonc` to the current date. This ensures you can utilize the latest Cloudflare Workers features.

```json
{
  "compatibility_date": "YYYY-MM-DD"
}
```

--------------------------------

### Create and Upload to R2 Bucket with Wrangler

Source: https://developers.cloudflare.com/workers/tutorials/create-finetuned-chatgpt-ai-models-with-r2

Demonstrates using the Wrangler CLI to create a new R2 bucket and upload a file to it. This is essential for storing the fine-tune document before it's sent to OpenAI.

```bash
wrangler r2 bucket create <BUCKET_NAME>
wrangler r2 object put <PATH>/<FILE_NAME> --file <FILE_NAME>
```

--------------------------------

### Python Usage Example with DeepSeek API

Source: https://developers.cloudflare.com/workers/-ai/models/deepseek-math-7b-instruct

This Python code demonstrates how to interact with the DeepSeek API to generate text using the DeepSeek-Math-7B-Instruct model. It shows how to set up the request, including headers and the JSON body for a chat completion.

```python
import os
import requests

api_key = os.environ.get("DEEPSEEK_API_KEY")

headers = {
    "Authorization": f"Bearer {api_key}",
    "Content-Type": "application/json"
}

data = {
    "model": "@cf/deepseek-ai/deepseek-math-7b-instruct",
    "messages": [
        {"role": "system", "content": "You are a helpful math assistant."},
        {"role": "user", "content": "Solve the following equation: 2x + 5 = 11"}
    ]
}

response = requests.post("https://api.deepseek.com/v1/chat/completions", headers=headers, json=data)

print(response.json())
```

--------------------------------

### Worker Usage Example for Qwen2.5-Coder-32B-Instruct

Source: https://developers.cloudflare.com/workers/-ai/models/qwen2

Demonstrates how to use the Qwen2.5-Coder-32B-Instruct model within a Cloudflare Worker. This example shows the basic structure for sending requests and handling responses from the model, suitable for streaming applications.

```javascript
addEventListener("fetch", (event) => {
  event.respondWith(handleRequest(event.request));
});

async function handleRequest(request) {
  const url = new URL(request.url);
  const prompt = url.searchParams.get("prompt");

  if (!prompt) {
    return new Response("Please provide a prompt parameter", {
      status: 400,
    });
  }

  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/qwen/qwen2.5-coder-32b-instruct", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${YOUR_CLOUDFLARE_API_TOKEN}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      prompt: prompt,
      stream: true // Enable streaming
    }),
  });

  if (!response.ok) {
    return new Response(`Error: ${response.statusText}`, {
      status: response.status,
    });
  }

  // Return the streaming response directly
  return new Response(response.body, {
    status: 200,
    headers: {
      "Content-Type": "text/plain", // Or appropriate content type for streaming
    },
  });
}

```

--------------------------------

### Disable Wrangler colorized output

Source: https://developers.cloudflare.com/workers/wrangler/system-environment-variables

This example shows how to disable Wrangler's colorized output by setting the `FORCE_COLOR` environment variable to '0'. This can improve readability in certain terminal setups.

```bash
FORCE_COLOR=0
```

--------------------------------

### Install Astro Cloudflare Adapter

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/astro

Installs the Astro Cloudflare adapter for your project, automatically configuring `astro.config.mjs` for server rendering.

```bash
npm install @astrojs/cloudflare
```

```bash
yarn add @astrojs/cloudflare
```

```bash
pnpm add @astrojs/cloudflare
```

--------------------------------

### Serve Static Assets and Handle SPA Fallbacks

Source: https://developers.cloudflare.com/workers/prompt

This example demonstrates serving static assets from a specified directory and configuring a Single Page Application (SPA) to handle 404 errors by routing them to the application's entry point. It utilizes the ASSETS binding.

```typescript
// src/index.ts

interface Env {
  ASSETS: Fetcher;
}

export default {
  fetch(request, env) {
    const url = new URL(request.url);

    if (url.pathname.startsWith("/api/")) {
      return Response.json({
        name: "Cloudflare",
      });
    }

    return env.ASSETS.fetch(request);
  },
} satisfies ExportedHandler<Env>;

```

--------------------------------

### Install Resend SDK for Workers

Source: https://developers.cloudflare.com/workers/tutorials/send-emails-with-resend

This command installs the Resend SDK as a dependency for your Cloudflare Worker project using npm.

```bash
npm install resend

```

--------------------------------

### Check Wrangler Version

Source: https://developers.cloudflare.com/workers/wrangler/install-and-update

Displays the currently installed version of the Wrangler CLI in your project. This is useful for verifying your installation or troubleshooting.

```bash
npx wrangler --version
```

--------------------------------

### Example Worker Code (TypeScript)

Source: https://developers.cloudflare.com/workers/testing/vitest-integration/write-your-first-test

A simple Cloudflare Worker written in TypeScript that returns a 404 response for the `/404` path and "Hello World!" for all other paths.

```typescript
interface Env {
  // Example binding, replace with your actual bindings
}

export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
    const url = new URL(request.url);

    if (url.pathname === '/404') {
      return new Response('Not Found', {
        status: 404
      });
    }

    return new Response('Hello World!');
  }
};
```

--------------------------------

### Install Wrangler with yarn

Source: https://developers.cloudflare.com/workers/wrangler/install-and-update

Installs the Wrangler CLI locally within your project using yarn. This method ensures consistent dependency management for your project.

```bash
yarn add wrangler --dev
```

--------------------------------

### Python Usage Example for Qwen QwQ-32B

Source: https://developers.cloudflare.com/workers/-ai/models/qwq-32b

This Python code snippet demonstrates how to interact with the Qwen QwQ-32B model using Cloudflare Workers. It shows how to send a prompt and receive a text generation response.

```python
from workers_ai import AiClient

client = AiClient("YOUR_CLOUDFLARE_API_TOKEN")

prompt = "Explain the concept of quantum entanglement in simple terms."

response = client.run("@cf/qwen/qwq-32b", {
    "prompt": prompt
})

print(response["result"])
```

--------------------------------

### Configure Vite for Cloudflare Workers

Source: https://developers.cloudflare.com/workers/vite-plugin

This example demonstrates how to configure your `vite.config.js` or `vite.config.ts` file to use the Cloudflare Vite plugin. It shows the basic setup for integrating the plugin into your Vite build process, which is crucial for deploying applications to Cloudflare Workers.

```javascript
import { defineConfig } from 'vite';
import cloudflareWorkers from '@cloudflare/vite-plugin-cloudflare-workers';

export default defineConfig({
  plugins: [
    cloudflareWorkers({
      // Options for the plugin
    }),
  ],
});
```

--------------------------------

### cURL Command for Model Interaction

Source: https://developers.cloudflare.com/workers/-ai/models/deepseek-math-7b-instruct

This example provides a cURL command to test the DeepSeek-Math-7B-Instruct model. It illustrates how to send a POST request with a prompt and necessary authentication headers to the DeepSeek API.

```bash
curl -X POST "https://api.deepseek.com/v1/chat/completions" \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer YOUR_API_KEY" \
     -d '{ 
         "model": "@cf/deepseek-ai/deepseek-math-7b-instruct", 
         "messages": [ 
             {"role": "system", "content": "You are a helpful math assistant."}, 
             {"role": "user", "content": "What is the integral of x^2 dx?"} 
         ] 
     }'
```

--------------------------------

### Worker - Streaming Text Generation with llama-2-7b-chat-int8

Source: https://developers.cloudflare.com/workers/-ai/models/llama-2-7b-chat-int8

Example of how to use the llama-2-7b-chat-int8 model within a Cloudflare Worker to generate text with streaming capabilities. This requires no external setup or authentication when used with Workers AI.

```typescript
import { Ai } from "@cloudflare/ai";

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const ai = new Ai(env.AI);
    const prompt = "Explain the importance of low-latency AI.";

    const response = await ai.run(
      "@cf/meta/llama-2-7b-chat-int8",
      {
        prompt: prompt,
        stream: true
      }
    );

    return new Response(response);
  },
};

```

--------------------------------

### Scoped Prompt Example (System and User Roles)

Source: https://developers.cloudflare.com/workers/-ai/guides/prompting

An example of a scoped prompt using system and user roles for interacting with text generation models. This method is recommended for its unified interface.

```json
{
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "What is the capital of France?"
    }
  ]
}
```

--------------------------------

### Wrangler Configuration Example

Source: https://developers.cloudflare.com/workers/vite-plugin/reference/vite-environments

This shows a basic configuration file for Wrangler, a tool for Cloudflare Workers. It includes settings relevant to a Worker, potentially used in conjunction with Vite environments. The example uses JSONC format.

```json
{
  "name": "my-worker",
  "main": "./src/index.js",
  "compatibility_date": "2024-01-01",
  "env": {
    "production": {
      "vars": {
        "MY_VARIABLE": "production_value"
      }
    }
  },
  "vars": {
    "MY_VARIABLE": "development_value"
  }
}
```

--------------------------------

### Install cargo-generate

Source: https://developers.cloudflare.com/workers/languages/rust

This command installs the `cargo-generate` tool, which is used to create new Rust projects from templates.

```bash
cargo install cargo-generate
```

--------------------------------

### Create Cloudflare Workers Project with TypeScript

Source: https://developers.cloudflare.com/workers/tutorials/connect-to-turso-using-workers

Generates a new Cloudflare Workers project named `worker-turso-ts` using the Wrangler CLI. It sets up a 'Hello World' example with TypeScript and Git version control, but skips initial deployment.

```bash
npm create cloudflare@latest worker-turso-ts -- --type=ts
```

--------------------------------

### Implement Workers AI Embedded Function Calling in JavaScript

Source: https://developers.cloudflare.com/workers/-ai/features/function-calling/embedded/get-started

This JavaScript code snippet shows how to integrate Workers AI embedded function calling into your application. It includes importing the `runWithTools` function from `@cloudflare/ai-utils` and defining a list of tools that the LLM can utilize, such as a 'sum' function. The `runWithTools` function simplifies the process of invoking these tools based on user input.

```javascript
import { runWithTools } from "@cloudflare/ai-utils"

// Example tool definition
const tools = [
  {
    name: "sum",
    description: "Adds two numbers together.",
    parameters: {
      type: "object",
      properties: {
        a: {
          type: "number",
          description: "The first number."
        },
        b: {
          type: "number",
          description: "The second number."
        }
      },
      required: ["a", "b"]
    },
    handler: async (a, b) => a + b
  }
]

// Example usage within a Worker handler
export default {
  async fetch(request) {
    const userQuery = "What is 5 + 3?"; // Replace with actual user input
    
    // The runWithTools function will call the appropriate tool based on the userQuery
    const result = await runWithTools(userQuery, tools);
    
    return new Response(JSON.stringify(result), {
      headers: {
        "Content-Type": "application/json"
      }
    });
  }
}
```

--------------------------------

### Installing Cloudflare Workers CLI with pnpm

Source: https://developers.cloudflare.com/workers/wrangler/api

Provides the command to install the Cloudflare Workers CLI using pnpm, a fast and efficient package manager for Node.js.

```bash
pnpm add -g @cloudflare/wrangler
```

--------------------------------

### Example: Miniflare Local Dev with Remote KV Binding (JavaScript)

Source: https://developers.cloudflare.com/workers/development-testing

A basic JavaScript example demonstrating how to configure Miniflare for local development with a remote KV binding using Wrangler utilities. Assumes a single hardcoded KV binding.

```javascript
const miniflare = require('miniflare');
const { maybeStartOrUpdateRemoteProxySession } = require('wrangler');

async function runDev() {
  let proxySession = null;

  try {
    // Attempt to start or update the remote proxy session
    proxySession = await maybeStartOrUpdateRemoteProxySession(
      {
        // Specify the binding name and its configuration
        bindings: {
          MY_KV: {
            type: 'kv-namespace',
            binding: 'MY_KV',
            id: 'your-kv-namespace-id'
          }
        }
      },
      proxySession, // Pass existing session details or null
      {
        accountId: 'YOUR_CLOUDFLARE_ACCOUNT_ID',
        apiToken: 'YOUR_CLOUDFLARE_API_TOKEN'
      }
    );

    const mf = new miniflare.Miniflare({
      scriptPath: 'dist/index.js', // Path to your compiled worker script
      kvNamespaces: proxySession ? { MY_KV: proxySession.kvNamespaces.MY_KV } : undefined,
      wranglerConfigPath: true,
      // If using remoteProxyConnectionString, it would be passed here
      // remoteProxyConnectionString: proxySession?.remoteProxyConnectionString
    });

    const res = await mf.dispatch();
    console.log('Worker response:', res);

  } finally {
    // Clean up the proxy session if it was started
    if (proxySession) {
      await proxySession.dispose();
    }
  }
}

runDev().catch(console.error);
```

--------------------------------

### Install Wrangler CLI

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/nextjs

Installs the Wrangler CLI as a devDependency using npm, yarn, or pnpm.

```bash
npm install wrangler --save-dev
```

```bash
yarn add wrangler --dev
```

```bash
pnpm add wrangler --save-dev
```

--------------------------------

### Connect to Agent using AgentClient

Source: https://developers.cloudflare.com/workers/prompt

Provides an example of a client-side JavaScript script that connects to a Cloudflare Agent using `AgentClient`. It demonstrates setting up the connection, listening for messages, and sending an inquiry.

```javascript
// client.js
import { AgentClient } from "agents/client";

const connection = new AgentClient({
  agent: "dialogue-agent",
  name: "insight-seeker",
});

connection.addEventListener("message", (event) => {
  console.log("Received:", event.data);
});

connection.send(
  JSON.stringify({
    type: "inquiry",
    content: "What patterns do you see?",
  })
);
```

--------------------------------

### Install Wrangler with npm

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/install-update

Installs the Wrangler CLI tool using the Node Package Manager (npm). This is a common method for JavaScript developers.

```bash
npm install -g @cloudflare/wrangler
```

--------------------------------

### Set, Get, and Return Cache Item with Momento

Source: https://developers.cloudflare.com/workers/configuration/integrations/momento

This example demonstrates how to interact with Momento Cache from a Cloudflare Worker. It shows how to set an item in the cache, retrieve it, and return it as a JSON object. The necessary Momento credentials are automatically available as secrets within the Worker environment due to the integration.

```javascript
import { set, get } from '@upstash/redis';

export default {
  async fetch(request, env) {
    const cacheName = 'user-profiles';
    const key = 'user:123';
    const value = { name: 'John Doe', email: 'john.doe@example.com' };

    // Set an item in the cache
    await set(cacheName, key, value);

    // Get an item from the cache
    const cachedValue = await get(cacheName, key);

    // Return the cached item as JSON
    return new Response(JSON.stringify(cachedValue), {
      headers: {
        'content-type': 'application/json',
      },
    });
  },
};
```

--------------------------------

### Install Turso Client Library

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/turso

Installs the Turso client library for use in your Cloudflare Worker. Supports npm, yarn, and pnpm package managers.

```bash
npm install @libsql/client/web
```

```bash
yarn add @libsql/client/web
```

```bash
pnpm add @libsql/client/web
```

--------------------------------

### Example: Miniflare Local Dev with Remote KV Binding (TypeScript)

Source: https://developers.cloudflare.com/workers/development-testing

A basic TypeScript example demonstrating how to configure Miniflare for local development with a remote KV binding using Wrangler utilities. Assumes a single hardcoded KV binding.

```typescript
import Miniflare from 'miniflare';
import {
  maybeStartOrUpdateRemoteProxySession,
  StartRemoteProxySessionResult
} from 'wrangler';

async function runDev(): Promise<void> {
  let proxySession: StartRemoteProxySessionResult | null = null;

  try {
    // Attempt to start or update the remote proxy session
    proxySession = await maybeStartOrUpdateRemoteProxySession(
      {
        // Specify the binding name and its configuration
        bindings: {
          MY_KV: {
            type: 'kv-namespace',
            binding: 'MY_KV',
            id: 'your-kv-namespace-id'
          }
        }
      },
      proxySession, // Pass existing session details or null
      {
        accountId: 'YOUR_CLOUDFLARE_ACCOUNT_ID',
        apiToken: 'YOUR_CLOUDFLARE_API_TOKEN'
      }
    );

    const mf = new Miniflare({
      scriptPath: 'dist/index.ts', // Path to your compiled worker script
      kvNamespaces: proxySession ? { MY_KV: proxySession.kvNamespaces.MY_KV } : undefined,
      wranglerConfigPath: true,
      // If using remoteProxyConnectionString, it would be passed here
      // remoteProxyConnectionString: proxySession?.remoteProxyConnectionString
    });

    const res = await mf.dispatch();
    console.log('Worker response:', res);

  } finally {
    // Clean up the proxy session if it was started
    if (proxySession) {
      await proxySession.dispose();
    }
  }
}

runDev().catch(console.error);
```

--------------------------------

### Wrangler Configuration File Example

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/xata

This JSON snippet shows an example of how to configure Hyperdrive bindings within your `wrangler.jsonc` file. It includes Node.js compatibility flags and the Hyperdrive binding name.

```json
{
  "compatibilityFlags": [
    "nodejs_compat"
  ],
  "hyperdrive": [
    {
      "name": "MY_HYPERDRIVE_BINDING",
      "connectionString": "postgres://user:password@hostname:port/database"
    }
  ]
}
```

--------------------------------

### Install Vitest Workers Integration

Source: https://developers.cloudflare.com/workers/testing/vitest-integration/migration-guides/migrate-from-miniflare-2

This command installs the necessary package for integrating Vitest with Cloudflare Workers, replacing the old Miniflare testing environment.

```bash
npm uninstall jest-environment-miniflare vitest-environment-miniflare
npm install @cloudflare/vitest-pool-workers
```

--------------------------------

### Develop RedwoodSDK Project Locally

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/redwoodsdk

Command to start the local development server for a RedwoodSDK project. RedwoodSDK uses Vite, so the development workflow is the same as any other Vite project.

```bash
npm run dev
```

```bash
yarn dev
```

```bash
pnpm dev
```

--------------------------------

### Install node-postgres Driver

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/xata

These commands show how to install the `node-postgres` driver using different package managers (npm, yarn, pnpm). This driver is necessary for interacting with your PostgreSQL database from your Worker.

```bash
npm install pg
```

```bash
yarn add pg
```

```bash
pnpm add pg
```

--------------------------------

### Handling Different HTTP Methods in Cloudflare Workers (JavaScript)

Source: https://developers.cloudflare.com/workers/-ai/models

This example shows how to create a Cloudflare Worker that responds differently based on the HTTP method of the incoming request (e.g., GET, POST). It uses a switch statement to route logic.

```javascript
addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  const url = new URL(request.url)
  switch (request.method) {
    case 'GET':
      return new Response('Received a GET request!', {
        headers: {
          'content-type': 'text/plain',
        },
      })
    case 'POST':
      return new Response('Received a POST request!', {
        headers: {
          'content-type': 'text/plain',
        },
      })
    default:
      return new Response('Unsupported method.', {
        status: 405,
        headers: {
          'content-type': 'text/plain',
        },
      })
  }
}
```

--------------------------------

### Start Cloudflare Workers Project with Astro

Source: https://developers.cloudflare.com/workers/get-started/quickstarts

This template allows you to build a personal website, blog, or portfolio using Astro, a modern web framework. It provides a solid foundation for content-focused sites.

```Shell
npm create cloudflare@latest -- --template astro-blog-starter-template
# or
yarn create cloudflare --template astro-blog-starter-template
# or
pnpm create cloudflare --template astro-blog-starter-template
```

--------------------------------

### Start Local Development Server

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/docusaurus

Command to run a local development server for a Docusaurus project created with C3. This allows for local testing and development before deployment.

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
```

--------------------------------

### Install node-postgres Driver (pnpm)

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase

Installs the `node-postgres` driver using pnpm, preparing your Cloudflare Worker environment to utilize Hyperdrive for efficient database access.

```bash
pnpm add pg
```

--------------------------------

### curl - Streaming Text Generation with Falcon-7B-Instruct

Source: https://developers.cloudflare.com/workers/-ai/models/falcon-7b-instruct

Example of how to initiate streaming text generation with the Falcon-7B-Instruct model using curl. This requires setting the appropriate API endpoint and headers for authentication and content type.

```bash
curl --request POST \
     --url https://api.cloudflare.com/client/v4/accounts/:account_id/ai/run/@cf/tiiuae/falcon-7b-instruct \
     --header "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
     --header "Content-Type: application/json" \
     --data '{ 
       "prompt": "Write a short story about a robot learning to love.", 
       "stream": true 
     }' \
     --stream
```

--------------------------------

### Install Hono Routing Library

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/build-a-retrieval-augmented-generation-ai

These commands show how to install the Hono routing library using different package managers (npm, yarn, pnpm). Hono is a lightweight web framework for Cloudflare Workers, enabling efficient routing and request handling.

```bash
npm install hono
```

```bash
yarn add hono
```

```bash
pnpm add hono
```

--------------------------------

### Unscoped Prompt Example (Mistral Chat Template)

Source: https://developers.cloudflare.com/workers/-ai/guides/prompting

An example of constructing a chat template manually for an unscoped prompt, specifically for the Mistral model. This allows for finer control over the input format.

```json
{
  "raw": "[INST] What is the capital of France? [/INST]"
}
```

--------------------------------

### Install Wrangler with Cargo

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/install-update

Installs the Wrangler CLI tool using Cargo, Rust's package manager. This method is suitable for Rust developers.

```bash
cargo install wrangler
```

--------------------------------

### Install Latest Wrangler

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/update-v1-to-v2

This command installs the latest version of Wrangler.

```bash
npm install -g wrangler
```

--------------------------------

### Build and Deploy Project to Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/react

Builds the React application and deploys it to a *.workers.dev subdomain or a Custom Domain. This command can be used for direct deployment from your machine or integrated into CI/CD pipelines.

```bash
npm run deploy

```

```bash
yarn deploy

```

```bash
pnpm deploy

```

--------------------------------

### Start local development server with Wrangler

Source: https://developers.cloudflare.com/workers/languages/rust

This command starts a local development server for your Cloudflare Worker. It allows you to test your Worker locally and automatically rebuilds on code changes.

```bash
wrangler dev
```

--------------------------------

### Curl Usage Example for sqlcoder-7b-2

Source: https://developers.cloudflare.com/workers/-ai/models/sqlcoder-7b-2

This curl command demonstrates how to use the sqlcoder-7b-2 model via the command line. It shows the structure for making a POST request to the model endpoint with the necessary API token and prompt.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/defog/sqlcoder-7b-2" \
     -H "Authorization: Bearer <API_TOKEN>" \
     -H "Content-Type: application/json" \
     -d '{ 
       "prompt": "Translate the following natural language into SQL: 'show me all customers who live in california'" 
     }'
```

--------------------------------

### Starting a Local Development Server with Vite Plugin

Source: https://developers.cloudflare.com/workers/development-testing

Initiate a local development server for Cloudflare Workers using Vite and the Cloudflare Vite plugin. This provides a modern development experience for Workers, leveraging Vite's ecosystem. It also uses Miniflare for local simulation.

```bash
vite dev
```

--------------------------------

### Manage Scheduled Tasks in Cloudflare Workers

Source: https://developers.cloudflare.com/workers/prompt

Demonstrates how to get, cancel, and filter scheduled tasks using the Agent's scheduling capabilities. It includes examples for retrieving a specific task by ID, fetching all tasks, canceling a task, and filtering tasks based on a time range.

```typescript
    // Get a specific schedule by ID
    // Returns undefined if the task does not exist
    let task = await this.getSchedule(task.id)

    // Get all scheduled tasks
    // Returns an array of Schedule objects
    let tasks = this.getSchedules();

    // Cancel a task by its ID
    // Returns true if the task was cancelled, false if it did not exist
    await this.cancelSchedule(task.id);

    // Filter for specific tasks
    // e.g. all tasks starting in the next hour
    let tasks = this.getSchedules({
      timeRange: {
        start: new Date(Date.now()),
        end: new Date(Date.now() + 60 * 60 * 1000),
      }
    });
```

--------------------------------

### Hyperdrive local connection string example

Source: https://developers.cloudflare.com/workers/wrangler/system-environment-variables

This snippet illustrates how to set the `CLOUDFLARE_HYPERDRIVE_LOCAL_CONNECTION_STRING_<BINDING_NAME>` environment variable for local development with Hyperdrive. It shows a PostgreSQL connection string example, where `PROD_DB` is the binding name for the Hyperdrive.

```bash
CLOUDFLARE_HYPERDRIVE_LOCAL_CONNECTION_STRING_PROD_DB="postgres://user:password@127.0.0.1:5432/testdb"
```

--------------------------------

### Install Supabase Client (npm)

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase

Installs the official Supabase JavaScript client library using npm, which is necessary for interacting with your Supabase database from a Cloudflare Worker.

```bash
npm install @supabase/supabase-js
```

--------------------------------

### Build and Deploy Nuxt Project to Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/nuxt

This command builds your Nuxt project and deploys it to Cloudflare Workers. It's suitable for deployment from your local machine or CI/CD systems. Ensure CI configurations are updated if using a CI environment.

```bash
npm run deploy
# or
yarn deploy
# or
pnpm deploy
```

--------------------------------

### Install wasm32-unknown-unknown toolchain

Source: https://developers.cloudflare.com/workers/languages/rust

This command installs the necessary WebAssembly toolchain for Rust development on Cloudflare Workers.

```bash
rustup target add wasm32-unknown-unknown
```

--------------------------------

### Implement Workers AI Embedded Function Calling in TypeScript

Source: https://developers.cloudflare.com/workers/-ai/features/function-calling/embedded/get-started

This TypeScript code snippet demonstrates how to update your `index.ts` file to include Workers AI embedded function calling. It shows the import statement for `runWithTools` from `@cloudflare/ai-utils` and defines a list of tools, including a 'sum' function, that the LLM can use to respond to user queries. The `runWithTools` function abstracts the underlying process.

```typescript
import { runWithTools } from "@cloudflare/ai-utils"

// Example tool definition
const tools = [
  {
    name: "sum",
    description: "Adds two numbers together.",
    parameters: {
      type: "object",
      properties: {
        a: {
          type: "number",
          description: "The first number."
        },
        b: {
          type: "number",
          description: "The second number."
        }
      },
      required: ["a", "b"]
    },
    handler: async (a: number, b: number) => a + b
  }
]

// Example usage within a Worker handler
export default {
  async fetch(request: Request): Promise<Response> {
    const userQuery = "What is 2 + 2?"; // Replace with actual user input
    
    // The runWithTools function will call the appropriate tool based on the userQuery
    const result = await runWithTools(userQuery, tools);
    
    return new Response(JSON.stringify(result), {
      headers: {
        "Content-Type": "application/json"
      }
    });
  }
}
```

--------------------------------

### Install PlanetScale Database Driver

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/planetscale

Install the official PlanetScale database driver for Node.js using npm, yarn, or pnpm to enable database interactions within your Worker.

```bash
npm install @planetscale/database
# or
yarn add @planetscale/database
# or
pnpm add @planetscale/database
```

--------------------------------

### Install @upstash/qstash with npm

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/upstash

This snippet shows how to install the Upstash QStash HTTP client using npm, enabling communication with QStash endpoints from a Cloudflare Worker.

```bash
npm install @upstash/qstash
```

--------------------------------

### Build and Deploy Waku Project to Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/waku

Command to build and deploy the Waku project to Cloudflare Workers. This is the final step to make the application live on a *.workers.dev subdomain or a custom domain.

```bash
npm run deploy
```

```bash
yarn deploy
```

```bash
pnpm deploy
```

--------------------------------

### Add build script to package.json

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/eject-webpack

This example shows how to add a custom build script to your `package.json` file. This script is used to invoke webpack, enabling you to bundle your Cloudflare Workers project with your existing webpack setup after migrating to Wrangler v2.

```json
{
  // ... other package.json contents
  "scripts": {
    "build": "webpack --config webpack.config.js"
  }
}
```

--------------------------------

### Scaffold Full-Stack App with create-cloudflare CLI (C3)

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/react

Initiates a new full-stack project with React SPA, Cloudflare Workers API, and Vite integration using the create-cloudflare CLI. Supports npm, yarn, and pnpm package managers.

```bash
npm create cloudflare@latest my-react-app -- --template=react

```

```bash
yarn create cloudflare my-react-app --template=react

```

```bash
pnpm create cloudflare my-react-app --template=react

```

--------------------------------

### Installing Cloudflare Workers CLI with npm

Source: https://developers.cloudflare.com/workers/wrangler/api

Provides the command to install the Cloudflare Workers CLI using npm, which is a prerequisite for using Wrangler and related tools.

```bash
npm install -g @cloudflare/wrangler
```

--------------------------------

### Verify Wrangler Installation

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/update-v1-to-v2

This command checks the installed Wrangler version to ensure the correct version is active.

```bash
wrangler --version
```

--------------------------------

### Installing Cloudflare Workers CLI with yarn

Source: https://developers.cloudflare.com/workers/wrangler/api

Provides the command to install the Cloudflare Workers CLI using yarn, an alternative package manager for Node.js projects.

```bash
yarn global add @cloudflare/wrangler
```

--------------------------------

### Wrangler Configuration with Multiple Environments

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/commands

Example of a Wrangler configuration file (`wrangler.toml`) defining multiple environments, each with its own KV namespace bindings.

```toml
[env.production]
name = "my-app-prod"
kv_namespaces = [
  { binding = "MY_KV", id = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" },
  { binding = "ANOTHER_KV", id = "yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy" }
]

[env.staging]
name = "my-app-staging"
kv_namespaces = [
  { binding = "MY_KV", id = "zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz" },
  { binding = "ANOTHER_KV", id = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa" }
]
```

--------------------------------

### Cloudflare Workers Configuration (wrangler.jsonc)

Source: https://developers.cloudflare.com/workers/prompt

Example of a wrangler.jsonc file for a Cloudflare Worker. It specifies the application name, main entry point, compatibility settings, and observability configuration.

```json
// wrangler.jsonc
{
  "name": "app-name-goes-here", // name of the app
  "main": "src/index.ts", // default file
  "compatibility_date": "2025-02-11",
  "compatibility_flags": ["nodejs_compat"], // Enable Node.js compatibility
  "observability": {
    // Enable logging by default
    "enabled": true
   }
}
```

--------------------------------

### Install @upstash/qstash with pnpm

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/upstash

This snippet shows how to install the Upstash QStash HTTP client using pnpm, enabling communication with QStash endpoints from a Cloudflare Worker.

```bash
pnpm add @upstash/qstash
```

--------------------------------

### Import and Use getAssetFromKV in Module Worker

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-worker

Demonstrates how to import the `getAssetFromKV` function from the `@cloudflare/kv-asset-handler` package and use it within a Cloudflare Worker to serve static assets. This is typically used in Module Workers.

```javascript
import { getAssetFromKV } from '@cloudflare/kv-asset-handler';

/**
 * The following lines are example properties you can use to configure the handler
 * You may want to extract these into a config file
 */
const ASSET_MANAGER = {
    // Define the path to your assets
    path: './public',

    // Define the cache control for your assets
    cacheControl: {
        browserTTL: 1000 * 60 * 60 * 24, // 24 hours
        edgeTTL: 1000 * 60 * 60 * 24, // 24 hours
    },

    // Define the cache key for your assets
    cacheKey: (request) => {
        return request.url;
    },

    // Define the transform for your assets
    transform: undefined,
};

/**
 * @param {Request} request
 * @param {Env} env
 * @param {ExecutionContext} ctx
 */
export async function handleRequest(request, env, ctx) {
    try {
        const response = await getAssetFromKV(request, ASSET_MANAGER);
        return response;
    } catch (e) {
        // Handle errors, e.g., return a 404 response
        return new Response('Not Found', {
            status: 404,
            statusText: 'Not Found',
        });
    }
}
```

```typescript
import { getAssetFromKV, /* other exports */ } from '@cloudflare/kv-asset-handler';

/**
 * The following lines are example properties you can use to configure the handler
 * You may want to extract these into a config file
 */
const ASSET_MANAGER = {
    // Define the path to your assets
    path: './public',

    // Define the cache control for your assets
    cacheControl: {
        browserTTL: 1000 * 60 * 60 * 24, // 24 hours
        edgeTTL: 1000 * 60 * 60 * 24, // 24 hours
    },

    // Define the cache key for your assets
    cacheKey: (request: Request) => {
        return request.url;
    },

    // Define the transform for your assets
    transform: undefined,
};

/**
 * @param {Request} request
 * @param {Env} env
 * @param {ExecutionContext} ctx
 */
export async function handleRequest(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
    try {
        const response = await getAssetFromKV(request, ASSET_MANAGER);
        return response;
    } catch (e) {
        // Handle errors, e.g., return a 404 response
        return new Response('Not Found', {
            status: 404,
            statusText: 'Not Found',
        });
    }
}
```

--------------------------------

### List KV Namespaces with Wrangler

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/commands

Lists all KV namespaces associated with your account ID. This example demonstrates piping the output to `jq` for processing.

```bash
wrangler kv:namespace list | jq
```

--------------------------------

### Install 'qrcode-svg' npm package for Cloudflare Workers

Source: https://developers.cloudflare.com/workers/tutorials/build-a-qr-code-generator

This command installs and saves the 'qrcode-svg' npm package to your project's dependencies. This package is used to generate QR codes. Ensure you are in your project's root directory before running these commands.

```bash
npm install qrcode-svg
```

```bash
yarn add qrcode-svg
```

```bash
pnpm add qrcode-svg
```

--------------------------------

### Install and Update Wrangler CLI

Source: https://developers.cloudflare.com/workers/wrangler

This section provides guidance on how to install Wrangler, the Cloudflare Developer Platform command-line interface (CLI), and how to update it to newer versions.

```bash
# Installation command example (specific command not provided in text)
npm install -g @cloudflare/wrangler

# Update command example (specific command not provided in text)
npm update -g @cloudflare/wrangler
```

--------------------------------

### Streaming Worker Example for Qwen QwQ-32B

Source: https://developers.cloudflare.com/workers/-ai/models/qwq-32b

This example outlines a Cloudflare Worker script designed for streaming responses from the Qwen QwQ-32B model. It's suitable for interactive applications where real-time output is desired.

```javascript
export default {
  async fetch(request) {
    const prompt = "Tell me a short story about a space explorer.";

    const response = await fetch("https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/qwen/qwq-32b", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${YOUR_CLOUDFLARE_API_TOKEN}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        "prompt": prompt,
        "stream": true
      })
    });

    return new Response(response.body, {
      headers: {
        "Content-Type": "text/plain"
      }
    });
  }
}
```

--------------------------------

### Specify Entry-Point for Wrangler Deploy

Source: https://developers.cloudflare.com/workers/ci-cd/builds/troubleshoot

Addresses the 'Missing entry-point' error by showing how to specify the script path via the command line or the 'main' configuration field in wrangler.toml.

```bash
wrangler deploy path/to/script
```

--------------------------------

### Scaffold Docusaurus Project with C3 CLI

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/docusaurus

Instructions to create a new Docusaurus project using the create-cloudflare CLI (C3). This command scaffolds the project, initiates Docusaurus setup, configures it for Cloudflare, and offers an option for instant deployment.

```bash
npm create cloudflare@latest -- --template docusaurus
# or
yarn create cloudflare --template docusaurus
# or
pnpm create cloudflare --template docusaurus
```

--------------------------------

### Scoped Prompt Example (System and User Roles)

Source: https://developers.cloudflare.com/workers/-ai/features/prompting

Demonstrates a basic scoped prompt using system and user roles for interacting with text generation models. This method is recommended for its unified interface and handling of model-specific chat templates.

```json
[
  {
    "role": "system",
    "content": "You are a helpful assistant."
  },
  {
    "role": "user",
    "content": "What is the capital of France?"
  }
]
```

--------------------------------

### Installing the 'jose' JWT Library via npm

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/using-bigquery-with-workers-ai

This command installs the 'jose' library, a JavaScript library for JSON Web Encryption, Signing and Compression. It is used to generate JSON Web Tokens (JWT) required for authenticating requests to Google Cloud Platform's APIs, such as BigQuery.

```bash
npm install jose
```

--------------------------------

### Install node-postgres Driver (yarn)

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase

Installs the `node-postgres` driver using yarn, enabling your Cloudflare Worker to establish a connection to the Supabase database via Hyperdrive.

```bash
yarn add pg
```

--------------------------------

### Develop Locally with Wrangler

Source: https://developers.cloudflare.com/workers/-ai/get-started/workers-wrangler

Starts a local development server for the Cloudflare Worker using Wrangler. This command allows you to test your Worker and its interactions with services like Workers AI locally before deploying.

```bash
npx wrangler dev
```

--------------------------------

### Python Usage Example for llama-3.3-70b-instruct-fp8-fast

Source: https://developers.cloudflare.com/workers/-ai/models/llama-3

This Python snippet demonstrates how to use the llama-3.3-70b-instruct-fp8-fast model with Cloudflare Workers. It requires the Cloudflare SDK for Python and shows a basic text generation request.

```python
from cloudflare.api_client import CloudflareAPI

client = CloudflareAPI(api_token='YOUR_API_TOKEN')

response = client.ai.llama_3_3_70b_instruct_fp8_fast.completions.create(
    account_id='YOUR_ACCOUNT_ID',
    prompt='Write a short poem about the ocean.'
)

print(response.completion)
```

--------------------------------

### Install node-postgres Types (TypeScript)

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase

Installs the type definitions for the `node-postgres` package using npm, which is beneficial for TypeScript projects to ensure type safety when working with database connections.

```bash
npm install --save-dev @types/pg
```

--------------------------------

### Build and Deploy Gatsby Project to Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/gatsby

This command builds your Gatsby project and deploys it to your Cloudflare Workers environment. It can be used for direct deployment or integrated into CI/CD pipelines.

```bash
npm run deploy
```

```bash
yarn deploy
```

```bash
pnpm deploy
```

--------------------------------

### Skip Automatic Dependency Installation

Source: https://developers.cloudflare.com/workers/ci-cd/builds/build-image

Explains how to disable the automatic dependency installation process in Cloudflare Workers builds. This is achieved by setting a specific build variable, allowing for custom installation scripts.

```bash
SKIP_DEPENDENCY_INSTALL = 1
```

--------------------------------

### Explore Text Generation Models with Workers AI SDK

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/explore-workers-ai-models-using-a-jupyter-notebook

This Python code snippet illustrates how to interact with the Workers AI API to explore text generation models. It assumes you have configured your environment with the necessary credentials. The example shows a basic call to a text generation model, returning a result. You can adapt this to iterate through available models and test different prompts.

```python
# This is a conceptual example using a hypothetical Workers AI SDK.
# Replace with actual SDK calls and model names.

# from workers_ai_sdk import WorkersAIClient

# client = WorkersAIClient(account_id=account_id, api_token=api_token)

# model_name = "@hf/text-generation"
# prompt = "Explain the concept of machine learning in simple terms."

# try:
#     response = client.generate(model=model_name, prompt=prompt)
#     print(response)
# except Exception as e:
#     print(f"An error occurred: {e}")

print("# Conceptual example for Text Generation")
print("# Replace with actual SDK calls.")
print("response = {'generated_text': 'Machine learning is a type of artificial intelligence...'}")

```

--------------------------------

### Install @upstash/qstash with yarn

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/upstash

This snippet shows how to install the Upstash QStash HTTP client using yarn, enabling communication with QStash endpoints from a Cloudflare Worker.

```bash
yarn add @upstash/qstash
```

--------------------------------

### Install node-postgres Driver (npm)

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase

Installs the `node-postgres` driver using npm, which is required to use Hyperdrive for connecting to your Supabase PostgreSQL database from a Cloudflare Worker.

```bash
npm install pg
```

--------------------------------

### Python - Text Generation with OpenHermes-2.5-Mistral-7B-AWQ

Source: https://developers.cloudflare.com/workers/-ai/models/openhermes-2

This Python snippet shows how to interact with the OpenHermes-2.5-Mistral-7B-AWQ model using a hypothetical SDK or direct HTTP requests. It assumes the existence of a library or function to handle the API call. The example outlines sending a prompt and receiving a generated text response. Error handling and specific parameter configurations would depend on the chosen library or API specification.

```python
import requests
import json

api_url = "https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@hf/thebloke/openhermes-2.5-mistral-7b-awq"
api_token = "<API_TOKEN>"

headers = {
    "Authorization": f"Bearer {api_token}",
    "Content-Type": "application/json"
}

data = {
    "prompt": "Write a short poem about the sea.",
    "stream": False
}

try:
    response = requests.post(api_url, headers=headers, json=data)
    response.raise_for_status()  # Raise an exception for bad status codes
    result = response.json()
    print(result['result']['response'])
except requests.exceptions.RequestException as e:
    print(f"An error occurred: {e}")
except KeyError as e:
    print(f"Unexpected response format: {e}")
```

--------------------------------

### Navigate to Project Directory

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/qwik

After successfully setting up your Qwik project using the create-cloudflare CLI, you need to change your current directory to the newly created project folder to proceed with development.

```bash
cd my-qwik-app
```

--------------------------------

### Configure Scripts in package.json

Source: https://developers.cloudflare.com/workers/platform/deploy-buttons

Example of how to configure build and deploy scripts in your package.json file, including running D1 migrations. This helps Cloudflare automatically detect and pre-populate these commands during deployment.

```json
{
  "scripts": {
    "build": "npm run build",
    "deploy": "npm run build && npx wrangler deploy --config wrangler.prod.toml && npm run migrate:prod",
    "migrate:prod": "npx wrangler d1 execute <YOUR_DB_BINDING_NAME> --file migrations/schema.sql --local"
  }
}
```

--------------------------------

### Install @upstash/kafka with npm

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/upstash

This snippet shows how to install the Upstash Kafka HTTP/REST client using npm, which is needed to interact with Upstash Kafka from a Cloudflare Worker.

```bash
npm install @upstash/kafka
```

--------------------------------

### Example Generated Wrangler Configuration (`dist/wrangler.jsonc`)

Source: https://developers.cloudflare.com/workers/wrangler/configuration

This is an example of a generated Wrangler configuration file. It points to the compiled code entry-point, does not define environments, and resolves environment-specific variables. This file is loaded by Wrangler when redirected by `.wrangler/deploy/config.json`.

```json
{
  "main": "./dist/index.js",
  "compatibility_date": "2022-09-01",
  "vars": {
    "MY_VARIABLE": "staging-value"
  }
}
```

--------------------------------

### Install Supabase Client (yarn)

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase

Installs the official Supabase JavaScript client library using yarn, a popular package manager for JavaScript projects, enabling database operations within your Worker.

```bash
yarn add @supabase/supabase-js
```

--------------------------------

### Create a Cloudflare Worker Project with C3

Source: https://developers.cloudflare.com/workers/tutorials/send-emails-with-postmark

This snippet shows how to create a new Cloudflare Worker project using the C3 command-line tool. It includes both interactive prompts and direct CLI arguments for project setup.

```bash
npx c3 create worker

```

```bash
npx c3 create worker --name my-worker --type "simple" --no-deploy

```

--------------------------------

### Create Svelte Project with Cloudflare Workers Assets

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/svelte

Use the create-cloudflare CLI (C3) to set up a new Svelte project configured for Cloudflare Workers Assets. This command initiates Svelte's official setup tool and offers instant deployment options.

```bash
npm create cloudflare@latest -- --template svelte
```

```bash
yarn create cloudflare --template svelte
```

```bash
pnpm create cloudflare --template svelte
```

--------------------------------

### Update Wrangler Configuration Example

Source: https://developers.cloudflare.com/workers/prompts/pages-to-workers

Illustrates the conversion of Cloudflare Pages build output directory configuration to the Workers Assets format within `wrangler.jsonc`. This example shows how to replace `pages_build_output_dir` with the `assets.directory` field.

```jsonc
{
	"name": "project-name",
	"compatibility_date": "2025-06-05",
	"assets": { "directory": "./dist" },
	// Add other fields as needed
}
```

--------------------------------

### Initialize Prisma in your application

Source: https://developers.cloudflare.com/workers/tutorials/using-prisma-postgres-with-workers

Initializes Prisma within your project. This command might prompt you to log in to the Prisma Data Platform and select a database region. It creates a `prisma` folder with `schema.prisma` and an `.env` file.

```bash
# npm
npx prisma init

# yarn
yarn prisma init

# pnpm
pnpm prisma init
```

--------------------------------

### Install @upstash/kafka with pnpm

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/upstash

This snippet shows how to install the Upstash Kafka HTTP/REST client using pnpm, which is needed to interact with Upstash Kafka from a Cloudflare Worker.

```bash
pnpm add @upstash/kafka
```

--------------------------------

### Cloudflare Workers API Output Schema Example

Source: https://developers.cloudflare.com/workers/-ai/models/phi-2

An example of the output schema for a Cloudflare Workers API response. This schema outlines the structure for the generated `response` string, `usage` statistics, and `tool_calls`.

```json
{
  "response": "string required",
  "usage": {
    "prompt_tokens": "number 0",
    "completion_tokens": "number 0",
    "total_tokens": "number 0"
  },
  "tool_calls": [
    {
      "items": {
        "arguments": {
          "name": "string"
        },
        "name": "string"
      }
    }
  ]
}
```

--------------------------------

### Generate Image with lucid-origin using cURL

Source: https://developers.cloudflare.com/workers/-ai/models/lucid-origin

This example shows how to generate an image using the lucid-origin model via a cURL command. It specifies the API endpoint and provides example parameters for the image generation request.

```bash
curl "https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/leonardo/lucid-origin" \
     -X POST \
     -H "Authorization: Bearer <API_TOKEN>" \
     -H "Content-Type: application/json" \
     -d '{ 
         "prompt": "A futuristic cityscape at sunset, with flying vehicles.", 
         "guidance": 7.0, 
         "seed": 54321, 
         "height": 768, 
         "width": 1024, 
         "num_steps": 30, 
         "steps": 30 
       }'
```

--------------------------------

### Import and Use getAssetFromKV in Service Worker

Source: https://developers.cloudflare.com/workers/configuration/sites/start-from-worker

Illustrates how to import and utilize the `getAssetFromKV` function within a Cloudflare Service Worker for serving static assets. This approach is suitable for Service Workers.

```javascript
import { getAssetFromKV } from '@cloudflare/kv-asset-handler';

/**
 * The following lines are example properties you can use to configure the handler
 * You may want to extract these into a config file
 */
const ASSET_MANAGER = {
    // Define the path to your assets
    path: './public',

    // Define the cache control for your assets
    cacheControl: {
        browserTTL: 1000 * 60 * 60 * 24, // 24 hours
        edgeTTL: 1000 * 60 * 60 * 24, // 24 hours
    },

    // Define the cache key for your assets
    cacheKey: (request) => {
        return request.url;
    },

    // Define the transform for your assets
    transform: undefined,
};

/**
 * @param {FetchEvent} event
 */
addEventListener('fetch', (event) => {
    event.respondWith(handleRequest(event.request));
});

/**
 * @param {Request} request
 */
async function handleRequest(request) {
    try {
        const response = await getAssetFromKV(request, ASSET_MANAGER);
        return response;
    } catch (e) {
        // Handle errors, e.g., return a 404 response
        return new Response('Not Found', {
            status: 404,
            statusText: 'Not Found',
        });
    }
}
```

--------------------------------

### Build and Deploy SolidJS Project to Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/solid

This command builds your SolidJS application and deploys it to Cloudflare Workers. It's suitable for deployment from your local machine or CI/CD systems. Ensure your CI configuration is updated if using this command in a pipeline.

```bash
npm run deploy
```

```bash
yarn deploy
```

```bash
pnpm deploy
```

--------------------------------

### Start Local Development Server

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/hono

This command starts a local development server for your Hono application. It utilizes the Cloudflare Vite plugin to emulate the Cloudflare Workers runtime locally, enabling features like hot module replacement (HMR) and binding emulation.

```bash
npm run dev
```

```bash
yarn dev
```

```bash
pnpm dev
```

--------------------------------

### Wrangler Configuration

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/nextjs

Example content for a Wrangler configuration file (wrangler.jsonc or wrangler.toml).

```json
{
  "name": "my-next-app",
  "main": "./.open-next/server.js",
  "compatibility_flags": [
    "nodejs_compat"
  ],
  "rules": [
    {
      "type": "TextRule",
      "pattern": "^$",
      "headers": {
        "Content-Type": "text/html; charset=utf-8"
      }
    }
  ]
}
```

--------------------------------

### Install Supabase Client (pnpm)

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase

Installs the official Supabase JavaScript client library using pnpm, an efficient package manager, facilitating the connection and data manipulation with your Supabase database from Cloudflare Workers.

```bash
pnpm add @supabase/supabase-js
```

--------------------------------

### Query Analytics Engine Data

Source: https://developers.cloudflare.com/workers/prompt

This section provides examples of how to query data stored in the Analytics Engine using SQL. It includes a sample query to retrieve temperature data and a command to list available datasets. Authentication is handled via API tokens.

```sql
SELECT
    timestamp,
    blob1 AS location_id,
    double1 AS inside_temp,
    double2 AS outside_temp
FROM temperatures
WHERE timestamp > NOW() - INTERVAL '1' DAY
```

```bash
curl "<https://api.cloudflare.com/client/v4/accounts/{account_id}/analytics_engine/sql>" \
--header "Authorization: Bearer <API_TOKEN>"
--data "SHOW TABLES"
```

--------------------------------

### Hello World Durable Object Template

Source: https://developers.cloudflare.com/workers/get-started/quickstarts

A basic template demonstrating the creation and usage of a Durable Object in Cloudflare Workers. This is a fundamental starting point for learning about Durable Objects.

```Shell
npm create cloudflare@latest -- --template hello-world-do-template
# or
yarn create cloudflare --template hello-world-do-template
# or
pnpm create cloudflare --template hello-world-do-template
```

--------------------------------

### startRemoteProxySession API

Source: https://developers.cloudflare.com/workers/development-testing

Starts a proxy session for interacting with remote bindings. Allows configuration of session behavior and authentication.

```APIDOC
## startRemoteProxySession

### Description
Starts a proxy session for a given set of bindings. It accepts options to control session behavior, including an `auth` option with your Cloudflare account ID and API token for remote binding access.

### Method
(Not applicable, this is a utility function)

### Endpoint
(Not applicable, this is a utility function)

### Parameters
#### Path Parameters
(None)

#### Query Parameters
(None)

#### Request Body
- **bindings** (object) - Required - The bindings to be used for the remote session.
- **options** (object) - Optional - Options to control session behavior.
  - **auth** (object) - Optional - Authentication details.
    - **accountId** (string) - Required - Your Cloudflare account ID.
    - **apiToken** (string) - Required - Your Cloudflare API token.

### Request Example
```json
{
  "bindings": {
    "MY_KV": {
      "type": "kv",
      "id": "your-kv-namespace-id"
    }
  },
  "options": {
    "auth": {
      "accountId": "YOUR_ACCOUNT_ID",
      "apiToken": "YOUR_API_TOKEN"
    }
  }
}
```

### Response
#### Success Response (Object returned)
- **ready** (Promise<void>) - Resolves when the session is ready.
- **dispose** (() => Promise<void>) - Stops the session.
- **updateBindings** ((bindings: object) => Promise<void>) - Updates session bindings.
- **remoteProxyConnectionString** (string) - String to pass to Miniflare for remote binding access.

#### Response Example
```json
{
  "ready": "<Promise>",
  "dispose": "<Function>",
  "updateBindings": "<Function>",
  "remoteProxyConnectionString": "wrangler:remote-proxy:port=XXXX"
}
```
```

--------------------------------

### Install node-postgres Types (TypeScript - pnpm)

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase

Installs the type definitions for the `node-postgres` package using pnpm, enhancing type safety in your TypeScript Cloudflare Worker for database operations.

```bash
pnpm add --save-dev @types/pg
```

--------------------------------

### Text Generation with gemma-7b-it-lora via cURL

Source: https://developers.cloudflare.com/workers/-ai/models/gemma-7b-it-lora

Provides a command-line example using cURL to send a prompt to the gemma-7b-it-lora model. This is useful for quick testing and integration into shell scripts.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/google/gemma-7b-it-lora" \
     -H "Authorization: Bearer <API_TOKEN>" \
     -H "Content-Type: application/json" \
     -d '{ "prompt": "What are the main benefits of using AI in cloud computing?", "stream": false }'
```

--------------------------------

### Initialize New Project with C3 CLI

Source: https://developers.cloudflare.com/workers/wrangler/commands

Creates a new Cloudflare Workers project using the create-cloudflare-cli (C3) tool. Supports various web frameworks and templates, with options to install dependencies and deploy immediately. Global flags like `--help`, `--config`, and `--cwd` are also applicable.

```bash
wrangler init <NAME> [--yes] [--from-dash <WORKER_NAME>]
```

--------------------------------

### Text Generation with Mistral-Small-3.1-24b-instruct using curl

Source: https://developers.cloudflare.com/workers/-ai/models/mistral-small-3

This example shows how to interact with the Mistral-Small-3.1-24b-instruct model for text generation using `curl` from the command line. It requires your Cloudflare API token and Account ID.

```bash
curl -X POST \
  "https://api.cloudflare.com/client/v4/accounts/YOUR_CLOUDFLARE_ACCOUNT_ID/ai/run/@cf/mistralai/mistral-small-3.1-24b-instruct" \
  -H "Authorization: Bearer YOUR_CLOUDFLARE_API_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{ "messages": [{"role": "user", "content": "What is the weather like in San Francisco?"}] }'
```

--------------------------------

### Configuring External Modules with Globs

Source: https://developers.cloudflare.com/workers/wrangler/bundling

This configuration example for `find_additional_modules` uses globs to include all `.mjs` files in the `./lang/` directory as external modules, enabling lazy loading and dynamic imports.

```json
{ "type": "EsModule", "globs": ["./lang/**/*.mjs"], "fallthrough": true }
```

--------------------------------

### Calculate Worker Costs (Example 1)

Source: https://developers.cloudflare.com/workers/platform/pricing

This example demonstrates the calculation for a Worker handling 15 million requests per month with an average of 7ms CPU time per request, showing subscription, request, and CPU time costs.

```text
Subscription: $5.00
Requests: (15,000,000 requests - 10,000,000 included requests) / 1,000,000 * $0.30 = $1.50
CPU time: ((7 ms of CPU time per request * 15,000,000 requests) - 30,000,000 included CPU ms) / 1,000,000 * $0.02 = $1.50
Total: $8.00
```

--------------------------------

### Start Vitest Inspector

Source: https://developers.cloudflare.com/workers/testing/vitest-integration/debugging

Run Vitest with the `--inspect` flag to enable debugging. This command starts the Vitest inspector, allowing you to attach a debugger to port 9229.

```bash
npx vitest --inspect
```

--------------------------------

### Cache Everything with TTLs and Custom Keys (Hono)

Source: https://developers.cloudflare.com/workers/examples/cache-using-fetch

Demonstrates how to cache all resources and control their Time-To-Live (TTL) using origin headers. It also explains the concept of custom cache keys for consistent caching across different URLs.

```JavaScript
import { Hono } from 'hono';

const app = new Hono();

app.get('*', async (c) => {
  const request = c.req;
  const url = new URL(request.url);
  // Example: Custom cache key based on a specific query parameter
  const cacheKey = `${url.origin}${url.pathname}?id=${url.searchParams.get('id')}`;

  const cache = await caches.open('my-cache');
  let response = await cache.match(cacheKey);

  if (!response) {
    response = await fetch(request.url);
    // Example: Set cache control headers if needed
    // response.headers.set('Cache-Control', 'public, max-age=3600');
    await cache.put(cacheKey, response.clone());
  }
  return response;
});

export default app;
```

--------------------------------

### Start Wrangler Dev and Open DevTools

Source: https://developers.cloudflare.com/workers/observability/dev-tools/memory-usage

This snippet shows the command to start a Cloudflare Worker in development mode and the key to press to open the browser's developer tools for memory profiling.

```bash
wrangler dev
# Press 'D' in your terminal to open DevTools
```

--------------------------------

### Build and Deploy Qwik Project to Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/qwik

This command builds your Qwik project and deploys it to Cloudflare Workers. It's suitable for deployment from your local machine or any CI/CD system. Ensure your CI configuration is updated if using this command in a pipeline.

```bash
npm run deploy
```

```bash
yarn deploy
```

```bash
pnpm deploy
```

--------------------------------

### Run and Orchestrate Workflows

Source: https://developers.cloudflare.com/workers/prompt

Illustrates how to initiate and manage workflows from within an Agent. It shows creating a workflow instance and scheduling a subsequent task to check its status periodically.

```typescript
	// Run and orchestrate Workflows from Agents
  async runWorkflow(data) {
     let instance = await env.MY_WORKFLOW.create({
       id: data.id,
       params: data,
     })

     // Schedule another task that checks the Workflow status every 5 minutes...
     await this.schedule("*/5 * * * *", "checkWorkflowStatus", { id: instance.id });
   }
}
```

--------------------------------

### Wrapper for Global Setup File Imports in Cloudflare Workers Vitest

Source: https://developers.cloudflare.com/workers/testing/vitest-integration/known-issues

When importing packages like Postgres.js from a global setup file in Vitest, which runs in a Node.js environment, use a wrapper that leverages Vite's SSR module loader. This ensures correct module resolution for the `workerd` runtime. Adjust your Vitest configuration to point to this wrapper.

```javascript
// vite-plugin-node-resolve.js
import { createRequire } from 'module';

export function resolve(id, parent, options) {
  const require = createRequire(import.meta.url);
  try {
    return require.resolve(id, { paths: options.paths });
  } catch (e) {
    // Handle resolution errors or delegate to Vite's loader
    throw e;
  }
}

// vitest.config.ts
import { defineConfig } from 'vitest/config';
import { resolve } from './vite-plugin-node-resolve.js';

export default defineConfig({
  // ... other Vitest options
  resolve: {
    // Configure Vite's module loader to use the wrapper
    alias: {
      // Example: resolve 'postgres' to its Node.js version
      'postgres': resolve('postgres', null, { paths: [process.cwd()] })
    }
  }
});

```

--------------------------------

### Cache Everything with TTLs and Custom Keys (JavaScript)

Source: https://developers.cloudflare.com/workers/examples/cache-using-fetch

Demonstrates how to cache all resources and control their Time-To-Live (TTL) using origin headers. It also explains the concept of custom cache keys for consistent caching across different URLs.

```JavaScript
async function fetchAndCache(request) {
  const url = new URL(request.url);
  // Example: Custom cache key based on a specific query parameter
  const cacheKey = `${url.origin}${url.pathname}?id=${url.searchParams.get('id')}`;

  const cache = await caches.open('my-cache');
  let response = await cache.match(cacheKey);

  if (!response) {
    response = await fetch(request);
    // Example: Set cache control headers if needed
    // response.headers.set('Cache-Control', 'public, max-age=3600');
    await cache.put(cacheKey, response.clone());
  }
  return response;
}
```

--------------------------------

### Build AI Agents with State Management

Source: https://developers.cloudflare.com/workers/prompt

This example illustrates how to build an AI Agent on Cloudflare Workers, leveraging agent APIs for state management and syncing. It includes handling HTTP requests, WebSocket connections, and scheduling tasks.

```typescript
// src/index.ts
import { Agent, AgentNamespace, Connection, ConnectionContext, getAgentByName, routeAgentRequest, WSMessage } from 'agents';
import { OpenAI } from "openai";

interface Env {
	AIAgent: AgentNamespace<Agent>;
	OPENAI_API_KEY: string;
}

export class AIAgent extends Agent {
	// Handle HTTP requests with your Agent
  async onRequest(request) {
    // Connect with AI capabilities
    const ai = new OpenAI({
      apiKey: this.env.OPENAI_API_KEY,
    });

    // Process and understand
    const response = await ai.chat.completions.create({
      model: "gpt-4",
      messages: [{ role: "user", content: await request.text() }],
    });

    return new Response(response.choices[0].message.content);
  }

  async processTask(task) {
    await this.understand(task);
    await this.act();
    await this.reflect();
  }

	// Handle WebSockets
  async onConnect(connection: Connection) {
   await this.initiate(connection);
   connection.accept()
  }

  async onMessage(connection, message) {
    const understanding = await this.comprehend(message);
    await this.respond(connection, understanding);
  }

  async evolve(newInsight) {
      this.setState({
        ...this.state,
        insights: [...(this.state.insights || []), newInsight],
        understanding: this.state.understanding + 1,
      });
    }

  onStateUpdate(state, source) {
    console.log("Understanding deepened:", {
      newState: state,
      origin: source,
    });
  }

  // Scheduling APIs
  // An Agent can schedule tasks to be run in the future by calling this.schedule(when, callback, data), where when can be a delay, a Date, or a cron string; callback the function name to call, and data is an object of data to pass to the function.
  //
  // Scheduled tasks can do anything a request or message from a user can: make requests, query databases, send emails, read+write state: scheduled tasks can invoke any regular method on your Agent.
  async scheduleExamples() {
  	// schedule a task to run in 10 seconds
  	let task = await this.schedule(10, "someTask", { message: "hello" });

  	// schedule a task to run at a specific date
  	let task = await this.schedule(new Date("2025-01-01"), "someTask", {});

  	// schedule a task to run every 10 seconds
  	let { id } = await this.schedule("*/10 * * * *", "someTask", { message: "hello" });

  	// schedule a task to run every 10 seconds, but only on Mondays
  	let task = await this.schedule("0 0 * * 1", "someTask", { message: "hello" });

  	// cancel a scheduled task
  	this.cancelSchedule(task.id);

```

--------------------------------

### Install dotenv-cli for environment variable management

Source: https://developers.cloudflare.com/workers/tutorials/using-prisma-postgres-with-workers

Installs the `dotenv-cli` package, which is used to load environment variables from a `.dev.vars` file in Cloudflare Workers projects. Supports npm, yarn, and pnpm.

```bash
# npm
npm install dotenv-cli --save-dev

# yarn
yarn add dotenv-cli --dev

# pnpm
pnpm add dotenv-cli --save-dev
```

--------------------------------

### Install @upstash/kafka with yarn

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/upstash

This snippet shows how to install the Upstash Kafka HTTP/REST client using yarn, which is needed to interact with Upstash Kafka from a Cloudflare Worker.

```bash
yarn add @upstash/kafka
```

--------------------------------

### Add Deployment Scripts to package.json

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/tanstack

Add 'deploy' and 'cf-typegen' scripts to your package.json for building, deploying, and generating TypeScript types for Cloudflare bindings.

```json
{
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview",
    "deploy": "npm run build && wrangler deploy",
    "cf-typegen": "wrangler types"
  }
}
```

--------------------------------

### Install node-postgres Types (TypeScript - yarn)

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase

Installs the type definitions for the `node-postgres` package using yarn, providing type safety for your TypeScript Cloudflare Worker when interacting with the database.

```bash
yarn add --dev @types/pg
```

--------------------------------

### Wrangler TOML configuration example

Source: https://developers.cloudflare.com/workers/tutorials/generate-youtube-thumbnails-with-workers-and-images

This TOML configuration file (`wrangler.toml`) provides an alternative way to configure Cloudflare Worker deployments. It specifies the Worker's name and main script, along with environment-specific variables for image IDs and account hashes.

```toml
[env.production]
name = "thumbnail-image"
route = ""
workers_dev = true

[env.production.vars]
IMAGE_ID = "YOUR_IMAGE_ID"
IMAGE_URL = "YOUR_IMAGE_URL"

[site]
bucket = "./public"
entry-point = "index.html"

[vars]
CLOUDFLARE_ACCOUNT_HASH = "YOUR_CLOUDFLARE_ACCOUNT_HASH"
```

--------------------------------

### Install PostgreSQL client library and types for Node.js

Source: https://developers.cloudflare.com/workers/tutorials/postgres

Installs the necessary PostgreSQL client library (`pg`) and its TypeScript types for use within a Node.js environment. This allows your Worker to connect to and interact with PostgreSQL databases.

```bash
npm install pg
yarn add pg
pnpm add pg
```

```bash
npm install --save-dev @types/pg
yarn add --dev @types/pg
pnpm add --save-dev @types/pg
```

--------------------------------

### Example of Multiple Redirects in _redirects

Source: https://developers.cloudflare.com/workers/static-assets/redirects

This example shows a `_redirects` file with multiple redirect rules, including comments, static redirects, and redirects using splats and placeholders. The order of redirects is important, with static redirects typically appearing before dynamic ones.

```plaintext
# Redirects
/home / 301
/about /about-us
/blog/* /posts/:splat
/products/:id /item/:id
```

--------------------------------

### Install @upstash/redis with npm

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/upstash

This snippet shows how to install the Upstash Redis HTTP client using npm, which is required to connect to an Upstash Redis database from a Cloudflare Worker.

```bash
npm install @upstash/redis
```

--------------------------------

### Python Scheduled Handler Example

Source: https://developers.cloudflare.com/workers/runtime-apis/handlers/scheduled

An example of how to implement the scheduled handler in Python for Cloudflare Workers. This handler is executed when a Cron Trigger invokes the Worker.

```python
import asyncio
import httpx

async def scheduled(event, env, ctx):
    print(f"Cron Trigger fired: {event.cron}")
    ctx.waitUntil(httpx.AsyncClient().get('https://example.com'))

# Note: The actual execution context and how to define the handler
# might vary slightly based on the Python worker framework used.
```

--------------------------------

### JavaScript Scheduled Handler Example

Source: https://developers.cloudflare.com/workers/runtime-apis/handlers/scheduled

An example of how to implement the scheduled handler in JavaScript for Cloudflare Workers. This handler is executed when a Cron Trigger invokes the Worker.

```javascript
export default {
  async scheduled(event, env, ctx) {
    console.log('Cron Trigger fired:', event.cron);
    ctx.waitUntil(fetch('https://example.com'));
  }
};
```

--------------------------------

### TypeScript Scheduled Handler Example

Source: https://developers.cloudflare.com/workers/runtime-apis/handlers/scheduled

An example of how to implement the scheduled handler in TypeScript for Cloudflare Workers. This handler is executed when a Cron Trigger invokes the Worker.

```typescript
interface Env {
  // Example binding
  // MY_KV_NAMESPACE: KVNamespace;
}

interface ScheduledEvent {
  cron: string;
  scheduledTime: number;
}

export default {
  async scheduled(event: ScheduledEvent, env: Env, ctx: ExecutionContext) {
    console.log(`Cron Trigger fired: ${event.cron}`);
    ctx.waitUntil(fetch('https://example.com'));
  }
};
```

--------------------------------

### Cloudflare Queues Producer/Consumer

Source: https://developers.cloudflare.com/workers/prompt

Illustrates the use of Cloudflare Queues for message production and consumption. The producer example sends request information to a queue for asynchronous processing.

```typescript
// src/producer.ts
interface Env {
  REQUEST_QUEUE: Queue;
  UPSTREAM_API_URL: string;
  UPSTREAM_API_KEY: string;
}

export default {
async fetch(request: Request, env: Env) {
const info = {
timestamp: new Date().toISOString(),
method: request.method,
url: request.url,
headers: Object.fromEntries(request.headers),
};
await env.REQUEST_QUEUE.send(info);

return Response.json({
message: 'Request logged',

```

--------------------------------

### Cloudflare Bindings Helper Function

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/tanstack

A helper function to access Cloudflare bindings, designed for use in TanStack Start applications. It uses getPlatformProxy for local development and process.env in production. Ensure 'npm run cf-typegen' has been executed.

```typescript
import type { Env } from './env'; // Assuming Env is generated by cf-typegen
import { getPlatformProxy } from 'wrangler';

let platformProxy: ReturnType<typeof getPlatformProxy> | undefined;

export async function getBindings(): Promise<Env> {
  if (platformProxy) {
    return platformProxy.env;
  }

  // Use getPlatformProxy for local development
  // In production, bindings are accessed via process.env
  // Ensure you have run `npm run cf-typegen` to generate the Env types
  // The example assumes a KV namespace with binding name 'CACHE'
  platformProxy = await getPlatformProxy<Env>();
  return platformProxy.env;
}

// Example usage in a server function:
// import { getBindings } from './utils/bindings';
//
// export async function GET() {
//   const env = await getBindings();
//   const cachedData = await env.CACHE.get('some-key');
//   return new Response(cachedData || 'No data');
// }
```

--------------------------------

### Cloudflare Workers Direct Uploads Example (TypeScript)

Source: https://developers.cloudflare.com/workers/static-assets/direct-upload

This example demonstrates how to upload static assets to Cloudflare Workers using TypeScript. It covers the process of registering a manifest, uploading files, and deploying the Worker with the assets.

```TypeScript
import { Worker } from "@cloudflare/workers-types";

// Example usage (conceptual, actual implementation would involve API calls)
async function uploadAssets(worker: Worker, assets: File[]) {
  // 1. Register manifest
  const manifestResponse = await fetch("/accounts/{accountId}/workers/scripts/{scriptName}/upload", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${process.env.CLOUDFLARE_API_TOKEN}`
    },
    body: JSON.stringify({
      files: assets.map(asset => ({
        hash: "some_hash", // Calculate file hash
        size: asset.size,
        name: asset.name
      }))
    })
  });
  const manifestData = await manifestResponse.json();
  const uploadToken = manifestData.jwt;

  // 2. Upload assets (multipart/form-data)
  const formData = new FormData();
  assets.forEach(asset => {
    formData.append(asset.name, asset);
  });

  await fetch(`${manifestData.upload_url}?jwt=${uploadToken}&base64=true`, {
    method: "POST",
    body: formData
  });

  // 3. Deploy Worker with assets
  const deployResponse = await fetch("/accounts/{accountId}/workers/scripts/{scriptName}", {
    method: "PUT",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${process.env.CLOUDFLARE_API_TOKEN}`
    },
    body: JSON.stringify({
      script: "// Your Worker code",
      // completion_token: manifestData.jwt, // Use completion token if available
      assets: {
        // asset_management: "legacy", // or "v2"
        // include_all: true
      }
    })
  });
  console.log("Deployment successful:", await deployResponse.json());
}

```

--------------------------------

### Deploying and Monitoring Worker Startup Time with Wrangler

Source: https://developers.cloudflare.com/workers/platform/limits

This snippet demonstrates how to deploy a Cloudflare Worker using Wrangler and monitor its startup time. Wrangler outputs the `startup_time_ms` which can be used to identify performance bottlenecks.

```bash
npx wrangler@latest deploy
npx wrangler@latest versions upload
```

--------------------------------

### Create Angular Project with Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/angular

Use the `create-cloudflare` CLI (C3) to set up a new Angular project and deploy it to Cloudflare Workers with Workers Assets. This command initiates Angular's setup and offers instant deployment options.

```bash
npx create-cloudflare@latest angular
```

```bash
yarn create cloudflare angular
```

```bash
pnpm create cloudflare angular
```

--------------------------------

### Handle EventSource Events

Source: https://developers.cloudflare.com/workers/runtime-apis/eventsource

Provides examples of setting up event handlers for connection opening (`onopen`), receiving messages (`onmessage`), and handling errors (`onerror`) for the EventSource API.

```javascript
const eventSource = new EventSource("/events");

eventSource.onopen = (event) => {
  console.log("Connection opened");
};

eventSource.onmessage = (event) => {
  console.log("Message received:", event.data);
};

eventSource.onerror = (event) => {
  console.error("EventSource error:", event);
};
```

--------------------------------

### Install @upstash/redis with pnpm

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/upstash

This snippet shows how to install the Upstash Redis HTTP client using pnpm, which is required to connect to an Upstash Redis database from a Cloudflare Worker.

```bash
pnpm add @upstash/redis
```

--------------------------------

### Queues Management API

Source: https://developers.cloudflare.com/workers/wrangler/commands

Commands for creating, updating, deleting, listing, and getting information about queues.

```APIDOC
## POST /queues

### Description
Create a new queue.

### Method
POST

### Endpoint
/queues

### Parameters
#### Path Parameters
- **name** (string) - Required - The name of the queue to create.

#### Query Parameters
- **--delivery-delay-secs** (number) - Optional - How long a published message should be delayed for, in seconds. Must be a positive integer.
- **--message-retention-period-secs** (number) - Optional - How long a published message is retained in the Queue. Must be a positive integer between 60 and 1209600 (14 days). Defaults to 345600 (4 days).

### Request Example
```bash
wrangler queues create my-queue --delivery-delay-secs 60
```

### Response
#### Success Response (200)
- Queue creation confirmation.

#### Response Example
```json
{
  "success": true,
  "message": "Queue created successfully."
}
```

---

## PUT /queues/{name}

### Description
Update an existing queue.

### Method
PUT

### Endpoint
/queues/{name}

### Parameters
#### Path Parameters
- **name** (string) - Required - The name of the queue to update.

#### Query Parameters
- **--delivery-delay-secs** (number) - Optional - How long a published message should be delayed for, in seconds. Must be a positive integer.
- **--message-retention-period-secs** (number) - Optional - How long a published message is retained on the Queue. Must be a positive integer between 60 and 1209600 (14 days). Defaults to 345600 (4 days).

### Request Example
```bash
wrangler queues update my-queue --message-retention-period-secs 86400
```

### Response
#### Success Response (200)
- Queue update confirmation.

#### Response Example
```json
{
  "success": true,
  "message": "Queue updated successfully."
}
```

---

## DELETE /queues/{name}

### Description
Delete an existing queue.

### Method
DELETE

### Endpoint
/queues/{name}

### Parameters
#### Path Parameters
- **name** (string) - Required - The name of the queue to delete.

### Request Example
```bash
wrangler queues delete my-queue
```

### Response
#### Success Response (200)
- Queue deletion confirmation.

#### Response Example
```json
{
  "success": true,
  "message": "Queue deleted successfully."
}
```

---

## GET /queues

### Description
List all queues in the current account.

### Method
GET

### Endpoint
/queues

### Request Example
```bash
wrangler queues list
```

### Response
#### Success Response (200)
- **queues** (array) - A list of queue objects.

#### Response Example
```json
[
  {
    "name": "queue-1",
    "delivery_delay_secs": 0,
    "message_retention_period_secs": 345600
  },
  {
    "name": "queue-2",
    "delivery_delay_secs": 60,
    "message_retention_period_secs": 1209600
  }
]
```

---

## GET /queues/{name}

### Description
Get information on individual queues.

### Method
GET

### Endpoint
/queues/{name}

### Parameters
#### Path Parameters
- **name** (string) - Required - The name of the queue to inspect.

### Request Example
```bash
wrangler queues info my-queue
```

### Response
#### Success Response (200)
- **queue_info** (object) - Details of the specified queue.

#### Response Example
```json
{
  "name": "my-queue",
  "delivery_delay_secs": 0,
  "message_retention_period_secs": 345600,
  "created_at": "2023-01-01T12:00:00Z",
  "updated_at": "2023-01-01T12:00:00Z"
}
```

---

## Consumer Management API

### Description
Commands for managing queue consumer configurations.

### Method
(Not specified, likely POST/PUT/DELETE)

### Endpoint
/queues/consumers

### Parameters
(Details not provided in the source text)

### Request Example
(Not provided in the source text)

### Response
(Details not provided in the source text)
```

--------------------------------

### Create Fine-tune Job with File Upload

Source: https://developers.cloudflare.com/workers/tutorials/create-finetuned-chatgpt-ai-models-with-r2

This JavaScript code demonstrates how to initiate a fine-tune job by uploading a file. It makes a request to the `/files` endpoint with a `file` query parameter specifying the filename. The response typically includes an ID for the uploaded file.

```javascript
fetch('/files?file=your_uploaded_file.jsonl');
```

--------------------------------

### Install Langchain Packages for Cloudflare Workers

Source: https://developers.cloudflare.com/workers/languages/python/packages/langchain

This snippet shows the installation of essential Langchain packages required for building AI applications on the Cloudflare Workers runtime. These packages include the core Langchain library, the core components, and the OpenAI integration.

```bash
pip install langchain==0.1.8 langchain-core==0.1.25 langchain-openai==0.0.6
```

--------------------------------

### Cron Expression Examples

Source: https://developers.cloudflare.com/workers/configuration/cron-triggers

Cloudflare supports cron expressions with five fields, similar to Quartz scheduler syntax. These examples demonstrate common time intervals for setting up Cron Triggers.

```text
* * * * *
  At every minute

*/30 * * * *
  At every 30th minute

45 * * * *
  On the 45th minute of every hour

0 17 * * sun or 0 17 * * 1
  17:00 (UTC) on Sunday

10 7 * * mon-fri or 10 7 * * 2-6
  07:10 (UTC) on weekdays

0 15 1 * *
  15:00 (UTC) on first day of the month

0 18 * * 6L or 0 18 * * friL
  18:00 (UTC) on the last Friday of the month

59 23 LW * *
  23:59 (UTC) on the last weekday of the month
```

--------------------------------

### Calculate Worker Costs (Example 2 - Static Assets)

Source: https://developers.cloudflare.com/workers/platform/pricing

This example shows the cost for a project where 80% of requests serve static assets (free and unlimited) and the remaining invoke dynamic Worker code, with an average of 7ms CPU time per dynamic request.

```text
Subscription: $5.00
Requests to static assets: $0
Requests to Worker: $0
CPU time: $0
Total: $5.00
```

--------------------------------

### Update Wrangler with npm

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/install-update

Updates the Wrangler CLI tool to the latest version using npm.

```bash
npm update -g @cloudflare/wrangler
```

--------------------------------

### TypeScript Example with getPlatformProxy and Type Hinting

Source: https://developers.cloudflare.com/workers/wrangler/api

Demonstrates how to use `getPlatformProxy` with TypeScript generics to provide type safety for the `env` object, avoiding `unknown` values.

```typescript
interface MyEnv {
  MY_VARIABLE: string;
}

import { getPlatformProxy } from 'wrangler';

const { env } = await getPlatformProxy<MyEnv>();

console.log(`MY_VARIABLE = ${env.MY_VARIABLE}`);
```

--------------------------------

### Scoped Prompt Example (Chat Session)

Source: https://developers.cloudflare.com/workers/-ai/features/prompting

Illustrates a chat session using multiple iterations between user and assistant roles within a scoped prompt. This showcases how to maintain context and build a conversational flow for more complex interactions.

```json
[
  {
    "role": "user",
    "content": "Who won the world series in 2020?"
  },
  {
    "role": "assistant",
    "content": "The Los Angeles Dodgers won the World Series in 2020."
  },
  {
    "role": "user",
    "content": "Where was it played?"
  }
]
```

--------------------------------

### Example Worker Script with Bindings

Source: https://developers.cloudflare.com/workers/configuration/multipart-upload-metadata

A sample JavaScript Worker script demonstrating how to access a KV namespace binding configured in the metadata. This script fetches a value from the 'MY_KV_NAMESPACE' and returns it.

```javascript
export default {
  async fetch(request, env, ctx) {
    const value = await env.MY_KV_NAMESPACE.get("my-key");
    return new Response(value);
  }
}
```

--------------------------------

### Unscoped Prompt Example (Mistral Chat Template)

Source: https://developers.cloudflare.com/workers/-ai/features/prompting

Shows how to use an unscoped prompt with the `raw` parameter to manually construct a model's chat template, specifically for a Mistral model. This allows for direct control over the prompt format when needed.

```json
{
  "prompt": "<s>[INST] What is the capital of France? [/INST]",
  "raw": true
}
```

--------------------------------

### Install @upstash/redis with yarn

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/upstash

This snippet shows how to install the Upstash Redis HTTP client using yarn, which is required to connect to an Upstash Redis database from a Cloudflare Worker.

```bash
yarn add @upstash/redis
```

--------------------------------

### Wrangler Configuration for Static Assets

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/docusaurus

Example Wrangler configuration files for deploying a pre-rendered Docusaurus static site. The `assets` field specifies the directory containing the static files to be served.

```json
{
  "main": "./workers-site/index.js",
  "compatibility_date": "2023-10-26",
  "assets": {
    "include": "./build",
    "dir": "./build",
    "prefix": "/"
  }
}
```

```toml
[site]
  bucket = "_static"
  entry-point = "workers-site"

[site.assets]
  include = "build"
  dir = "build"
  prefix = "/"

[dev]
  entry-point = "workers-site"
```

--------------------------------

### Worker Log Tailing API

Source: https://developers.cloudflare.com/workers/wrangler/commands

Starts a log tailing session for a Cloudflare Worker to view live console and exception logs.

```APIDOC
## GET /api/workers/{WORKER_NAME}/tail

### Description
Starts a live feed of console and exception logs for a specified Worker. Supports filtering by various criteria to manage log volume.

### Method
GET

### Endpoint
`/api/workers/{WORKER_NAME}/tail`

### Parameters
#### Path Parameters
- **WORKER_NAME** (string) - Required - The name or route of the Worker to tail logs for.

#### Query Parameters
- **format** (string) - Optional - The format of log entries. Allowed values: "json", "pretty".
- **status** (string) - Optional - Filter logs by invocation status. Allowed values: "ok", "error", "canceled".
- **header** (string) - Optional - Filter logs by HTTP header.
- **method** (string) - Optional - Filter logs by HTTP method.
- **sampling-rate** (number) - Optional - Adds a percentage of requests to the log sampling rate (0-100).
- **search** (string) - Optional - Filter logs by a text match in console.log messages.
- **ip** (string) - Optional - Filter logs by the originating IP address. Use "self" to filter for your own IP.
- **version-id** (string) - Optional - Filter logs by Worker version.

### Request Example
```bash
curl -X GET https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/workers/scripts/{WORKER_NAME}/tail?format=json&status=error
```

### Response
#### Success Response (200)
- **logs** (array) - An array of log objects, each containing details about a request.
  - **timestamp** (string) - The time the log entry was generated.
  - **message** (string) - The log message content.
  - **level** (string) - The log level (e.g., 'log', 'error').
  - **request_id** (string) - The unique identifier for the request.
  - **status** (string) - The status of the worker invocation.

#### Response Example
```json
{
  "logs": [
    {
      "timestamp": "2023-10-27T10:30:00Z",
      "message": "An error occurred during processing.",
      "level": "error",
      "request_id": "req-abc123xyz",
      "status": "error"
    }
  ]
}
```
```

--------------------------------

### Minimal Hono Application

Source: https://developers.cloudflare.com/workers/tutorials/build-a-slackbot

A basic Hono application that handles GET requests to the root path ('/') by returning 'Hello Hono!'. It also includes a 404 Not Found response for any other path or method.

```TypeScript
import { Hono } from 'hono'

export const app = new Hono()

app.get('/', (c) => {
  return c.text('Hello Hono!')
})

export default app
```

--------------------------------

### Using unstable_startWorker() with node:test

Source: https://developers.cloudflare.com/workers/testing/unstable_startworker

Demonstrates how to use Wrangler's unstable_startWorker() API with the node:test framework. This example showcases the integration of Wrangler's dev server internals into a testing environment.

```JavaScript
import { unstable_startWorker } from "wrangler";
import test from "node:test";
import assert from "node:assert";

test("basic worker test", async (t) => {
  const worker = await unstable_startWorker({
    // Optional: Specify a wrangler.toml file
    // configPath: "./wrangler.toml",
  });

  const res = await worker.fetch("http://localhost:8787/");
  const text = await res.text();

  assert.strictEqual(text, "Hello World!");

  // Clean up the worker
  await worker.stop();
});

```

--------------------------------

### R2 Bindings: Range Header Support for `get`

Source: https://developers.cloudflare.com/workers/platform/changelog/historical-changelog

Allows using a `Headers` object with the `range` header for range requests within `R2GetOptions` for the `get` R2 binding.

```JavaScript
// A `Headers` object with the `range` header can now be used for range within `R2GetOptions` for the `get` R2 binding.
```

--------------------------------

### Text Generation with gemma-7b-it-lora in Python

Source: https://developers.cloudflare.com/workers/-ai/models/gemma-7b-it-lora

Demonstrates how to interact with the gemma-7b-it-lora model using Python. This client-side example shows how to send a prompt and receive a text response.

```python
import os
import requests

api_url = "https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/google/gemma-7b-it-lora"
api_token = os.environ.get("CLOUDFLARE_API_TOKEN")

headers = {
    "Authorization": f"Bearer {api_token}",
    "Content-Type": "application/json",
}

prompt = "Explain the concept of recursion in programming."

data = {
    "prompt": prompt,
    "stream": False
}

response = requests.post(api_url, headers=headers, json=data)

if response.status_code == 200:
    result = response.json()
    print(result.get("result", {}).get("response"))
else:
    print(f"Error: {response.status_code} - {response.text}")
```

--------------------------------

### Install mysql2 Driver for Node.js Compatibility

Source: https://developers.cloudflare.com/workers/tutorials/mysql

Install the `mysql2` package, a popular MySQL client for Node.js, to interact with your MySQL database from a Cloudflare Worker. This requires Node.js compatibility to be enabled in your Worker project.

```bash
npm install mysql2
yarn add mysql2
pnpm add mysql2
```

--------------------------------

### Logpush API Example for ScriptVersion

Source: https://developers.cloudflare.com/workers/configuration/versions-and-deployments/gradual-deployments

This is a sample API call to the Logpush API for adding the `ScriptVersion` object. This object is crucial for attributing Worker invocations to a specific version for better observability during gradual deployments. The structure of `ScriptVersion` is detailed separately.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/zones/<ZONE_ID>/logpush/datasets/workers-requests/subscriptions" \
     -H "Authorization: Bearer <API_TOKEN>" \
     -H "Content-Type: application/json" \
     --data '{ "destination": "<LOGPUSH_DESTINATION>", "subவதற்கான": { "fields": ["ScriptVersion", "RequestMethod", "Status"], "redact": [] }, "enabled": true }'
```

--------------------------------

### OpenNext Configuration

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/nextjs

Example content for an OpenNext configuration file (open-next.config.ts).

```typescript
import { defineConfig } from '@open-next/core';

export default defineConfig({
  // Your OpenNext configuration options here
  // For example:
  // assetsDir: '.open-next/assets',
  // buildTarget: 'workers',
});

```

--------------------------------

### Install Cloudflare Vite Plugin

Source: https://developers.cloudflare.com/workers/vite-plugin

This snippet shows how to install the Cloudflare Vite plugin using npm or yarn. This plugin is essential for integrating Vite with the Cloudflare Workers runtime, enabling features like direct access to runtime APIs and optimized front-end builds.

```bash
npm install --save-dev @cloudflare/vite-plugin-cloudflare-workers

# or

yarn add --dev @cloudflare/vite-plugin-cloudflare-workers
```

--------------------------------

### Python Client for Mistral-7B-Instruct-v0.2 LLM

Source: https://developers.cloudflare.com/workers/-ai/models/mistral-7b-instruct-v0

This Python code illustrates how to interact with the Mistral-7B-Instruct-v0.2 LLM using a hypothetical Python client. It sends a prompt and expects a text response. Ensure you have the necessary libraries installed and replace placeholders with your actual account ID and API token.

```python
import requests

api_url = "https://api.cloudflare.com/client/v4/accounts/{YOUR_ACCOUNT_ID}/ai/run/@cf/mistral/mistral-7b-instruct-v0.2-lora"
api_token = "{YOUR_API_TOKEN}"

prompt = "Explain the concept of quantum entanglement in simple terms."

headers = {
    "Authorization": f"Bearer {api_token}",
    "Content-Type": "application/json"
}

data = {
    "prompt": prompt,
    "stream": False
}

response = requests.post(api_url, headers=headers, json=data)

if response.status_code == 200:
    result = response.json()
    print(result['result']['response'])
else:
    print(f"Error: {response.status_code}")
    print(response.text)
```

--------------------------------

### Configure Wrangler for Service Bindings

Source: https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/rpc

Example `wrangler.toml` configuration for setting up service bindings, specifying the Worker name and its entrypoint.

```toml
[env.bindings]
WORKER_B = {
  service = "worker-b",
  entrypoint = "// Default entrypoint"
}
```

--------------------------------

### Run Inference with LoRA using Workers AI SDK

Source: https://developers.cloudflare.com/workers/-ai/fine-tunes/loras

Example of how to make inference requests and apply a LoRA adapter using the Workers AI SDK. You need your model and finetune name or ID.

```javascript
import { Ai } from "@cloudflare/ai";

const ai = new Ai(env.AI);
const model = "@cf/meta/llama-2-7b-chat-fp16";
const finetune = "<your-finetune-name-or-id>";

const response = await ai.run({
  model: model,
  finetune: finetune,
  messages: [
    { role: "user", content: "Hello!" },
  ],
  raw: true // Optionally use raw mode with a specific template
});
```

--------------------------------

### Worker - Streaming Usage Example

Source: https://developers.cloudflare.com/workers/-ai/models/deepseek-math-7b-instruct

This snippet demonstrates how to use the DeepSeek-Math-7B-Instruct model with Cloudflare Workers for streaming text generation. It outlines the basic structure for making a request to the model endpoint.

```javascript
export default {
  async fetch(request, env, ctx) {
    const url = new URL(request.url);
    const prompt = url.searchParams.get('prompt');

    if (!prompt) {
      return new Response('Please provide a prompt via ?prompt=your_prompt', {
        status: 400
      });
    }

    const res = await fetch('https://api.deepseek.com/v1/chat/completions',
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${env.DEEPSEEK_API_KEY}`
        },
        body: JSON.stringify({
          model: '@cf/deepseek-ai/deepseek-math-7b-instruct',
          messages: [
            { role: 'system', content: 'You are a helpful math assistant.' },
            { role: 'user', content: prompt }
          ],
          stream: true
        })
      }
    );

    return new Response(res.body, {
      headers: {
        'Content-Type': 'text/plain; charset=utf-8'
      }
    });
  }
};
```

--------------------------------

### Batch Query Contexts with baai/bge-m3 using Python

Source: https://developers.cloudflare.com/workers/-ai/models/bge-m3

This Python example demonstrates how to submit multiple embedding requests, including query-context pairs and single text embeddings, in a single batch using the baai/bge-m3 model. It shows the structure for the `input` parameter, which accepts a list of request objects. The response will contain `request_id`s for asynchronous retrieval.

```python
import os

from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

response = client.embeddings.create(
    model="@cf/baai/bge-m3",
    input=[
        {
            "query": "What is the capital of France?",
            "contexts": [
                "Paris is the capital of France.",
                "The Eiffel Tower is in Paris."
            ]
        },
        {
            "text": "Another piece of text to embed."
        }
    ]
)
```

--------------------------------

### Render Websites with Browser Rendering API

Source: https://developers.cloudflare.com/workers/prompt

This example demonstrates using the Browser Rendering API within a Cloudflare Worker to act as a headless browser. It shows how to launch Puppeteer, navigate to a URL, and extract page content and text from specific elements.

```typescript
import puppeteer from "@cloudflare/puppeteer";

interface Env {
  BROWSER_RENDERING: Fetcher;
}

export default {
  async fetch(request, env): Promise<Response> {
    const { searchParams } = new URL(request.url);
    let url = searchParams.get("url");

    if (url) {
      url = new URL(url).toString(); // normalize
      const browser = await puppeteer.launch(env.MYBROWSER);
      const page = await browser.newPage();
      await page.goto(url);
      // Parse the page content
      const content = await page.content();
      // Find text within the page content
      const text = await page.$eval("body", (el) => el.textContent);
      // Do something with the text
      // e.g. log it to the console, write it to KV, or store it in a database.

```

--------------------------------

### Using `unstable_dev()` for Wrangler Configuration

Source: https://developers.cloudflare.com/workers/testing/miniflare/migrations/from-v2

When migrating from Miniflare v2, the `wranglerConfigPath` and `wranglerConfigEnv` options are no longer supported. Instead, you should use the `unstable_dev()` API to programmatically start a Worker based on Wrangler configuration.

```TypeScript
import { unstable_dev } from 'wrangler';

// Example usage:
unstable_dev({
  // Wrangler configuration options here
});

```

--------------------------------

### Fetching Resources with fetch()

Source: https://developers.cloudflare.com/workers/runtime-apis/web-standards

The fetch() global function starts the process of fetching a resource from the network. It returns a Promise that resolves to the Response to that request, whether it is successful or not.

```JavaScript
async function fetchData(url) {
  try {
    const response = await fetch(url);
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    const data = await response.json();
    console.log(data);
  } catch (error) {
    console.error('Error fetching data:', error);
  }
}

fetchData('https://api.example.com/data');
```

--------------------------------

### Fill-in-the-Middle Code Completion with DeepSeek Coder

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/explore-code-generation-using-deepseek-coder-models

This example showcases the fill-in-the-middle capability of DeepSeek Coder, where the model completes existing code based on context provided with special placeholder tokens. Ensure correct copying of these tokens to maintain functionality.

```python
import numpy as np

def calculate_mean(data):
    """Calculates the mean of a list of numbers."""
    <｜fim_middle｜>
    return np.mean(data)
<｜fim_suffix｜>
```

--------------------------------

### Update Wrangler with Cargo

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/install-update

Updates the Wrangler CLI tool to the latest version using Cargo.

```bash
cargo install --force wrangler
```

--------------------------------

### Start HTTP Server for Worker Testing with Wrangler

Source: https://developers.cloudflare.com/workers/wrangler/api

The `unstable_dev` API starts an HTTP server for testing your Worker. It returns a `fetch` function to invoke the Worker and a `stop` function to shut down the server. By default, it runs integration tests locally, but can be configured for e2e tests against a preview Worker by setting `local: false`.

```javascript
import { unstable_dev } from 'wrangler';

// Example usage within a testing framework (e.g., jest)
describe('My Worker', () => {
  let worker;

  beforeAll(async () => {
    worker = await unstable_dev({
      // path to your worker script
      script: './src/index.js',
      // optional configuration options
      options: {
        // disable experimental warning
        experimental: {
          disableExperimentalWarning: true
        }
      }
    });
  });

  afterAll(async () => {
    await worker.stop();
  });

  test('should handle requests', async () => {
    const response = await worker.fetch('/');
    expect(response.status).toBe(200);
    const text = await response.text();
    expect(text).toContain('Hello Worker!');
  });
});
```

```typescript
import { unstable_dev } from 'wrangler';

// Example usage within a testing framework (e.g., vitest)

describe('My Worker', async () => {
  let worker;

  beforeAll(async () => {
    worker = await unstable_dev({
      script: './src/index.ts',
      options: {
        experimental: {
          disableExperimentalWarning: true
        }
      }
    });
  });

  afterAll(async () => {
    await worker.stop();
  });

  it('should respond correctly', async () => {
    const response = await worker.fetch('/test');
    expect(response.status).toBe(200);
  });
});
```

--------------------------------

### Create PlanetScale 'products' Table

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/planetscale

SQL query to create a 'products' table in your PlanetScale database with specified columns for product information.

```sql
CREATE TABLE products (
  id INT PRIMARY KEY AUTO_INCREMENT,
  name VARCHAR(255) NOT NULL,
  description TEXT,
  price DECIMAL(10, 2),
  category VARCHAR(100)
);
```

--------------------------------

### Develop Next.js Locally

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/nextjs

Start a local development server for your Next.js project. This command utilizes the Next.js development server for a fast, hot-reloading developer experience.

```bash
npm run dev
```

```bash
yarn dev
```

```bash
pnpm dev
```

--------------------------------

### Update src/index.ts with Prisma integration and data handling

Source: https://developers.cloudflare.com/workers/tutorials/using-prisma-postgres-with-workers

Replaces the default `src/index.ts` content with code that initializes Prisma, handles POST requests to create users, and GET requests to count users. It demonstrates database interaction within a Cloudflare Worker.

```typescript
import {
	PrismaClient
} from '@prisma/client';


export interface Env {
	DATABASE_URL: string;
}


const prisma = new PrismaClient({
	datasourceUrl: (globalThis as any).env.DATABASE_URL
});


export default {
	async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
		if (request.method === 'POST') {
			const {
				name,
				email
			} = await request.json();
			await prisma.user.create({
				data: {
					name,
				email
				}
			});
			return new Response('User created successfully');
		}

		const users = await prisma.user.findMany();
		return new Response(`Total users: ${users.length}`);
	}
};

```

--------------------------------

### Create Cloudflare Worker Project with pnpm

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/llama-vision-tutorial

Use the `create-cloudflare` CLI (C3) to initialize a new Cloudflare Worker project using pnpm. This command sets up a basic 'Hello World' Worker project, which can then be customized for specific functionalities.

```bash
pnpm create cloudflare llama-vision-tutorial
```

--------------------------------

### Manage Workflows with Cloudflare Workers

Source: https://developers.cloudflare.com/workers/prompt

This example demonstrates how to define and manage workflows using Cloudflare Workers. It includes spawning new workflow instances, retrieving their status, and passing data to them. The code utilizes the `MY_WORKFLOW` binding and `crypto.randomUUID` for instance IDs.

```typescript
export default {
async fetch(req: Request, env: Env): Promise<Response> {
let url = new URL(req.url);

    if (url.pathname.startsWith('/favicon')) {
      return Response.json({}, { status: 404 });
    }

    // Get the status of an existing instance, if provided
    let id = url.searchParams.get('instanceId');
    if (id) {
      let instance = await env.MY_WORKFLOW.get(id);
      return Response.json({
        status: await instance.status(),
      });
    }

    const data = await req.json()

    // Spawn a new instance and return the ID and status
    let instance = await env.MY_WORKFLOW.create({
      // Define an ID for the Workflow instance
      id: crypto.randomUUID(),
       // Pass data to the Workflow instance
      // Available on the WorkflowEvent
       params: data,
    });

    return Response.json({
      id: instance.id,
      details: await instance.status(),
    });

},
};

```

--------------------------------

### Generate Text using OpenChat-3.5-0106 with Python

Source: https://developers.cloudflare.com/workers/-ai/models/openchat-3

Demonstrates how to make a request to the OpenChat-3.5-0106 model using Python. This example assumes you have the necessary Cloudflare API credentials configured.

```python
import requests

api_url = "https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/openchat/openchat-3.5-0106"
api_token = "{API_TOKEN}"

prompt = "Explain the concept of quantum computing."

headers = {
    "Authorization": f"Bearer {api_token}",
    "Content-Type": "application/json"
}

data = {
    "prompt": prompt
}

response = requests.post(api_url, headers=headers, json=data)

if response.status_code == 200:
    print(response.json())
else:
    print(f"Error: {response.status_code}")
    print(response.text)
```

--------------------------------

### Call Reasoning Model with OpenAI API

Source: https://developers.cloudflare.com/workers/prompt

Shows how to integrate with the OpenAI API to call a reasoning model. It includes defining interfaces for prompts and history, querying a SQL database for user history, constructing prompts, making the API call, and storing the response in the database.

```typescript
  async callReasoningModel(prompt: Prompt) {
  	interface Prompt {
   		userId: string;
   		user: string;
   		system: string;
   		metadata: Record<string, string>;
		}

		interface History {
			timestamp: Date;
			entry: string;
		}

		let result = this.sql<History>`SELECT * FROM history WHERE user = ${prompt.userId} ORDER BY timestamp DESC LIMIT 1000`;
		let context = [];
		for await (const row of result) {
			context.push(row.entry);
		}

		const client = new OpenAI({
			apiKey: this.env.OPENAI_API_KEY,
		});

		// Combine user history with the current prompt
		const systemPrompt = prompt.system || 'You are a helpful assistant.';
		const userPrompt = `${prompt.user}\n\nUser history:\n${context.join('\n')}`;

		try {
			const completion = await client.chat.completions.create({
				model: this.env.MODEL || 'o3-mini',
				messages: [
					{ role: 'system', content: systemPrompt },
					{ role: 'user', content: userPrompt },
				],
				temperature: 0.7,
				max_tokens: 1000,
			});

			// Store the response in history
			this
				.sql`INSERT INTO history (timestamp, user, entry) VALUES (${new Date()}, ${prompt.userId}, ${completion.choices[0].message.content})`;

			return completion.choices[0].message.content;
		} catch (error) {
			console.error('Error calling reasoning model:', error);
			throw error;
		}
	}
```

--------------------------------

### Python Text Generation with llama-2-7b-chat-int8

Source: https://developers.cloudflare.com/workers/-ai/models/llama-2-7b-chat-int8

Python code snippet demonstrating how to interact with the llama-2-7b-chat-int8 model. This example assumes the necessary Cloudflare SDK or API client is configured.

```python
from cloudflare.ai import Client

client = Client()
prompt = "Summarize the main benefits of using AI in customer service."

response = client.run(
    "@cf/meta/llama-2-7b-chat-int8",
    { "prompt": prompt }
)

print(response)

```

--------------------------------

### Cloudflare Workers R2 Bindings: Error Handling and get() Behavior

Source: https://developers.cloudflare.com/workers/platform/changelog/historical-changelog

Improvements to R2 bindings error handling. The `get()` method now throws an exception for non-existent keys instead of returning null. `R2Error` is temporarily removed.

```JavaScript
try {
  const value = await env.MY_BUCKET.get("non-existent-key");
} catch (e) {
  console.error("Error getting key:", e);
}
```

--------------------------------

### Create Airtable-Form-Handler Worker Project (npm)

Source: https://developers.cloudflare.com/workers/tutorials/handle-form-submissions-with-airtable

Initializes a new Cloudflare Worker project named 'airtable-form-handler' using npm. It sets up a basic 'Hello World' Worker template with JavaScript and git version control, but defers deployment.

```bash
npm create cloudflare@latest
# For setup, select the following options:
# - What would you like to start with? > Hello World example
# - Which template would you like to use? > Worker only
# - Which language do you want to use? > JavaScript
# - Do you want to use git for version control? > Yes
# - Do you want to deploy your application? > No

cd airtable-form-handler
```

--------------------------------

### Query Turso Database in Cloudflare Worker

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/turso

Example of how to query a Turso database from a Cloudflare Worker using the libSQL client library. It demonstrates importing the client, defining environment variables, and executing a SQL query.

```javascript
import { createClient } from "@libsql/client/web";

export default {
  async fetch(request, env, ctx) {
    const client = createClient({
      url: env.TURSO_DATABASE_URL,
      authToken: env.TURSO_AUTH_TOKEN,
    });

    const result = await client.execute("SELECT * FROM elements");

    return Response.json(result);
  },
};
```

--------------------------------

### Dynamic Worker Loader API Reference

Source: https://developers.cloudflare.com/workers/runtime-apis/bindings/worker-loader

Reference for the Dynamic Worker Loader binding, including its `get` method and associated types.

```APIDOC
## Worker Loader Binding

### Description
A Worker Loader binding allows your Worker to create additional isolates that load arbitrary code on-demand.

### Method
`get(id: string, getCodeCallback: () => Promise<WorkerCode>): WorkerStub`

### Endpoint
N/A (This is a binding method, not a direct HTTP endpoint)

### Parameters
#### Path Parameters
None

#### Query Parameters
None

#### Request Body
None

### Request Example
```json
{
  "id": "my-dynamic-worker-id",
  "getCodeCallback": async () => {
    // Logic to fetch worker code, e.g., from storage
    return {
      "compatibilityDate": "2023-01-01",
      "mainModule": "index.js",
      "modules": {
        "index.js": "export default { fetch() { return new Response('Hello from dynamic worker!'); } }"
      }
    };
  }
}
```

### Response
#### Success Response (WorkerStub)
- **WorkerStub** - A stub object that may be used to invoke the loaded Worker. Requests made to the stub will wait for the Worker to load before being delivered.

#### Response Example
```json
{
  "message": "WorkerStub object returned. Invocation will await loading."
}
```

## WorkerCode Type

### Description
Represents the code and configuration for a Worker to be loaded by the Worker Loader.

### Fields
#### `compatibilityDate` (string) - Required
The compatibility date for the Worker. This has the same meaning as the `compatibility_date` setting in a Wrangler config file.

#### `compatibilityFlags` (string[]) - Optional
An optional list of compatibility flags augmenting the compatibility date. This has the same meaning as the `compatibility_flags` setting in a Wrangler config file.

#### `allowExperimental` (boolean) - Optional
If true, then experimental compatibility flags will be permitted in `compatibilityFlags`. In order to set this, the worker calling the loader must itself have the compatibility flag "experimental" set. Experimental flags cannot be enabled in production.

#### `mainModule` (string) - Required
The name of the Worker's main module. This must be one of the modules listed in `modules`.

### Example
```json
{
  "compatibilityDate": "2023-01-01",
  "compatibilityFlags": ["fetch_retry_on_dns_error"],
  "allowExperimental": false,
  "mainModule": "index.js",
  "modules": {
    "index.js": "export default { fetch(request) { return fetch(request); } }",
    "utils.js": "export function helper() { return 'helper'; }"
  }
}
```
```

--------------------------------

### Create a new Cloudflare Workers project

Source: https://developers.cloudflare.com/workers/tutorials/build-a-jamstack-app

This snippet demonstrates how to create a new Cloudflare Workers project named 'todos' using the create-cloudflare CLI tool. It outlines the setup options for a 'Worker only' project using JavaScript.

```bash
npm create cloudflare@latest
# or
yarn create cloudflare
# or
pnpm create cloudflare
```

--------------------------------

### Running Inference with LoRA Adapters (SDK)

Source: https://developers.cloudflare.com/workers/-ai/features/fine-tunes/loras

Example of how to run inference requests using the Workers AI SDK, applying a specific LoRA adapter. You need the model and finetune name or ID. Consider using the appropriate chat template or setting `raw: true`.

```javascript
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: YOUR_CLOUDFLARE_API_KEY,
  baseURL: 'https://api.cloudflare.com/client/v4/accounts/<account_id>/ai/run/<model_name@finetune_name_or_id>'
});

async function main() {
  const stream = await openai.chat.completions.create({
    model: '<model_name@finetune_name_or_id>',
    messages: [
      { role: 'user', content: 'Explain the importance of low-rank adaptation.' },
    ],
    stream: true,
  });
  for await (const chunk of stream) {
    console.log(chunk.choices[0]?.delta?.content || '');
  }
}
main();
```

--------------------------------

### Dispatching Fetch Events with RequestInit in JavaScript

Source: https://developers.cloudflare.com/workers/testing/miniflare/core/fetch

Demonstrates how to use the `dispatchFetch` function to simulate a fetch event for testing a Cloudflare Worker. It shows how to provide a URL and `RequestInit` object, including custom headers and the `cf` object, to control the event's behavior.

```javascript
import { Miniflare } from 'miniflare';

const mf = new Miniflare({
    script: `
        export default {
            async fetch(request, env, ctx) {
                return new Response(request.url, {
                    headers: {
                        'x-custom-header': request.headers.get('x-custom-header'),
                        'cf-custom-header': request.headers.get('cf-custom-header'),
                    },
                });
            },
        };
    `
});

// Dispatch a fetch event with a URL and RequestInit
const response = await mf.dispatchFetch('http://example.com/', {
    method: 'POST',
    headers: {
        'x-custom-header': 'value',
        'cf': JSON.stringify({
            country: 'USA',
            colo: 'LAX',
        }),
    },
    body: 'hello world',
});

console.log(await response.text());
// Expected output: http://example.com/
console.log(response.headers.get('x-custom-header'));
// Expected output: value
console.log(response.headers.get('cf-custom-header'));
// Expected output: USA
```

--------------------------------

### curl: Generate Image - Command Line

Source: https://developers.cloudflare.com/workers/-ai/models/flux-1-schnell

Command-line example using curl to interact with the FLUX.1 model. This shows how to send a POST request with JSON payload containing the prompt and desired steps to the API endpoint.

```bash
curl -X POST "https://YOUR_ACCOUNT_ID.cloudflare.workers-ai.com/v1/run/@cf/black-forest-labs/flux-1-schnell" \
     -H "Authorization: Bearer YOUR_API_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{ 
       "prompt": "A futuristic cityscape at sunset", 
       "steps": 6 
     }'
```

--------------------------------

### Generate Text using OpenChat-3.5-0106 with cURL

Source: https://developers.cloudflare.com/workers/-ai/models/openchat-3

A command-line example using cURL to interact with the OpenChat-3.5-0106 model. This is useful for quick testing and integration into shell scripts.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/openchat/openchat-3.5-0106" \
     -H "Authorization: Bearer {API_TOKEN}" \
     -H "Content-Type: application/json" \
     -d '{"prompt": "Write a short poem about the ocean."}'
```

--------------------------------

### Wrangler Global Flags Example

Source: https://developers.cloudflare.com/workers/wrangler/commands

Demonstrates the usage of global flags with Wrangler commands. These flags control aspects like version display, working directory, configuration file path, environment selection, and experimental features.

```bash
wrangler --version
wrangler --cwd /path/to/project --config wrangler.toml --env production deploy
wrangler --experimental-remote-bindings deploy

```

--------------------------------

### Scaffold Next.js Project with C3 CLI

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/nextjs

Create a new Next.js project configured for Cloudflare Workers using the create-cloudflare CLI (C3). This command initiates Next.js setup and configures the project for Cloudflare deployment.

```bash
npm create cloudflare@latest -- --next
```

```bash
yarn create cloudflare --next
```

```bash
pnpm create cloudflare --next
```

--------------------------------

### Cache Everything with TTLs and Custom Keys (TypeScript)

Source: https://developers.cloudflare.com/workers/examples/cache-using-fetch

Demonstrates how to cache all resources and control their Time-To-Live (TTL) using origin headers. It also explains the concept of custom cache keys for consistent caching across different URLs.

```TypeScript
async function fetchAndCache(request: Request): Promise<Response> {
  const url = new URL(request.url);
  // Example: Custom cache key based on a specific query parameter
  const cacheKey = `${url.origin}${url.pathname}?id=${url.searchParams.get('id')}`;

  const cache = await caches.open('my-cache');
  let response = await cache.match(cacheKey);

  if (!response) {
    response = await fetch(request);
    // Example: Set cache control headers if needed
    // response.headers.set('Cache-Control', 'public, max-age=3600');
    await cache.put(cacheKey, response.clone());
  }
  return response;
}
```

--------------------------------

### Fetch Assets via Binding with Base URL

Source: https://developers.cloudflare.com/workers/vite-plugin/reference/static-assets

This example demonstrates how to fetch assets imported as URLs via the assets binding. It recommends using the request URL as the base because the binding's `fetch` method requires a full URL.

```javascript
export default {
  async fetch(request, env, ctx) {
    const url = new URL(request.url);
    const base = url.origin;

    // Assuming 'ASSETS' is the name of your assets binding
    const asset = await env.ASSETS.fetch(base + "/asset.png");
    return asset;
  },
};
```

--------------------------------

### cURL Text Generation with llama-2-7b-chat-int8

Source: https://developers.cloudflare.com/workers/-ai/models/llama-2-7b-chat-int8

Command-line interface example using cURL to send a request to the llama-2-7b-chat-int8 model. This demonstrates a basic API interaction for text generation.

```bash
curl https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/meta/llama-2-7b-chat-int8 \
     -X POST \
     -H "Authorization: Bearer {API_TOKEN}" \
     -H "Content-Type: application/json" \
     -d '{ "prompt": "Generate a tagline for a new coffee brand." }'

```

--------------------------------

### Start Local Development Server

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/react-router

Command to launch a local development server for your React Router application integrated with Cloudflare Workers. This allows for testing and debugging in an environment that closely mimics production.

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
```

--------------------------------

### Calculate Worker Costs (Example 3 - Cron Trigger)

Source: https://developers.cloudflare.com/workers/platform/pricing

This example calculates the cost for a Worker running on a Cron Trigger once an hour, processing data and generating a report, with specific request and CPU time per request values.

```text
Subscription: $5.00
Requests: $0.00
CPU time: ((180,000 ms of CPU time per request * 720 requests) - 30,000,000 included CPU ms) / 1,000,000 * $0.02 = $1.99
Total: $6.99
```

--------------------------------

### Wrangler Deploy with Environments

Source: https://developers.cloudflare.com/workers/ci-cd/builds/advanced-setups

This snippet shows how to deploy a Cloudflare Worker to specific environments using Wrangler. It includes commands for deploying to 'staging' and 'production' environments, and for uploading versions associated with these environments.

```bash
npx wrangler deploy --env staging
```

```bash
npx wrangler deploy --env production
```

```bash
npx wrangler versions upload --env staging
```

```bash
npx wrangler versions upload --env production
```

--------------------------------

### Basic 'Hello World' Worker code

Source: https://developers.cloudflare.com/workers/get-started/guide

This is a minimal 'Hello World!' Worker written in ES module syntax. It exports a default object with a `fetch` handler that returns a 'Hello World!' response.

```javascript
export default {
  async fetch(request, env, ctx) {
    return new Response("Hello World!");
  },
};
```

--------------------------------

### Calculate Worker Costs (Example 4 - High Traffic)

Source: https://developers.cloudflare.com/workers/platform/pricing

This example illustrates the cost for a high-traffic Worker serving 100 million requests per month with an average of 7ms CPU time per request.

```text
Subscription: $5.00
Requests: (100,000,000 requests - 10,000,000 included requests) / 1,000,000 * $0.30 = $27.00
CPU time: ((7 ms of CPU time per request * 100,000,000 requests) - 30,000,000 included CPU ms) / 1,000,000 * $0.02 = $13.40
Total: $45.40
```

--------------------------------

### Batch Embed Texts with baai/bge-m3 using Python

Source: https://developers.cloudflare.com/workers/-ai/models/bge-m3

This Python example demonstrates how to embed multiple texts in a single request using the baai/bge-m3 model. It shows how to structure the input as a list of strings. This approach is efficient for processing numerous text inputs simultaneously.

```python
import os

from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

response = client.embeddings.create(
    model="@cf/baai/bge-m3",
    input=["The quick brown fox", "jumps over the lazy dog"]
)
```

--------------------------------

### Curl Text Generation with Llama-2-7b-chat-hf-lora

Source: https://developers.cloudflare.com/workers/-ai/models/llama-2-7b-chat-hf-lora

Example demonstrating how to interact with the Llama-2-7b-chat-hf-lora model using curl from the command line. This is useful for quick testing and integration into shell scripts.

```bash
curl https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/meta-llama/llama-2-7b-chat-hf-lora \
     -X POST \
     -H "Authorization: Bearer YOUR_API_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"prompt": "What are the benefits of using renewable energy?"}'
```

--------------------------------

### Redirect with Wildcard (Splat)

Source: https://developers.cloudflare.com/workers/static-assets/redirects

This example demonstrates how to use a splat (`*`) to match any characters in the source path. The matched value can be referenced in the destination using `:splat`.

```plaintext
/blog/* /posts/:splat
```

--------------------------------

### Run Wrangler Dev with Environment Configuration

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/commands

This example illustrates using the '--env' flag with 'wrangler dev' to load specific environment configurations, enabling testing of different deployment settings locally.

```bash
wrangler dev --env production
```

--------------------------------

### Run Local Cloudflare Worker Development Server

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/build-a-retrieval-augmented-generation-ai

Starts a local development server for a Cloudflare Worker project using the Wrangler CLI. Enables hot-reloading for immediate feedback on code changes.

```bash
wrangler dev
```

--------------------------------

### Build Script for Pages Functions Migration

Source: https://developers.cloudflare.com/workers/prompts/pages-to-workers

An example `package.json` script that includes a build step for migrating Cloudflare Pages Functions to Workers. It first runs the framework's build command and then executes `wrangler pages functions build` to convert the functions.

```json
{
	"scripts": {
		"build": "your-framework-build && wrangler pages functions build --outdir=./dist/_worker.js/"
	}
}
```

--------------------------------

### Add Prisma migration scripts to package.json

Source: https://developers.cloudflare.com/workers/tutorials/using-prisma-postgres-with-workers

Defines helper scripts in your `package.json` to run Prisma database migrations. These scripts use `dotenv-cli` to load variables from `.dev.vars` and then execute Prisma commands.

```json
"scripts": {
    "migrate": "dotenv -e .dev.vars -- npx prisma migrate dev --name init",
    "generate": "dotenv -e .dev.vars -- npx prisma generate"
  }
```

--------------------------------

### Configure Wrangler file with project name

Source: https://developers.cloudflare.com/workers/tutorials/generate-youtube-thumbnails-with-workers-and-images

This example shows how to update the `wrangler.jsonc` or `wrangler.toml` file with your project's name. This is necessary for deploying your Cloudflare Worker with the correct name.

```JSON
{
  "name": "worker-to-text",
  "main": "./worker/worker.js",
  "compatibility_date": "2023-04-03"
}
```

--------------------------------

### Handle WebSocket Messages (Hono)

Source: https://developers.cloudflare.com/workers/examples/websockets

This example demonstrates how to handle incoming WebSocket messages within a Hono application, logging the received data.

```javascript
ws.onmessage((message) => {
  console.log(message.data);
});

```

--------------------------------

### Cloudflare Workers: Use fetch() handler

Source: https://developers.cloudflare.com/workers/-ai/features/function-calling/embedded/examples

Demonstrates how to use the fetch() handler in Cloudflare Workers to intercept and respond to incoming HTTP requests. This is a fundamental pattern for building serverless applications on Cloudflare's edge network.

```javascript
addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  return new Response('Hello worker!', {
    headers: {
      'content-type': 'text/plain',
    },
  })
}
```

--------------------------------

### Starting a New Worker Script

Source: https://developers.cloudflare.com/workers/static-assets/migration-guides/migrate-from-pages

You can initiate a new Cloudflare Worker project using JavaScript or TypeScript, leveraging Wrangler's features like bundling and TypeScript support.

```javascript
export default {
  async fetch(request, env, ctx) {
    return new Response("Hello World!");
  },
};

```

--------------------------------

### Example Usage of @cf/leonardo/phoenix-1.0 (Text-to-Image)

Source: https://developers.cloudflare.com/workers/-ai/changelog

A text-to-image model from Leonardo AI known for exceptional prompt adherence and coherent text generation in images. Available on Workers AI.

```javascript
// Example usage for @cf/leonardo/phoenix-1.0 (Text-to-Image)

const prompt = "A photorealistic image of a futuristic city skyline at sunset, highly detailed, cinematic lighting";

async function generateImagePhoenix1(prompt) {
  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/leonardo/phoenix-1.0", {
    method: "POST",
    headers: {
      "Authorization": "Bearer <YOUR_API_TOKEN>",
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      "prompt": prompt
    })
  });
  const data = await response.json();
  // The response will contain a URL to the generated image or the image data itself.
  return data.result.image_url; // The exact key might vary
}

generateImagePhoenix1(prompt).then(imageUrl => {
  console.log("Generated image URL:", imageUrl);
});

```

--------------------------------

### Query Contexts with baai/bge-m3 using Python

Source: https://developers.cloudflare.com/workers/-ai/models/bge-m3

This Python example demonstrates how to perform query-context embedding using the baai/bge-m3 model. It shows how to structure the request with a query string and a list of context objects, each containing text. The response will provide scores for each context's relevance to the query.

```python
import os

from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

response = client.embeddings.create(
    model="@cf/baai/bge-m3",
    input=[
        {
            "query": "What is the capital of France?",
            "contexts": [
                "Paris is the capital of France.",
                "The Eiffel Tower is in Paris."
            ]
        }
    ]
)
```

--------------------------------

### Direct Text Generation with Cloudflare Workers (Python)

Source: https://developers.cloudflare.com/workers/-ai/models/starling-lm-7b-beta

This example shows how to call the Starling-LM-7B-beta model from a Python script using Cloudflare Workers. It outlines the necessary steps to send a prompt and receive a complete text generation response.

```python
import requests
import os

# Ensure you have your Cloudflare API token and account ID set as environment variables
API_TOKEN = os.environ.get("CLOUDFLARE_API_TOKEN")
ACCOUNT_ID = os.environ.get("CLOUDFLARE_ACCOUNT_ID")

if not API_TOKEN or not ACCOUNT_ID:
    raise ValueError("CLOUDFLARE_API_TOKEN and CLOUDFLARE_ACCOUNT_ID must be set.")

API_URL = f"https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@hf/nexusflow/starling-lm-7b-beta"

def generate_text(prompt):
    headers = {
        "Authorization": f"Bearer {API_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {
        "prompt": prompt,
        "stream": False  # Set to False for non-streaming response
    }

    try:
        response = requests.post(API_URL, headers=headers, json=payload)
        response.raise_for_status()  # Raise an exception for bad status codes
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"Error during API call: {e}")
        return None

if __name__ == "__main__":
    user_prompt = "Once upon a time, in a land far, far away,"
    result = generate_text(user_prompt)

    if result and "result" in result:
        print("Generated Text:")
        print(result["result"])
    elif result:
        print("API Response:")
        print(result)
    else:
        print("Text generation failed.")
```

--------------------------------

### Develop with Development Cloudflare Environment

Source: https://developers.cloudflare.com/workers/vite-plugin/reference/cloudflare-environments

This command starts your Worker project in development mode, specifically targeting the 'development' Cloudflare environment. It uses the CLOUDFLARE_ENV environment variable to activate the development configuration.

```bash
CLOUDFLARE_ENV=development vite dev
```

--------------------------------

### KV Bulk Get

Source: https://developers.cloudflare.com/workers/wrangler/commands

Retrieves multiple key-value pairs from a Workers KV namespace in a batch.

```APIDOC
## `kv bulk get`

### Description
Gets multiple key-value pairs from a namespace.

### Method
`wrangler kv:bulk get` (or `kv bulk get`)

### Parameters
#### Command Options
- `--filename` (string) - Required - The file containing the keys to get.
- `--binding` (string) - Optional - The binding name to the namespace to get from.
- `--namespace-id` (string) - Optional - The id of the namespace to get from.
- `--preview` (boolean) - Optional - Interact with a preview namespace.
- `--local` (boolean) - Optional - Interact with local storage.
- `--remote` (boolean) - Optional - Interact with remote storage.
- `--persist-to` (string) - Optional - Directory for local persistence.

### Global Flags
- `--version` (boolean) - Alias: `--v` - Show version number.
- `--cwd` (string) - Run as if Wrangler was started in the specified directory instead of the current working directory.
- `--config` (string) - Alias: `--c` - Path to Wrangler configuration file.
- `--env` (string) - Alias: `--e` - Environment to use for operations, and for selecting .env and .dev.vars files.
- `--env-file` (string) - Path to an .env file to load - can be specified multiple times - values from earlier files are overridden by values in later files.
- `--experimental-remote-bindings` (boolean) - Aliases: `--x-remote-bindings` - Default: true - Experimental: Enable Remote Bindings.
- `--experimental-provision` (boolean) - Aliases: `--x-provision` - Experimental: Enable automatic resource provisioning.
```

--------------------------------

### Example `events` object structure for Tail Workers

Source: https://developers.cloudflare.com/workers/observability/tail-workers

This snippet illustrates the potential structure of the `events` object that a Tail Worker receives. It includes details about the request, response, logs, exceptions, and other execution-related information from the producer Worker.

```json
{
  "request": {
    "url": "https://example.com/",
    "method": "GET",
    "headers": {
      "CF-Request-ID": "...",
      "User-Agent": "..."
    }
  },
  "response": {
    "status": 200,
    "headers": {
      "Content-Type": "application/json"
    }
  },
  "logs": [
    "Log message 1",
    "Log message 2"
  ],
  "exceptions": [
    {
      "name": "Error",
      "message": "An example error occurred",
      "stack": "..."
    }
  ]
}
```

--------------------------------

### Static Site Configuration for Wrangler

Source: https://developers.cloudflare.com/workers/static-assets/migration-guides/netlify-to-workers

Configure your `wrangler.jsonc` or `wrangler.toml` file for deploying a static site to Cloudflare Workers. Ensure you replace placeholders like `<your-project-name>` and `<your-build-directory>` with your project's specific values.

```json
{
  "name": "<your-project-name>",
  "main": "worker/index.js",
  "compatibility_date": "2023-10-26",
  "build": {
    "dir": "<your-build-directory>"
  }
}
```

```toml
[project]
name = "<your-project-name>"

[build]
dir = "<your-build-directory>"

[compatibility_flags]
# For Wrangler v3, you need to specify a main entry point
# main = "worker/index.js"

```

--------------------------------

### Develop Angular Project Locally

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/angular

Start a local development server for your Angular project within the project directory. This allows you to preview your application during the development process.

```bash
npm run dev
```

```bash
yarn dev
```

```bash
pnpm dev
```

--------------------------------

### Create Cloudflare Worker Project with yarn

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/llama-vision-tutorial

Use the `create-cloudflare` CLI (C3) to initialize a new Cloudflare Worker project using yarn. This command sets up a basic 'Hello World' Worker project, which can then be customized for specific functionalities.

```bash
yarn create cloudflare llama-vision-tutorial
```

--------------------------------

### Uninstall Wrangler v1 (npm)

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/update-v1-to-v2

This command uninstalls Wrangler v1 if it was previously installed globally using npm.

```bash
npm uninstall -g wrangler
```

--------------------------------

### experimental_maybeStartOrUpdateProxySession API

Source: https://developers.cloudflare.com/workers/development-testing

A convenience function to simplify the process of starting or updating a remote proxy session.

```APIDOC
## experimental_maybeStartOrUpdateProxySession

### Description
This wrapper simplifies proxy session management. It takes configuration details and existing session information to either start a new proxy session, update an existing one, or determine if no session is needed.

### Method
(Not applicable, this is a utility function)

### Endpoint
(Not applicable, this is a utility function)

### Parameters
#### Path Parameters
(None)

#### Query Parameters
(None)

#### Request Body
- **configOrWorkerInfo** (object) - Required - Contains either:
  - **configPath** (string) - Path to a Wrangler configuration file.
  - **environment** (string) - Target environment for the configuration.
  - **workerName** (string) - Name of the Worker.
  - **bindings** (object) - Bindings the Worker is using.
- **currentSession** (object | null) - Optional - The current proxy session details. Can be `null` if no session exists.
- **authData** (object) - Optional - Authentication data for the remote proxy session.
  - **accountId** (string) - Required - Your Cloudflare account ID.
  - **apiToken** (string) - Required - Your Cloudflare API token.

### Request Example
```json
{
  "configOrWorkerInfo": {
    "configPath": "wrangler.toml",
    "environment": "dev"
  },
  "currentSession": null,
  "authData": {
    "accountId": "YOUR_ACCOUNT_ID",
    "apiToken": "YOUR_API_TOKEN"
  }
}
```

### Response
#### Success Response (Object returned or null)
- **proxySessionDetails** (object) - If a session is started or updated. Contains details about the proxy session.
- **null** - If no proxy session is needed.

#### Response Example
```json
{
  "proxySessionDetails": {
    "ready": "<Promise>",
    "dispose": "<Function>",
    "updateBindings": "<Function>",
    "remoteProxyConnectionString": "wrangler:remote-proxy:port=XXXX"
  }
}
```
```

--------------------------------

### Deploy Rust Worker project

Source: https://developers.cloudflare.com/workers/languages/rust

This command deploys your Rust-based Cloudflare Worker to a *.workers.dev subdomain or a configured Custom Domain. Wrangler will prompt for subdomain/domain setup if not already configured.

```bash
wrangler publish
```

--------------------------------

### D1 Starter Template with Sessions API

Source: https://developers.cloudflare.com/workers/get-started/quickstarts

A starter template for Cloudflare D1, leveraging the Sessions API for efficient read replication. This template is optimized for applications requiring high read throughput on D1 databases.

```Shell
npm create cloudflare@latest -- --template d1-starter-sessions-api-template
# or
yarn create cloudflare --template d1-starter-sessions-api-template
# or
pnpm create cloudflare --template d1-starter-sessions-api-template
```

--------------------------------

### Get Build Output Directory

Source: https://developers.cloudflare.com/workers/wrangler/deprecations

The `wrangler build` command is deprecated. To access the output from bundling your Worker, use `wrangler publish --outdir=path/to/output`.

```bash
wrangler publish --outdir=path/to/output
```

--------------------------------

### Example Worker Code for Memory Leak Analysis

Source: https://developers.cloudflare.com/workers/observability/dev-tools/memory-usage

This is an example of a JavaScript Worker code that might exhibit a memory leak. The leak is caused by repeatedly appending to a global string variable, leading to increased memory consumption over time.

```javascript
addEventListener("fetch", (event) => {
  event.respondWith(handleRequest(event.request));
});

let globalString = "";

async function handleRequest(request) {
  // Simulate appending to a string, potentially causing a leak
  globalString += "Requested at: " + new Date().toISOString() + "\n";

  return new Response(globalString, {
    headers: {
      "content-type": "text/plain",
    },
  });
}
```

--------------------------------

### Importing Bundled Modules in a Worker

Source: https://developers.cloudflare.com/workers/wrangler/configuration

Demonstrates how to import modules that have been bundled with a Cloudflare Worker. This example shows importing text and data modules.

```javascript
import data from "./data/config.json";
import markdown from "./README.md";

export default {
  async fetch(request, env, ctx) {
    console.log(data.message);
    console.log(markdown.substring(0, 50));
    return new Response("Modules imported successfully!");
  },
};
```

--------------------------------

### Configure Vite for Cloudflare

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/tanstack

Update your vite.config.ts file to ensure compatibility with Cloudflare Workers by setting the build target to 'cloudflare-module'.

```typescript
import { defineConfig } from 'vite';

export default defineConfig({
  build: {
    target: 'cloudflare-module',
  },
});
```

--------------------------------

### Generate TypeScript Types for Bindings

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/tanstack

Command to generate TypeScript types for your Cloudflare bindings based on your wrangler configuration. This ensures type safety when accessing bindings.

```bash
npm run cf-typegen
# or
yarn cf-typegen
# or
pnpm cf-typegen
```

--------------------------------

### Basic Cloudflare Worker Example (JavaScript)

Source: https://developers.cloudflare.com/workers/-ai/models

A simple Cloudflare Worker that responds to requests with a plain text message. This demonstrates the basic structure of a Worker script and how to handle incoming requests.

```javascript
addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  return new Response('Hello World!', {
    headers: {
      'content-type': 'text/plain',
    },
  })
}
```

--------------------------------

### Direct Text Generation with Cloudflare Workers (curl)

Source: https://developers.cloudflare.com/workers/-ai/models/starling-lm-7b-beta

This snippet provides a command-line example using curl to interact with the Starling-LM-7B-beta model via Cloudflare Workers. It shows how to send a POST request with a prompt and receive the generated text.

```bash
curl -X POST \
  https://api.cloudflare.com/client/v4/accounts/[ACCOUNT_ID]/ai/run/@hf/nexusflow/starling-lm-7b-beta \
  -H "Authorization: Bearer [YOUR_API_TOKEN]" \
  -H "Content-Type: application/json" \
  --data '{ 
    "prompt": "Explain the concept of quantum entanglement in simple terms.", 
    "stream": false 
  }'
```

--------------------------------

### Python: Text Generation with llama-3-8b-instruct-awq

Source: https://developers.cloudflare.com/workers/-ai/models/llama-3-8b-instruct-awq

This Python snippet demonstrates how to use the llama-3-8b-instruct-awq model for text generation. It requires the appropriate libraries for interacting with the Workers AI service. The function takes a prompt as input and returns the generated text.

```python
from workers_ai import Ai

# Assuming you have your Cloudflare API key and account ID set up
ai = Ai("YOUR_CLOUDFLARE_ACCOUNT_ID", "YOUR_CLOUDFLARE_API_KEY")

async def generate_text(prompt: str):
    response = await ai.run("@cf/meta/llama-3-8b-instruct-awq", {
        "prompt": prompt
    })
    return response['result']['text']

# Example usage:
# import asyncio
# async def main():
#     generated_text = await generate_text("What is the capital of France?")
#     print(generated_text)
# asyncio.run(main())
```

--------------------------------

### Check cf-placement Header

Source: https://developers.cloudflare.com/workers/configuration/smart-placement

This example demonstrates how to check the `cf-placement` header in a Cloudflare Worker to determine if Smart Placement was used and the location of the Worker execution. The header provides insights into routing decisions.

```javascript
addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  const placementHeader = request.headers.get('cf-placement');
  let message = 'Smart Placement status unknown.';

  if (placementHeader) {
    if (placementHeader.startsWith('remote-')) {
      const location = placementHeader.split('-')[1];
      message = `Request routed using Smart Placement to location: ${location}.`;
    } else if (placementHeader.startsWith('local-')) {
      const location = placementHeader.split('-')[1];
      message = `Request not routed using Smart Placement. Worker invoked in default location near ${location}.`;
    }
  }

  return new Response(message, {
    headers: {
      'content-type': 'text/plain',
      'cf-placement': placementHeader || 'not-present'
    }
  })
}
```

--------------------------------

### Example Usage of @cf/google/embeddinggemma-300m

Source: https://developers.cloudflare.com/workers/-ai/changelog

Introducing EmbeddingGemma from Google, a high-performance embedding model for its size, ideal for RAG and semantic search. Available on Workers AI.

```javascript
// Example usage for @cf/google/embeddinggemma-300m

const inputText = "This is a sample text for embedding.";

async function getEmbeddingGemmaEmbeddings(text) {
  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/google/embeddinggemma-300m", {
    method: "POST",
    headers: {
      "Authorization": "Bearer <YOUR_API_TOKEN>",
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      "text": text
    })
  });
  const data = await response.json();
  return data.result.embedding; // The exact key might vary
}

getEmbeddingGemmaEmbeddings(inputText).then(embedding => {
  console.log("EmbeddingGemma embedding:", embedding);
});

```

--------------------------------

### Wrangler KV Get Command Behavior Change

Source: https://developers.cloudflare.com/workers/wrangler/migration/update-v3-to-v4

This snippet illustrates the change in default behavior for the `wrangler kv get` command between Wrangler v3 and v4. In v3, it defaulted to remote queries, while v4 defaults to local queries, requiring the `--remote` flag for remote access.

```bash
# Previous Behavior (Wrangler v3):
wrangler kv get <key> # Queries remotely by default

# New Behavior (Wrangler v4):
wrangler kv get <key> # Queries locally by default
wrangler kv get <key> --remote # Queries remotely
```

--------------------------------

### Cloudflare Workers API Output Schema Example

Source: https://developers.cloudflare.com/workers/-ai/models/deepseek-r1-distill-qwen-32b

This JSON schema defines the output structure for the Cloudflare Workers API. It details the properties and types of data returned by the API.

```json
{
  "output": "object"
}
```

--------------------------------

### Execute AI Model

Source: https://developers.cloudflare.com/workers/-ai/get-started/rest-api

This endpoint allows you to run a specified AI model with your given prompt. You need to authenticate your request using your Account ID and API Token.

```APIDOC
## POST /accounts/{ACCOUNT_ID}/ai/run/{model}

### Description
Executes a specified AI model with a given prompt.

### Method
POST

### Endpoint
`/accounts/{ACCOUNT_ID}/ai/run/{model}`

### Parameters
#### Path Parameters
- **ACCOUNT_ID** (string) - Required - Your Cloudflare Account ID.
- **model** (string) - Required - The name of the AI model to run (e.g., `@cf/meta/llama-3.1-8b-instruct`).

#### Query Parameters
None.

#### Request Body
- **prompt** (string) - Required - The input prompt for the AI model.
- **stream** (boolean) - Optional - Whether to stream the response.

### Request Example
```json
{
  "prompt": "Hello, world!",
  "stream": false
}
```

### Response
#### Success Response (200)
- **response** (object) - The AI model's response.
  - **completion** (string) - The generated text completion.

#### Response Example
```json
{
  "completion": "This is a response from the AI model."
}
```
```

--------------------------------

### Configure Wrangler for Named Entrypoints

Source: https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/rpc

Example `wrangler.toml` configuration to bind to a specific named entrypoint ('AdminEntrypoint') of another Worker.

```toml
[env.bindings]
ADMIN_API = {
  service = "worker-b",
  entrypoint = "AdminEntrypoint"
}
```

--------------------------------

### Detach Header Example

Source: https://developers.cloudflare.com/workers/static-assets/headers

Demonstrates how to remove a default or previously applied header by prepending the header name with '! '.

```cloudflare-workers-headers
/remove-header
  ! X-Content-Type-Options
```

--------------------------------

### Mock Outbound Requests with `fetchMock`

Source: https://developers.cloudflare.com/workers/testing/vitest-integration/migration-guides/migrate-from-miniflare-2

The `fetchMock` helper from `cloudflare:test` replaces `getMiniflareFetchMock`. It is deactivated by default and resets at the start of each test run, requiring explicit activation before making `fetch` calls.

```javascript
import { fetchMock } from 'cloudflare:test';

// Activate fetchMock before making requests
fetchMock.activate();

// Mock a request
fetchMock.get('https://example.com', 'Mocked response');

const response = await fetch('https://example.com');
console.log(await response.text()); // Output: Mocked response

```

--------------------------------

### Uninstall Wrangler v1 (Cargo)

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/update-v1-to-v2

This command uninstalls Wrangler v1 if it was installed using Cargo.

```shell
cargo uninstall wrangler
```

--------------------------------

### Perform HTTPS GET Request with https.get

Source: https://developers.cloudflare.com/workers/runtime-apis/nodejs/https

The `https.get` method in Cloudflare Workers is a wrapper around the global `fetch` API, simplifying GET requests. It must be used within an exported fetch handler. Ensure requests are awaited properly using promises to prevent premature cancellation.

```javascript
import https from 'https';

export default {
  async fetch(request) {
    const url = 'https://example.com';
    return new Promise((resolve, reject) => {
      https.get(url, (res) => {
        let data = '';
        res.on('data', (chunk) => {
          data += chunk;
        });
        res.on('end', () => {
          resolve(new Response(data, { status: res.statusCode }));
        });
      }).on('error', (err) => {
        reject(err);
      });
    });
  }
};

```

--------------------------------

### Setting and Getting Environment Variables in Cloudflare Workers

Source: https://developers.cloudflare.com/workers/runtime-apis/nodejs/process

Demonstrates how to set and get environment variables within the Workers environment. Values set on `process.env` are coerced to strings and are globally persistent within the isolate and context. This is distinct from per-request environment variables available in `fetch` handlers.

```javascript
// Setting an environment variable
process.env.MY_VARIABLE = "my_value";

// Getting an environment variable
const myValue = process.env.MY_VARIABLE;
console.log(myValue); // Output: my_value

// Environment variables are strings
process.env.NUMBER_VARIABLE = 123;
console.log(typeof process.env.NUMBER_VARIABLE); // Output: string
```

--------------------------------

### Wrangler Configuration for Hyperdrive (TOML)

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase

Example of how to configure Hyperdrive binding in a Wrangler configuration file (`wrangler.toml`) to use the created Hyperdrive configuration within your Cloudflare Worker.

```toml
[env.production.hyperdrive]
name = "SUPABASE_HYPERDRIVE"
connectionString = "postgres://user:password@hostname:port/database"

[env.dev.hyperdrive]
name = "SUPABASE_HYPERDRIVE"
connectionString = "postgres://user:password@hostname:port/database"
```

--------------------------------

### Explore Text-to-Image Models with Workers AI SDK

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/explore-workers-ai-models-using-a-jupyter-notebook

This Python snippet demonstrates how to use the Workers AI SDK to generate images from text prompts. It outlines the process of calling a text-to-image model with a given prompt and receiving an image output. Ensure your environment is set up correctly and explore different prompts to generate diverse images.

```python
# This is a conceptual example using a hypothetical Workers AI SDK.
# Replace with actual SDK calls and model names.

# from workers_ai_sdk import WorkersAIClient

# client = WorkersAIClient(account_id=account_id, api_token=api_token)

# model_name = "@cf/stabilityai/stable-diffusion-xl-base-1.0"
# prompt = "A photorealistic image of a futuristic cityscape at sunset."

# try:
#     response = client.generate(model=model_name, prompt=prompt)
#     # The response would typically contain image data or a URL
#     print(response)
# except Exception as e:
#     print(f"An error occurred: {e}")

print("# Conceptual example for Text-to-Image Generation")
print("# Replace with actual SDK calls.")
print("response = {'image': '<base64_encoded_image_data>'}")

```

--------------------------------

### Image Generation using curl

Source: https://developers.cloudflare.com/workers/-ai/models/dreamshaper-8-lcm

Demonstrates how to send a request to the dreamshaper-8-lcm model using curl for image generation. This example shows a basic text-to-image request with a prompt.

```bash
curl -X POST https://api.cloudflare.com/client/v4/accounts/$CLOUDFLARE_ACCOUNT_ID/ai/run/@cf/lykon/dreamshaper-8-lcm \
     -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
     -d '{ "prompt": "A futuristic cityscape at sunset" }'
```

--------------------------------

### Generate Text with curl - Cloudflare Workers

Source: https://developers.cloudflare.com/workers/-ai/models/una-cybertron-7b-v2-bf16

Example of how to use the 'una-cybertron-7b-v2-bf16' model via the Cloudflare Workers AI API using curl. This command sends a prompt and retrieves the generated text.

```bash
curl -X POST \
  "https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/fblgit/una-cybertron-7b-v2-bf16" \
  -H "Authorization: Bearer YOUR_API_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Write a short poem about the ocean."}'
```

--------------------------------

### Cloudflare Workers API Input Schema Example

Source: https://developers.cloudflare.com/workers/-ai/models/deepseek-r1-distill-qwen-32b

This JSON schema defines the expected input structure for the Cloudflare Workers API. It outlines the properties and their types for making requests to the API.

```json
{
  "input": "object"
}
```

--------------------------------

### Generate Text with Python - Cloudflare Workers

Source: https://developers.cloudflare.com/workers/-ai/models/una-cybertron-7b-v2-bf16

Example of how to use the 'una-cybertron-7b-v2-bf16' model via the Cloudflare Workers AI API using Python. This script sends a prompt and retrieves the generated text.

```python
import requests
import os

api_url = "https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/fblgit/una-cybertron-7b-v2-bf16"
api_token = os.environ.get("CLOUDFLARE_API_TOKEN")

prompt = "Explain the concept of artificial intelligence in simple terms."

headers = {
    "Authorization": f"Bearer {api_token}",
    "Content-Type": "application/json"
}

data = {
    "prompt": prompt
}

response = requests.post(api_url, headers=headers, json=data)

if response.status_code == 200:
    result = response.json()
    print(result['result']['content'])
else:
    print(f"Error: {response.status_code}")
    print(response.text)
```

--------------------------------

### Create Cloudflare Worker Project with npm

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/llama-vision-tutorial

Use the `create-cloudflare` CLI (C3) to initialize a new Cloudflare Worker project using npm. This command sets up a basic 'Hello World' Worker project, which can then be customized for specific functionalities.

```bash
npm create cloudflare@latest llama-vision-tutorial
```

--------------------------------

### Access Environment Binding (JavaScript)

Source: https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/rpc

This example shows how a Worker can access environment variables or other bindings, such as a 'GREETING' binding, through the 'env' property of the WorkerEntrypoint class.

```javascript
import { WorkerEntrypoint } from 'cloudflare:workers';

export default class extends WorkerEntrypoint {
  async greet() {
    return `Hello, ${this.env.GREETING}!`;
  }
}
```

--------------------------------

### Python Worker Module Splitting

Source: https://developers.cloudflare.com/workers/languages/python

Python Workers can be organized into multiple files. This example shows how to create a separate module and import it into the main entry point.

```Python
# src/hello.py
def greet(name):
    return f"Hello, {name}!"

```

```Python
# src/entry.py
from workers import WorkerEntrypoint, Request
from .hello import greet

class Default(WorkerEntrypoint):
    async def fetch(self, request: Request):
        return greet("World")

```

--------------------------------

### Build and Deploy Hono Project

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/hono

This command builds your Hono project and deploys it to the Cloudflare Workers platform. It can be used for deployment to a *.workers.dev subdomain or a Custom Domain, and is suitable for use in CI/CD systems.

```bash
npm run deploy
```

```bash
yarn deploy
```

```bash
pnpm deploy
```

--------------------------------

### Run Wrangler Dev with Custom Host

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/commands

This example demonstrates how to use the '--host' flag with 'wrangler dev' to specify a custom host for forwarding requests, overriding the default zone or tutorial host.

```bash
wrangler dev --host example.com
```

--------------------------------

### GitHub Actions Workflow for Cloudflare Worker Deployment

Source: https://developers.cloudflare.com/workers/ci-cd/external-cicd/github-actions

This example GitHub Actions workflow demonstrates how to deploy a Cloudflare Worker. It assumes that `CLOUDFLARE_ACCOUNT_ID` and `CLOUDFLARE_API_TOKEN` are set as secrets in your GitHub repository.

```yaml
name: Deploy Worker

on:
  push:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: cloudflare/wrangler-action@v1
        with:
          apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          accountId: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        # Optional: specify the Wrangler command to run
        # command: deploy --config wrangler.toml
        # Optional: specify the directory containing your worker
        # workingDirectory: ./path/to/worker

```

--------------------------------

### Respond with Another Site using JavaScript

Source: https://developers.cloudflare.com/workers/examples/respond-with-another-site

This Worker fetches a response from 'example.com' and returns it to the client. It requires no external dependencies and handles basic HTTP requests.

```JavaScript
addEventListener('fetch', event => {
  event.respondWith(fetch('https://example.com'))
})
```

--------------------------------

### Make Request to OpenAI Chat Completions API (JavaScript)

Source: https://developers.cloudflare.com/workers/tutorials/openai-function-calls-workers

This code demonstrates how to make a request to the OpenAI Chat Completions API using the function calling feature. It specifies the model, messages, available tools (including parameters and descriptions), and tool choice. The example includes a 'read_website_content' tool.

```javascript
const response = await openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [{"role": "user", "content": message}],
  tools: [
    {
      "type": "function",
      "function": {
        "name": "read_website_content",
        "description": "Reads the content on a given website.",
        "parameters": {
          "type": "object",
          "properties": {
            "url": {
              "type": "string",
              "description": "The URL of the website to read."
            }
          },
          "required": ["url"]
        }
      }
    }
  ],
  tool_choice: 'auto', // auto is default, but shown for clarity
});
```

--------------------------------

### Generate Text with Worker (Streaming) - Cloudflare Workers

Source: https://developers.cloudflare.com/workers/-ai/models/una-cybertron-7b-v2-bf16

Example of how to use the 'una-cybertron-7b-v2-bf16' model with Cloudflare Workers for streaming text generation. This demonstrates setting up a worker to interact with the LLM API and handle streaming responses.

```javascript
addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  const url = new URL(request.url)
  const prompt = url.searchParams.get('prompt')

  if (!prompt) {
    return new Response('Please provide a prompt parameter.', {
      status: 400
    })
  }

  const response = await fetch('https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/fblgit/una-cybertron-7b-v2-bf16', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer YOUR_API_TOKEN',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      prompt: prompt,
      stream: true
    })
  })

  return new Response(response.body, {
    headers: {
      'Content-Type': 'text/plain; charset=utf-8'
    }
  })
}
```

--------------------------------

### Example Wrangler JSONC Configuration

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/configuration

This snippet illustrates a top-level configuration within a Wrangler JSONC file. It highlights how to define project-wide settings and environment-specific overrides for different deployment targets.

```json
{
  "name": "my-worker",
  "main": "src/index.js",
  "compatibility_date": "2023-01-01",
  "env": {
    "production": {
      "kv_namespace": "my-kv-production",
      "route": "https://production.example.com/*"
    },
    "staging": {
      "kv_namespace": "my-kv-staging",
      "route": "https://staging.example.com/*"
    }
  }
}
```

--------------------------------

### Create a new Worker project with C3

Source: https://developers.cloudflare.com/workers/get-started/guide

Use the C3 command-line tool to create a new Cloudflare Worker project. This involves selecting options for the project template, language, and version control.

```bash
npm create cloudflare@latest
# or
yarn create cloudflare
# or
pnpm create cloudflare
```

--------------------------------

### R2 domain get

Source: https://developers.cloudflare.com/workers/wrangler/commands

Retrieves information about a specific custom domain connected to an R2 bucket. Provides details of the domain's configuration.

```APIDOC
## `domain get`

### Description
Get custom domain connected to an R2 bucket.

### Method
GET

### Endpoint
`/buckets/{NAME}/domains/{domain}` (conceptual endpoint)

### Parameters
#### Path Parameters
- **NAME** (string) - Required - The name of the R2 bucket whose custom domain to retrieve.
- **domain** (string) - Required - The custom domain to get information for.

#### Query Parameters
- **jurisdiction** (string) - Optional - The jurisdiction where the bucket exists, if a jurisdiction has been specified. Refer to jurisdictional restrictions.

### Request Example
(No request body for GET request)

### Response
#### Success Response (200)
- **domain_details** (object) - An object containing details of the custom domain.
  - **domain** (string) - The custom domain name.
  - **status** (string) - The status of the custom domain (e.g., 'active', 'pending').
  - **min_tls** (string) - The minimum TLS version configured.

#### Response Example
```json
{
  "domain_details": {
    "domain": "my-custom-domain.com",
    "status": "active",
    "min_tls": "1.2"
  }
}
```
```

--------------------------------

### Cloudflare Workers: Use KV API

Source: https://developers.cloudflare.com/workers/-ai/features/function-calling/embedded/examples

Illustrates how to interact with the Cloudflare Workers KV (Key-Value) API to store and retrieve data. This is essential for applications requiring persistent storage at the edge.

```javascript
/**
 * @param {Request} request
 * @param {Env} env
 * @param {ExecutionContext} ctx
 * @returns {Response}
 */
export async function onRequest(request, env, ctx) {
  // Read a value from KV
  let value = await env.MY_KV_NAMESPACE.get('mykey');

  if (value === null) {
    // Write a value to KV
    await env.MY_KV_NAMESPACE.put('mykey', 'myvalue');
    value = 'myvalue';
  }

  return new Response(`Value: ${value}`);
}
```

--------------------------------

### cURL Usage Example for Qwen QwQ-32B

Source: https://developers.cloudflare.com/workers/-ai/models/qwq-32b

This cURL command demonstrates how to send a request to the Qwen QwQ-32B model via the Cloudflare Workers AI API. It includes the necessary headers for authentication and the JSON payload for the prompt.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/qwen/qwq-32b" \
     -H "Authorization: Bearer YOUR_CLOUDFLARE_API_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{ "prompt": "What are the main challenges in renewable energy adoption?" }'
```

--------------------------------

### Update Wrangler with yarn

Source: https://developers.cloudflare.com/workers/wrangler/install-and-update

Updates the Wrangler CLI to the latest version within your project using yarn. This ensures you are using the most current version of the tool.

```bash
yarn upgrade wrangler
```

--------------------------------

### Create Airtable-Form-Handler Worker Project (pnpm)

Source: https://developers.cloudflare.com/workers/tutorials/handle-form-submissions-with-airtable

Initializes a new Cloudflare Worker project named 'airtable-form-handler' using pnpm. It sets up a basic 'Hello World' Worker template with JavaScript and git version control, but defers deployment.

```bash
pnpm create cloudflare
# For setup, select the following options:
# - What would you like to start with? > Hello World example
# - Which template would you like to use? > Worker only
# - Which language do you want to use? > JavaScript
# - Do you want to use git for version control? > Yes
# - Do you want to deploy your application? > No

cd airtable-form-handler
```

--------------------------------

### Python Text Generation with Llama-2-7b-chat-hf-lora

Source: https://developers.cloudflare.com/workers/-ai/models/llama-2-7b-chat-hf-lora

Example showing how to use the Llama-2-7b-chat-hf-lora model for text generation via Python. This typically involves making HTTP requests to an API endpoint.

```python
import os
import httpx

API_URL = "https://api.cloudflare.com/client/v4/accounts/{}/ai/run/{}".format(
    os.environ.get("CLOUDFLARE_ACCOUNT_ID"), "@cf/meta-llama/llama-2-7b-chat-hf-lora"
)

def generate_text(prompt):
    headers = {"Authorization": "Bearer {}".format(os.environ.get("CLOUDFLARE_API_TOKEN"))}
    response = httpx.post(API_URL, headers=headers, json={"prompt": prompt})
    return response.json()["result"]["response"] # Adjust based on actual API response structure

if __name__ == "__main__":
    user_prompt = "Explain the concept of quantum entanglement in simple terms."
    generated_text = generate_text(user_prompt)
    print(generated_text)
```

--------------------------------

### Generate Text with Python SDK

Source: https://developers.cloudflare.com/workers/-ai/models/tinyllama-1

This Python code example shows how to integrate the tinyllama-1.1b-chat-v1.0 model into your applications using Python. It utilizes the Cloudflare client library to send prompts and receive generated text.

```python
fromCloudflare.ai import AIClient

client = AIClient(api_token="{API_TOKEN}")
prompt = "Tell me a short story."

response = client.run("@cf/tinyllama/tinyllama-1.1b-chat-v1.0", {
    "prompt": prompt
})

print(response["result"]["response"])
```

--------------------------------

### Generate Text with Zephyr 7B Beta AWQ using Python

Source: https://developers.cloudflare.com/workers/-ai/models/zephyr-7b-beta-awq

Demonstrates how to interact with the Zephyr 7B Beta AWQ model using Python. This snippet shows how to send a prompt and receive a text generation response, likely using an HTTP client library.

```python
import requests

url = "https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@hf/thebloke/zephyr-7b-beta-awq"
headers = {
    "Authorization": "Bearer YOUR_API_TOKEN",
    "Content-Type": "application/json",
}

data = {
    "prompt": "Write a short story about a space explorer."
}

response = requests.post(url, headers=headers, json=data)

if response.status_code == 200:
    print(response.json())
else:
    print(f"Error: {response.status_code}")
    print(response.text)
```

--------------------------------

### Getting User Agent with navigator.userAgent

Source: https://developers.cloudflare.com/workers/runtime-apis/web-standards

When the global_navigator compatibility flag is set, the navigator.userAgent property is available and returns 'Cloudflare-Workers'. This helps identify the runtime environment.

```JavaScript
if (typeof navigator !== 'undefined' && navigator.userAgent === 'Cloudflare-Workers') {
  console.log('Running in Cloudflare Workers environment.');
}
```

--------------------------------

### Scaffold Hono App with React SPA using pnpm

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/hono

This command scaffolds a new full-stack application using Hono, a React Single Page Application (SPA), and the Cloudflare Vite plugin. It sets up the project structure for rapid development on Cloudflare Workers.

```bash
pnpm create cloudflare --template react-hono my-hono-app
```

--------------------------------

### Example Usage of @cf/leonardo/lucid-origin (Text-to-Image)

Source: https://developers.cloudflare.com/workers/-ai/changelog

A text-to-image model from Leonardo AI that generates images with sharp graphic design and specific creative direction. Available on Workers AI.

```javascript
// Example usage for @cf/leonardo/lucid-origin (Text-to-Image)

const prompt = "A minimalist logo for a coffee shop, vector art, clean lines";

async function generateImageLucidOrigin(prompt) {
  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/leonardo/lucid-origin", {
    method: "POST",
    headers: {
      "Authorization": "Bearer <YOUR_API_TOKEN>",
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      "prompt": prompt
    })
  });
  const data = await response.json();
  // The response will contain a URL to the generated image or the image data itself.
  return data.result.image_url; // The exact key might vary
}

generateImageLucidOrigin(prompt).then(imageUrl => {
  console.log("Generated image URL:", imageUrl);
});

```

--------------------------------

### AI Prompting for JavaScript Workers

Source: https://developers.cloudflare.com/workers/get-started/prompting

This example shows how to use the base prompt as a system prompt for AI models when generating JavaScript code for Cloudflare Workers. It helps the AI understand how to structure the output code in JavaScript.

```javascript
// Example of how the AI might structure JavaScript output based on the prompt
// This is a conceptual example, not actual executable code from the prompt itself.

addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  // Your Worker logic here
  return new Response('Hello from Cloudflare Workers!', {
    headers: {
      'content-type': 'text/plain',
    },
  })
}
```

--------------------------------

### Simple Wasm Module in WAT Format

Source: https://developers.cloudflare.com/workers/runtime-apis/webassembly/javascript

An example of a simple WebAssembly module written in the WebAssembly Text Format (WAT). This module exports an 'add' function that takes two i32 arguments and returns their sum.

```WAT
(module
  ;; Export the 'add' function
  (func $add (param $a i32) (param $b i32) (result i32)
    local.get $a
    local.get $b
    i32.add)
  (export "add" (func $add))
)

```

--------------------------------

### Worker Streaming Usage Example for llama-3.3-70b-instruct-fp8-fast

Source: https://developers.cloudflare.com/workers/-ai/models/llama-3

This JavaScript snippet illustrates how to use the llama-3.3-70b-instruct-fp8-fast model within a Cloudflare Worker, enabling streaming responses. It shows the basic structure for making a request and handling the streamed output.

```javascript
export default {
  async fetch(request, env, ctx) {
    const prompt = "Tell me a joke.";
    const response = await env.AI.llama_3_3_70b_instruct_fp8_fast.chat.completions.create({
      messages: [{ role: "user", content: prompt }],
      stream: true
    });

    let stream = "";
    for await (const chunk of response) {
      stream += chunk.delta.content;
    }
    return new Response(stream);
  }
};
```

--------------------------------

### Wrangler Configuration for Hyperdrive

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase

Example of how to configure Hyperdrive binding in a Wrangler configuration file (`wrangler.jsonc` or `wrangler.toml`) to use the created Hyperdrive configuration within your Cloudflare Worker.

```json
{
  "name": "my-worker",
  "main": "src/index.js",
  "compatibility_flags": [
    "nodejs_compat"
  ],
  "hyperdrive": [
    {
      "name": "SUPABASE_HYPERDRIVE",
      "connectionString": "postgres://user:password@hostname:port/database"
    }
  ]
}
```

--------------------------------

### Create Worker Configuration File

Source: https://developers.cloudflare.com/workers/vite-plugin/tutorial

This section details the creation of a Worker configuration file, typically `wrangler.jsonc` or `wrangler.toml`. It highlights the `not_found_handling` setting, which is crucial for SPAs, directing all not-found requests to serve the `index.html` file. This ensures proper routing for client-side applications.

```json
{
  "name": "cloudflare-vite-tutorial",
  "main": "./dist/server/entry.js",
  "compatibility_date": "2023-10-20",
  "workers_dev": true,
  "build": {
    "upload": {
      "dir": "dist/client"
    }
  },
  "routes": [
    {
      "pattern": "api/*",
      "zone_name": "example.com",
      "script": "api"
    }
  ],
  "site": {
    "bucket": "dist/client"
  },
  "pages_build_output_dir": "dist/client",
  "pages_functions": {
    "api/**": {
      "include": ["dist/server/entry.js"],
      "exclude": []
    }
  },
  "log_level": "info",
  "usage_model": "unlimited",
  "kv_namespaces": [
    {
      "binding": "MY_KV",
      "id": "your-kv-namespace-id"
    }
  ],
  "d1_databases": [
    {
      "binding": "MY_D1",
      "id": "your-d1-database-id"
    }
  ],
  "queues": [
    {
      "binding": "MY_QUEUE",
      "queue_name": "your-queue-name",
      "url": "your-queue-url"
    }
  ],
  "queues_producer": [
    {
      "binding": "MY_PRODUCER",
      "queue_name": "your-queue-name",
      "url": "your-queue-url"
    }
  ],
  "r2_buckets": [
    {
      "binding": "MY_BUCKET",
      "bucket_name": "your-r2-bucket-name"
    }
  ],
  "services": [
    {
      "binding": "MY_SERVICE",
      "service": "your-service-name",
      "environment": "production"
    }
  ],
  "wasm_modules": [
    {
      "binding": "MY_WASM",
      "path": "path/to/your/module.a.wasm"
    }
  ],
  "data_sources": [
    {
      "binding": "MY_DATA_SOURCE",
      "database": "your-database-name",
      "table": "your-table-name"
    }
  ],
  "ai": [
    {
      "binding": "MY_AI",
      "model": "@cf/meta/llama-2-7b-chat-fp16"
    }
  ],
  "durable_objects": {
    "bindings": [
      {
        "name": "MY_DO",
        "class_name": "MyDO",
        "script_name": "do"
      }
    ]
  },
  "queue_handlers": [
    {
      "route": "*",
      "handler": "queue_handler"
    }
  ],
  "queue_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_handler"
    }
  ],
  "queue_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_producer"
    }
  ],
  "queue_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message"
    }
  ],
  "queue_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch"
    }
  ],
  "queue_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_handler"
    }
  ],
  "queue_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_consumer"
    }
  ],
  "queue_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_producer"
    }
  ],
  "queue_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message"
    }
  ],
  "queue_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_messages": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batches": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handlers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_handler"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_consumer"
    }
  ],
  "queue_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_message_batch_producers": [
    {
      "queue": "your-queue-name",
      "handler": "queue_message_batch_
```

--------------------------------

### Update Wrangler with pnpm

Source: https://developers.cloudflare.com/workers/wrangler/install-and-update

Updates the Wrangler CLI to the latest version within your project using pnpm. This command fetches the newest version and updates your project's dependencies.

```bash
pnpm update wrangler
```

--------------------------------

### Python Usage for Hermes-2-Pro-Mistral-7B

Source: https://developers.cloudflare.com/workers/-ai/models/hermes-2-pro-mistral-7b

Example code for interacting with the Hermes-2-Pro-Mistral-7B model using Python. This typically involves using a library like 'requests' to send prompts to the Cloudflare Workers endpoint.

```python
import requests

API_URL = "https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@hf/nousresearch/hermes-2-pro-mistral-7b"
API_TOKEN = "YOUR_CLOUDFLARE_API_TOKEN"

def query(prompt):
    headers = {
        "Authorization": f"Bearer {API_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {
        "prompt": prompt
    }
    response = requests.post(API_URL, headers=headers, json=payload)
    return response.json()
```

--------------------------------

### Linux Sandboxing with seccomp and Namespaces

Source: https://developers.cloudflare.com/workers/reference/security-model

This snippet illustrates the concept of using Linux namespaces and seccomp for strict sandboxing, commonly employed in containerization but applied more rigorously in Cloudflare Workers. It highlights how these technologies can prohibit filesystem and network access by configuring them after process start but before isolate loading.

```bash
# Example conceptual commands (not directly executable without a full setup)

# Using namespaces to create an empty filesystem
unshare --mount --pid --ipc --net --uts --user --map-root-user

# Mount a new, empty filesystem (e.g., tmpfs)
mount -t tmpfs none /mnt

# Using seccomp to define allowed system calls (conceptual)
# This would typically involve a seccomp filter program
# Example: Allow only specific syscalls, block others like open(), socket()
# seccomp_filter_program = "..."

# Applying seccomp to the current process
# prctl(PR_SET_SECCOMP, 1, seccomp_filter_program, 0, 0);

# Prohibiting network access (conceptual, often done via seccomp)
# Block syscalls like socket(), connect(), bind()

```

--------------------------------

### Wrangler Configuration File

Source: https://developers.cloudflare.com/workers/wrangler

Developers can use a configuration file to customize the development and deployment setup for their Worker projects and other Developer Platform products, providing flexibility and control.

```yaml
# Example wrangler.toml structure (specific content not provided in text)
name = "my-worker"
main = "src/index.js"
compatibility_date = "2023-10-26"

[env.production]
kv_namespaces = [
  {
    binding = "MY_KV",
    id = "your-kv-namespace-id"
  }
]
```

--------------------------------

### Call qwen1.5-14b-chat-awq with Cloudflare Workers (Python)

Source: https://developers.cloudflare.com/workers/-ai/models/qwen1

Example of how to use the qwen1.5-14b-chat-awq model within a Cloudflare Worker using Python. This snippet demonstrates sending a prompt and receiving a streamed text generation response.

```python
from python_worker import CloudflareWorker

async def main(request):
    prompt = "What is the weather like today?"
    worker = CloudflareWorker()
    response = await worker.ai.run("@cf/qwen/qwen1.5-14b-chat-awq", {
        "messages": [
            {"role": "user", "content": prompt}
        ]
    })
    return response
```

--------------------------------

### Shimming Global APIs with Webpack Plugins

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/webpack

To replace existing global APIs with custom implementations, you can use webpack plugins. This example demonstrates shimming the `URL` global class with the `url-polyfill` npm package.

```javascript
const path = require('path');
const { URL } = require('url-polyfill');

module.exports = {
  entry: './src/index.js',
  output: {
    filename: 'worker.js',
    path: path.resolve(__dirname, 'dist'),
  },
  target: 'webworker',
  plugins: [
    // Example: Shimming URL global
    // Note: Actual plugin implementation might vary based on webpack version and polyfill usage
    // This is a conceptual representation.
    // new webpack.ProvidePlugin({
    //   URL: [path.resolve(__dirname, 'node_modules/url-polyfill/url.min.js'), 'URL']
    // })
  ],
  resolve: {
    fallback: {
      "url": require.resolve("url/"),
      "querystring": require.resolve("querystring-es3")
    }
  }
};
```

--------------------------------

### Get Information about a Container

Source: https://developers.cloudflare.com/workers/wrangler/commands

Retrieves detailed information about a specific Cloudflare container, including its top-level attributes and a list of its instances. Requires the container's ID.

```bash
wrangler containers info CONTAINER_ID
```

--------------------------------

### Embed Text with baai/bge-m3 using Python

Source: https://developers.cloudflare.com/workers/-ai/models/bge-m3

This Python example illustrates how to use the baai/bge-m3 model to generate text embeddings. It outlines the structure of the request, including the text to embed and a flag for input truncation. This is useful for integrating embeddings into Python applications.

```python
import os

from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

response = client.embeddings.create(
    model="@cf/baai/bge-m3",
    input="The quick brown fox jumps over the lazy dog."
)
```

--------------------------------

### Prevent Indexing by Search Engines

Source: https://developers.cloudflare.com/workers/static-assets/headers

This example uses the X-Robots-Tag header to prevent search engines from indexing your workers.dev URLs. It applies to wildcard subdomains.

```HTML
X-Robots-Tag: noindex

```

--------------------------------

### Vite Configuration with Cloudflare Vite Plugin

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/react

Sets up Vite to use the Cloudflare Vite plugin for local development. This configuration ensures the application runs in the Cloudflare Workers runtime locally, providing accurate emulation of bindings and production behavior.

```typescript
import { defineConfig } from 'vite';

export default defineConfig({
  plugins: [
    {
      name: 'my-plugin',
      // Vite plugin API
    },
  ],
});

```

--------------------------------

### LLaVA 1.5 7B HF Image-to-Text

Source: https://developers.cloudflare.com/workers/-ai/models/llava-1

This endpoint processes an image and a text prompt to generate a text description or answer questions about the image.

```APIDOC
## POST /@cf/llava-hf/llava-1.5-7b-hf

### Description
Processes an image and a text prompt to generate a text description or answer questions about the image using the LLaVA 1.5 7B HF model.

### Method
POST

### Endpoint
/@cf/llava-hf/llava-1.5-7b-hf

### Parameters
#### Request Body
- **image** (one of [array, string]) - Required - The image data. Can be an array of integers (0-255) or a binary string.
- **prompt** (string) - Required - The input text prompt for the model.
- **temperature** (number) - Optional - Controls the randomness of the output; higher values produce more random results.
- **raw** (boolean) - Optional - If true, a chat template is not applied and you must adhere to the specific model's expected formatting.
- **top_p** (number) - Optional - Controls the creativity of the AI's responses by adjusting how many possible words it considers.
- **top_k** (number) - Optional - Limits the AI to choose from the top 'k' most probable words.
- **seed** (number) - Optional - Random seed for reproducibility of the generation.
- **repetition_penalty** (number) - Optional - Penalty for repeated tokens; higher values discourage repetition.
- **frequency_penalty** (number) - Optional - Decreases the likelihood of the model repeating the same lines verbatim.
- **presence_penalty** (number) - Optional - Increases the likelihood of the model introducing new topics.
- **max_tokens** (integer) - Optional - The maximum number of tokens to generate in the response. Default is 512.

### Request Example
```json
{
  "image": "binary_image_string_or_array",
  "prompt": "What is in this image?",
  "max_tokens": 100,
  "temperature": 0.7
}
```

### Response
#### Success Response (200)
- **description** (string) - The generated text output from the model.
```

--------------------------------

### Generate Image with curl

Source: https://developers.cloudflare.com/workers/-ai/models/stable-diffusion-xl-base-1

Example of how to use the Stable Diffusion XL 1.0 model via curl command. This demonstrates making an API request with a prompt and other parameters to generate an image.

```bash
curl 'https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/stabilityai/stable-diffusion-xl-base-1.0' \
     -H 'Authorization: Bearer {API_TOKEN}' \
     -H 'Content-Type: application/json' \
     --data-raw '{ 
         "prompt": "A serene landscape with a glowing river", 
         "negative_prompt": "dark, gloomy, monsters", 
         "width": 1024, 
         "height": 1024, 
         "num_steps": 20, 
         "seed": 12345 
     }'
```

--------------------------------

### ResNet-50 Image Classification with cURL

Source: https://developers.cloudflare.com/workers/-ai/models/resnet-50

Example of how to invoke the ResNet-50 image classification model using cURL. This demonstrates sending image data via a POST request to the model endpoint.

```shell
curl -X POST https://api.cloudflare.com/client/v4/accounts/$CLOUDFLARE_ACCOUNT_ID/ai/run/@cf/microsoft/resnet-50 \
     -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{ "image": [255, 0, 128, ... ] }'
```

--------------------------------

### Durable Object Alarm Example

Source: https://developers.cloudflare.com/workers/prompt

Demonstrates using the Durable Object Alarm API to schedule and handle alarms. It sets an alarm for 10 seconds in the future and logs a message when the alarm is triggered, then reschedules it.

```typescript
import { DurableObject } from "cloudflare:workers";

interface Env {
ALARM_EXAMPLE: DurableObject<Env>;
}

export default {
  async fetch(request, env) {
    let url = new URL(request.url);
    let userId = url.searchParams.get("userId") || crypto.randomUUID();
    return await env.ALARM_EXAMPLE.getByName(userId).fetch(request);
  },
};

const SECONDS = 1000;

export class AlarmExample extends DurableObject {
constructor(ctx, env) {
this.ctx = ctx;
this.storage = ctx.storage;
}
async fetch(request) {
// If there is no alarm currently set, set one for 10 seconds from now
let currentAlarm = await this.storage.getAlarm();
if (currentAlarm == null) {
this.storage.setAlarm(Date.now() + 10 
 SECONDS);
}
}
async alarm(alarmInfo) {
// The alarm handler will be invoked whenever an alarm fires.
// You can use this to do work, read from the Storage API, make HTTP calls
// and set future alarms to run using this.storage.setAlarm() from within this handler.
if (alarmInfo?.retryCount != 0) {
console.log("This alarm event has been attempted ${alarmInfo?.retryCount} times before.");
}

// Set a new alarm for 10 seconds from now before exiting the handler
this.storage.setAlarm(Date.now() + 10 
 SECONDS);
}
}
```

--------------------------------

### Use Fine-tuned Model in Chat Completions

Source: https://developers.cloudflare.com/workers/tutorials/create-finetuned-chatgpt-ai-models-with-r2

This JavaScript example illustrates how to use a fine-tuned model in API requests to OpenAI's chat completions endpoints. It shows a typical request structure, including the `model` parameter set to your fine-tuned model's identifier.

```javascript
const response = await fetch('https://api.openai.com/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
  },
  body: JSON.stringify({
    model: 'your-fine-tuned-model-id',
    messages: [{ role: 'user', content: 'Hello!' }]
  })
});
const data = await response.json();
```

--------------------------------

### Curl Command for Mistral-7B-Instruct-v0.2 LLM

Source: https://developers.cloudflare.com/workers/-ai/models/mistral-7b-instruct-v0

This command-line interface (CLI) example shows how to send a request to the Mistral-7B-Instruct-v0.2 LLM using curl. It includes the necessary endpoint, authentication headers, and a JSON payload with the prompt. Remember to replace placeholder values with your specific account ID and API token.

```bash
curl https://api.cloudflare.com/client/v4/accounts/{YOUR_ACCOUNT_ID}/ai/run/@cf/mistral/mistral-7b-instruct-v0.2-lora \
  -X POST \
  -H "Authorization: Bearer {YOUR_API_TOKEN}" \
  -H "Content-Type: application/json" \
  -d '{ "prompt": "What are the main differences between Python 2 and Python 3?", "stream": false }'
```

--------------------------------

### Run Inference with LoRA using REST API

Source: https://developers.cloudflare.com/workers/-ai/fine-tunes/loras

Example of making inference requests with a LoRA adapter applied via the REST API. Requires the model and finetune name or ID, and appropriate API token permissions.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/v1/run/{MODEL_NAME}" \
     -H "Authorization: Bearer {API_TOKEN}" \
     -H "Content-Type: application/json" \
     --data '{
       "finetune": "<your-finetune-name-or-id>",
       "messages": [
         { "role": "user", "content": "Hello!" }
       ],
       "raw": true // Optionally use raw mode with a specific template
     }'
```

--------------------------------

### Generate Text with Worker (Non-Streaming) - Cloudflare Workers

Source: https://developers.cloudflare.com/workers/-ai/models/una-cybertron-7b-v2-bf16

Example of how to use the 'una-cybertron-7b-v2-bf16' model with Cloudflare Workers for non-streaming text generation. This demonstrates setting up a worker to interact with the LLM API and receive a complete response.

```javascript
addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  const url = new URL(request.url)
  const prompt = url.searchParams.get('prompt')

  if (!prompt) {
    return new Response('Please provide a prompt parameter.', {
      status: 400
    })
  }

  const response = await fetch('https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/fblgit/una-cybertron-7b-v2-bf16', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer YOUR_API_TOKEN',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      prompt: prompt,
      stream: false
    })
  })

  const data = await response.json()
  return new Response(JSON.stringify(data.result.content), {
    headers: {
      'Content-Type': 'application/json'
    }
  })
}
```

--------------------------------

### Cloudflare Workers API Input Schema Example

Source: https://developers.cloudflare.com/workers/-ai/models/qwen1

A sample JSON object representing the input schema for the Cloudflare Workers API. This schema defines the structure for requests made to the API, including potential parameters for text generation.

```json
{
  "prompt": "Generate text about Cloudflare Workers.",
  "frequency_penalty": 0.1,
  "presence_penalty": 0.0
}
```

--------------------------------

### Package Manager Cache Directories

Source: https://developers.cloudflare.com/workers/ci-cd/builds/build-caching

Cloudflare Workers build cache supports caching global cache directories for various package managers. This speeds up dependency installation in subsequent builds.

```text
Package Manager| Directories cached  
---|---
npm ↗| `.npm`  
yarn ↗| `.cache/yarn`  
pnpm ↗| `.pnpm-store`  
bun ↗| `.bun/install/cache`
```

--------------------------------

### Run AI Model with env.AI.run()

Source: https://developers.cloudflare.com/workers/-ai/configuration/bindings

Example of using the `env.AI.run()` method within a Cloudflare Worker to execute a specified AI model. This method takes the model name and an options object, supporting streaming of results.

```javascript
export default {
  async fetch(request, env) {
    const response = await env.AI.run(
      "@cf/meta/llama-2-7b-chat",
      {
        stream: true,
        prompt": "What is the capital of France?"
      }
    );
    return new Response(response);
  }
}
```

--------------------------------

### Cloudflare Workers API Output Schema Example

Source: https://developers.cloudflare.com/workers/-ai/models/qwen1

A sample JSON object representing the output schema for the Cloudflare Workers API. This schema outlines the structure of the data returned by the API, including generated text and usage metrics.

```json
{
  "response": "This is an example output generated by the Cloudflare Workers API.",
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 30,
    "total_tokens": 50
  }
}
```

--------------------------------

### Create TCP Socket and Read Response

Source: https://developers.cloudflare.com/workers/runtime-apis/tcp-sockets

Demonstrates creating a TCP socket, writing data to it, and returning the readable stream as a response. This is a fundamental example of establishing and interacting with a TCP connection.

```javascript
import { connect } from "cloudflare:sockets";

export default {
  async fetch(request) {
    const socket = connect("example.com:80");
    const writer = socket.writable.getWriter();
    await writer.write(new TextEncoder().encode("GET / HTTP/1.1\r\nHost: example.com\r\nConnection: close\r\n\r\n"));
    writer.releaseLock();
    return new Response(socket.readable);
  },
};

```

--------------------------------

### Streaming Text Generation with Cloudflare Worker

Source: https://developers.cloudflare.com/workers/-ai/models/gemma-7b-it-lora

Example of how to use the gemma-7b-it-lora model for streaming text generation within a Cloudflare Worker. This snippet demonstrates the server-side implementation.

```javascript
addEventListener("fetch", (event) => {
  event.respondWith(handleRequest(event.request));
});

async function handleRequest(request) {
  const prompt = "Write a short story about a robot.";
  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/google/gemma-7b-it-lora", {
    method: "POST",
    headers: {
      "Authorization": "Bearer <API_TOKEN>",
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      "prompt": prompt,
      "stream": true
    }),
  });

  return new Response(response.body, {
    headers: {
      "Content-Type": "text/plain",
    },
  });
}
```

--------------------------------

### Starting a New Worker Script (TypeScript)

Source: https://developers.cloudflare.com/workers/static-assets/migration-guides/migrate-from-pages

For projects requiring static typing, Cloudflare Workers support TypeScript. This allows for better code maintainability and early error detection.

```typescript
export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
    return new Response("Hello World!");
  },
};

```

--------------------------------

### Get Information about D1 Database

Source: https://developers.cloudflare.com/workers/wrangler/commands

Retrieves information about a specific D1 database, including its current size and operational state. Supports returning the output in JSON format.

```bash
wrangler d1 info DATABASE_NAME [--json]
```

--------------------------------

### List Fine-tunes

Source: https://developers.cloudflare.com/workers/-ai/fine-tunes/loras

Lists all fine-tunes created in your account. Requires 'Workers AI Write' or 'Workers AI Read' permissions.

```APIDOC
## GET /accounts/{accountId}/ai/v1/finetunes

### Description
Lists all fine-tunes created in your account.

### Method
GET

### Endpoint
`/accounts/{accountId}/ai/v1/finetunes`

### Parameters
#### Path Parameters
- **accountId** (string) - Required - Your Cloudflare account ID.

### Response
#### Success Response (200)
- **finetunes** (array) - A list of fine-tune objects.
  - **id** (string) - The unique identifier for the fine-tune.
  - **name** (string) - The name of the fine-tune.

#### Response Example
```json
{
  "finetunes": [
    {
      "id": "finetune-id-12345",
      "name": "my-lora-finetune"
    },
    {
      "id": "finetune-id-67890",
      "name": "another-finetune"
    }
  ]
}
```
```

--------------------------------

### Tail Worker Logs

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/commands

Starts a session to livestream logs from a deployed Worker. Supports filtering by format, status, HTTP header, HTTP method, sampling rate, and search terms.

```bash
wrangler tail --format json
wrangler tail --status error
wrangler tail --header "Content-Type: application/json"
wrangler tail --method POST
wrangler tail --sampling-rate 10
wrangler tail --search "user login"
```

--------------------------------

### Run Inference with Public LoRA (JavaScript)

Source: https://developers.cloudflare.com/workers/-ai/features/fine-tunes/public-loras

JavaScript code snippet for running inference with a public LoRA adapter. This example requires your account ID, API token, the LoRA name, and the prompt.

```javascript
async function runInferenceWithLora(accountId, apiToken, model, loraName, prompt) {
  const response = await fetch(`https://api.cloudflare.com/client/v4/accounts/${accountId}/ai/run/${model}`, {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${apiToken}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      lora: loraName,
      prompt: prompt
    })
  });
  const data = await response.json();
  console.log(data);
  return data;
}
```

--------------------------------

### Running Inference with LoRA Adapters (REST API)

Source: https://developers.cloudflare.com/workers/-ai/features/fine-tunes/loras

Example of making a REST API call to run inference with a LoRA adapter applied. Specify the model and finetune name or ID in the URL. The request body should include the messages and potentially `raw: true`.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/<account_id>/ai/run/<model_name@finetune_name_or_id>" \
     -H "Authorization: Bearer <cloudflare_api_token>" \
     -H "Content-Type: application/json" \
     --data '{ "messages": [{"role": "user", "content": "Explain the importance of low-rank adaptation."}] }'
```

--------------------------------

### Example Usage of @cf/pipecat-ai/smart-turn-v2

Source: https://developers.cloudflare.com/workers/-ai/changelog

This model helps detect when a speaker has finished talking, useful for interactive voice applications. It's available on Workers AI with WebSocket support.

```javascript
// Example usage for @cf/pipecat-ai/smart-turn-v2
// Detects when a speaker has finished speaking. WebSocket support available.

// This model typically processes audio streams and indicates speaking status.
// The exact input/output format depends on the API implementation.

async function detectSpeakingEnd(audioChunk) {
  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/pipecat-ai/smart-turn-v2", {
    method: "POST",
    headers: {
      "Authorization": "Bearer <YOUR_API_TOKEN>",
      "Content-Type": "audio/wav" // Or other supported audio format
    },
    body: audioChunk // A chunk of audio data
  });
  const data = await response.json();
  // The response should indicate if the speaker has finished.
  // Example: return data.result.is_speaking_ended;
  return data;
}

// Placeholder for audio chunk processing
// detectSpeakingEnd(yourAudioChunk).then(result => {
//   console.log("Speaking end detection result:", result);
// });

```

--------------------------------

### Run Hono Application Locally

Source: https://developers.cloudflare.com/workers/tutorials/build-a-slackbot

Commands to run a Hono application locally on your machine after it has been set up. This allows for testing and development before deployment.

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
```

--------------------------------

### R2 dev-url get

Source: https://developers.cloudflare.com/workers/wrangler/commands

Retrieves the r2.dev URL and its current status for a specified R2 bucket. This endpoint is useful for checking the public accessibility configuration.

```APIDOC
## `dev-url get`

### Description
Get the r2.dev URL and status for an R2 bucket.

### Method
GET

### Endpoint
`/buckets/{NAME}/dev-url` (conceptual endpoint)

### Parameters
#### Path Parameters
- **NAME** (string) - Required - The name of the R2 bucket whose r2.dev URL status to retrieve.

#### Query Parameters
- **jurisdiction** (string) - Optional - The jurisdiction where the bucket exists, if a jurisdiction has been specified. Refer to jurisdictional restrictions.

### Request Example
(No request body for GET request)

### Response
#### Success Response (200)
- **url** (string) - The r2.dev URL for the bucket.
- **status** (string) - The current status of the r2.dev URL (e.g., 'enabled', 'disabled').

#### Response Example
```json
{
  "url": "https://<bucket-name>.r2.dev",
  "status": "enabled"
}
```
```

--------------------------------

### Completions API Parameters

Source: https://developers.cloudflare.com/workers/-ai/models/llama-3-8b-instruct-awq

This section details the parameters available for controlling text generation, such as frequency and presence penalties.

```APIDOC
## POST /completions (Example Endpoint)

### Description
This endpoint is used for text generation with adjustable parameters to control repetition and topic diversity.

### Method
POST

### Endpoint
/completions

### Parameters
#### Query Parameters
- `frequency_penalty` (number) - Optional - Minimum: -2, Maximum: 2. Decreases the likelihood of the model repeating the same lines verbatim.
- `presence_penalty` (number) - Optional - Minimum: -2, Maximum: 2. Increases the likelihood of the model introducing new topics.

### Request Body
(No specific request body schema provided in the input text)

### Request Example
```json
{
  "prompt": "Write a poem about Cloudflare Workers.",
  "frequency_penalty": 0.5,
  "presence_penalty": 0.2
}
```

### Response
#### Success Response (200)
- `response` (string) - The generated text response from the model.
- `usage` (object) - Usage statistics for the inference request.
  - `prompt_tokens` (number) - Total number of tokens in input.
  - `completion_tokens` (number) - Total number of tokens in output.
  - `total_tokens` (number) - Total number of input and output tokens.
- `tool_calls` (array) - An array of tool calls requests made during the response generation.
  - `items` (object) - Represents a single tool call.
    - `arguments` (object) - The arguments passed to be passed to the tool call request.
    - `name` (string) - The name of the tool to be called.

#### Response Example
```json
{
  "response": "Cloudflare Workers, a serverless way,\nTo run your code, come what may.\nEdge computing, fast and so neat,\nDeploy your apps, can't be beat.",
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 25,
    "total_tokens": 35
  },
  "tool_calls": []
}
```

#### Error Response (e.g., 400)
(No specific error response schema provided in the input text)

```

--------------------------------

### Run Inference with Public LoRA using cURL

Source: https://developers.cloudflare.com/workers/-ai/fine-tunes/public-loras

This example shows how to perform inference using a public LoRA adapter via a cURL command. It highlights the need to specify the LoRA name and use the appropriate prompt template for the model.

```bash
curl 'https://api.cloudflare.com/client/v4/accounts/:account_id/ai/run/:model_name' \
     -H "Authorization: Bearer YOUR_API_TOKEN" \
     -H "Content-Type: application/json" \
     --data '{ "text": "Your prompt here", "lora": "cf-public-magicoder" }'
```

--------------------------------

### Access Cache Outside Workers with getCaches

Source: https://developers.cloudflare.com/workers/testing/miniflare/storage/cache

Provides an example of how to access and manipulate cache data from outside a Worker using the `getCaches` method. This is useful for testing purposes.

```JavaScript
const caches = await getCaches();
const cache = await caches.open("my-named-cache");
await cache.put("/test.txt", new Response("Hello World"));
```

--------------------------------

### Generate Image using Phoenix 1.0 (curl)

Source: https://developers.cloudflare.com/workers/-ai/models/phoenix-1

Command-line example using curl to interact with the Phoenix 1.0 model. This shows how to send a POST request with JSON payload containing image generation parameters.

```bash
curl -X POST https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/leonardo/phoenix-1.0 \ 
     -H "Authorization: Bearer YOUR_API_TOKEN" \ 
     -H "Content-Type: application/json" \ 
     -d '{ 
       "prompt": "A futuristic cityscape at sunset", 
       "guidance": 8, 
       "seed": 67890, 
       "height": 512, 
       "width": 512, 
       "num_steps": 25, 
       "negative_prompt": "ugly, deformed, noisy" 
     }'
```

--------------------------------

### Stream Text Generation with Gemma 7B IT using Python

Source: https://developers.cloudflare.com/workers/-ai/models/gemma-7b-it

Example of how to generate text using the Gemma 7B IT model with Cloudflare Workers in Python. This snippet demonstrates streaming output, which is useful for real-time applications. It requires the 'requests' library for making HTTP calls.

```python
import os
import requests

url = "https://api.cloudflare.com/client/v4/accounts/" + os.environ.get("CLOUDFLARE_ACCOUNT_ID") + "/ai/v1/run/@hf/google/gemma-7b-it"

headers = {
    "Authorization": "Bearer " + os.environ.get("CLOUDFLARE_API_TOKEN")
}

data = {
    "messages": [
        {"role": "user", "content": "Write a short poem about the moon."}
    ],
    "stream": True
}

response = requests.post(url, headers=headers, json=data, stream=True)

for chunk in response.iter_content(chunk_size=1024):
    if chunk:
        print(chunk.decode('utf-8'), end='')

```

--------------------------------

### Example Event Object Structure

Source: https://developers.cloudflare.com/workers/observability/logs/tail-workers

This JSON object illustrates the structure of the `event` data that a Tail Worker receives from a producer Worker. It includes details like logs, exceptions, and the outcome of the producer's execution.

```json
{
  "outcome": {
    "status": 200,
    "statusText": "OK",
    "headers": {},
    "body": "...",
    "மையாக": "..."
  },
  "logs": [
    "Log message 1",
    "Log message 2"
  ],
  "exceptions": [
    {
      "name": "ErrorName",
      "message": "Error message",
      "stack": "..."
    }
  ],
  "மையாக": "..."
}
```

--------------------------------

### Example Usage of @cf/deepgram/nova-3 (Speech-to-Text)

Source: https://developers.cloudflare.com/workers/-ai/changelog

This speech-to-text model from Deepgram rapidly transcribes multilingual audio. It's available on Workers AI and supports WebSocket connections for real-time transcription.

```javascript
// Example usage for @cf/deepgram/nova-3 (Speech-to-Text)
// Supports multilingual audio transcription at high speed. WebSocket support available.

// Assuming you have an audio file or stream
// For simplicity, this example shows a conceptual API call.
// Actual implementation might involve uploading audio or streaming via WebSocket.

async function speechToTextNova3(audioData) {
  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/deepgram/nova-3", {
    method: "POST",
    headers: {
      "Authorization": "Bearer <YOUR_API_TOKEN>",
      "Content-Type": "audio/wav" // Or other supported audio format
    },
    body: audioData // This should be the raw audio data
  });
  const data = await response.json();
  return data.result.transcripts[0].transcript; // The exact key might vary
}

// Placeholder for actual audio data
// speechToTextNova3(yourAudioData).then(transcript => {
//   console.log("Transcription:", transcript);
// });

```

--------------------------------

### Configuring KV Namespaces with `Record<string, string>`

Source: https://developers.cloudflare.com/workers/testing/miniflare/migrations/from-v2

In Miniflare v3, options like `kvNamespaces`, `r2Buckets`, and `d1Databases` now accept `Record<string, string>` in addition to `string[]`. This allows mapping binding names to namespace IDs, bucket names, or database IDs, enabling multiple Workers to bind to the same resource under different names.

```TypeScript
{
  kvNamespaces: {
    'MY_KV': 'my-kv-namespace-id',
    'ANOTHER_KV': 'another-kv-namespace-id'
  }
}

```

--------------------------------

### Define TypeScript Types for Cloudflare Workers

Source: https://developers.cloudflare.com/workers/tutorials/build-a-slackbot

Example of defining TypeScript types for a Cloudflare Workers project, including `Bindings` for environment variables, and types for GitHub `Issue` and `User` objects, which are essential for interacting with the GitHub API.

```TypeScript
type Bindings = {
  // Define your environment variables here
}

type Issue = {
  id: number;
  title: string;
  user: User;
  // ... other issue properties
}

type User = {
  login: string;
  // ... other user properties
}

```

--------------------------------

### Python Text Generation with phi-2

Source: https://developers.cloudflare.com/workers/-ai/models/phi-2

This example shows how to interact with the phi-2 model using Python. It utilizes the `requests` library to send a prompt to the model endpoint and receive a text response. Ensure you have the necessary API keys and endpoint configured.

```python
import requests

url = "YOUR_CLOUDFLARE_WORKER_URL"
api_key = "YOUR_CLOUDFLARE_API_KEY"

headers = {
    "Authorization": f"Bearer {api_key}",
    "Content-Type": "application/json"
}

data = {
    "model": "@cf/microsoft/phi-2",
    "prompt": "Explain the concept of quantum entanglement in simple terms.",
    "max_tokens": 150
}

response = requests.post(url, json=data, headers=headers)

if response.status_code == 200:
    print(response.json())
else:
    print(f"Error: {response.status_code}")
    print(response.text)
```

--------------------------------

### Handle WebSocket Messages (JavaScript)

Source: https://developers.cloudflare.com/workers/examples/websockets

Use addEventListener to listen for the 'message' event on a WebSocket. When a message is received, you can process the data, for example, by logging it to the console.

```javascript
server.addEventListener("message", (event) => {
  console.log(`Received message: ${event.data}`);
});

```

--------------------------------

### Interacting with KV Namespace in Tests

Source: https://developers.cloudflare.com/workers/testing/miniflare/writing-tests

Demonstrates how to interact with a KV namespace from within your tests using Miniflare's `getBindings()` API. This allows testing data persistence and retrieval.

```javascript
import { Miniflare } from "miniflare";
import { test } from "node:test";
import assert from "node:assert";

test("Interact with KV Namespace", async () => {
  const mf = new Miniflare({
    script: `export default {
      async fetch(request, env, ctx) {
        await env.MY_KV.put("key", "value");
        const value = await env.MY_KV.get("key");
        return new Response(value);
      },
    }`,
    kvNamespaces: {
      MY_KV: {
        data: {
          key: "initial-value",
        }
      }
    },
  });

  const res = await mf.dispatchFetch("http://localhost:8787/");
  const text = await res.text();

  assert.strictEqual(text, "value");
});
```

--------------------------------

### Text Generation Parameters

Source: https://developers.cloudflare.com/workers/-ai/models/deepseek-math-7b-instruct

Details parameters that control the behavior of text generation models, including penalties for repetition.

```APIDOC
## Text Generation Parameters

### Description
Parameters to control the text generation model's output, such as discouraging repetition.

### Parameters

#### Query Parameters

- **frequency_penalty** (number) - Optional - Minimum value: -2, Maximum value: 2. Decreases the likelihood of the model repeating the same lines verbatim.
- **presence_penalty** (number) - Optional - Minimum value: -2, Maximum value: 2. Increases the likelihood of the model introducing new topics.

### Response

#### Success Response (200)

- **response** (string) - Required - The generated text response from the model.
- **usage** (object) - Usage statistics for the inference request.
  - **prompt_tokens** (number) - Total number of tokens in input.
  - **completion_tokens** (number) - Total number of tokens in output.
  - **total_tokens** (number) - Total number of input and output tokens.
- **tool_calls** (array) - An array of tool calls requests made during the response generation.
  - **items** (object) - Details of a tool call.
    - **arguments** (object) - The arguments passed to be passed to the tool call request.
    - **name** (string) - The name of the tool to be called.
```

--------------------------------

### Object Detection with detr-resnet-50 using cURL

Source: https://developers.cloudflare.com/workers/-ai/models/detr-resnet-50

Example of how to perform object detection using the detr-resnet-50 model via cURL. This command sends an image file to the Cloudflare API endpoint for processing.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/<account_id>/ai/run/@cf/facebook/detr-resnet-50" \
     -H "Authorization: Bearer <api_token>" \
     -H "Content-Type: application/json" \
     --data '{ "data": [ "<image_base64_encoded>" ] }'
```

--------------------------------

### Get Baseline Timestamp with performance.timeOrigin

Source: https://developers.cloudflare.com/workers/runtime-apis/performance

Shows how to access the `performance.timeOrigin` property, which provides a baseline timestamp for performance measurements. In the Workers runtime, this value is always 0.

```javascript
const timeOrigin = performance.timeOrigin;
console.log(`Performance time origin: ${timeOrigin}`); // Output: Performance time origin: 0
```

--------------------------------

### Scaffold Hono App with React SPA using npm

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/hono

This command scaffolds a new full-stack application using Hono, a React Single Page Application (SPA), and the Cloudflare Vite plugin. It sets up the project structure for rapid development on Cloudflare Workers.

```bash
npm create cloudflare@latest my-hono-app -- --template react-hono
```

--------------------------------

### Migrate from `site.entry-point` to `main`

Source: https://developers.cloudflare.com/workers/wrangler/deprecations

The `site.entry-point` configuration field, used for specifying an entry point for Workers with a `[site]` configuration, has been deprecated. It is replaced by the top-level `main` field in the Wrangler configuration.

```toml
# Deprecated:
site.entry-point = "index.js"

# Recommended:
main = "index.js"
```

--------------------------------

### Get ReadableStreamDefaultReader

Source: https://developers.cloudflare.com/workers/runtime-apis/streams/readablestreamdefaultreader

Retrieves a ReadableStreamDefaultReader from a ReadableStream to read its data. This reader is not instantiated directly.

```javascript
const reader = stream.getReader();
```

--------------------------------

### Redirect with Named Placeholder

Source: https://developers.cloudflare.com/workers/static-assets/redirects

This example shows how to use named placeholders in the source path. Placeholders are defined using a colon followed by the placeholder name (e.g., `:year`). The matched value can be used in the destination path with the same placeholder name.

```plaintext
/blog/:year/:month/:date/:slug /news/:year/:month/:date/:slug
```

--------------------------------

### Environment-Specific Webpack Configurations

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/webpack

Wrangler supports using different webpack configuration files for various environments. This example shows using `webpack.development.js` for `wrangler dev` and other configurations for production builds.

```json
{
  "environments": {
    "development": {
      "webpack_config": "webpack.development.js"
    },
    "production": {
      "webpack_config": "webpack.production.js"
    }
  }
}
```

--------------------------------

### Embed Text with baai/bge-m3 using curl

Source: https://developers.cloudflare.com/workers/-ai/models/bge-m3

This example shows how to call the baai/bge-m3 embeddings model using a curl command. It demonstrates the necessary headers, including authentication, and the JSON payload structure for embedding a single piece of text. This is useful for testing or scripting API interactions.

```bash
curl https://api.cloudflare.com/client/v4/accounts/:account_id/ai/run/@cf/baai/bge-m3 \
  -X POST \
  -H "Authorization: Bearer $CF_API_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{ "text": "What is the weather like?" }'
```

--------------------------------

### Deploy Worker with Terraform

Source: https://developers.cloudflare.com/workers/platform/infrastructure-as-code

Example of deploying a Cloudflare Worker using Terraform. Requires a local file 'my-script.mjs' and Cloudflare Terraform Provider configuration. Note that bundling is typically done separately with tools like Wrangler or esbuild.

```HCL
resource "cloudflare_worker_script" "my_worker" {
  name       = "my-worker"
  account_id = "YOUR_ACCOUNT_ID"
  content_type = "application/javascript"
  script_content = file("my-script.mjs")
}
```

--------------------------------

### Export CLOUDFLARE_API_TOKEN in Zsh

Source: https://developers.cloudflare.com/workers/wrangler/system-environment-variables

This example shows how to set the `CLOUDFLARE_API_TOKEN` environment variable by exporting it in your Zsh shell configuration file (`~/.zshrc`). This ensures the token is available for all subsequent shell sessions, commonly used for CI/CD and automation.

```bash
export CLOUDFLARE_API_TOKEN=...
```

--------------------------------

### Create Airtable-Form-Handler Worker Project (yarn)

Source: https://developers.cloudflare.com/workers/tutorials/handle-form-submissions-with-airtable

Initializes a new Cloudflare Worker project named 'airtable-form-handler' using yarn. It sets up a basic 'Hello World' Worker template with JavaScript and git version control, but defers deployment.

```bash
yarn create cloudflare
# For setup, select the following options:
# - What would you like to start with? > Hello World example
# - Which template would you like to use? > Worker only
# - Which language do you want to use? > JavaScript
# - Do you want to use git for version control? > Yes
# - Do you want to deploy your application? > No

cd airtable-form-handler
```

--------------------------------

### Python Worker Environment Variable Access

Source: https://developers.cloudflare.com/workers/languages/python

Environment variables and bindings can be accessed through the 'env' parameter in the fetch handler. This example shows how to access an 'API_HOST' environment variable.

```Python
from workers import WorkerEntrypoint, Request

class Default(WorkerEntrypoint):
    async def fetch(self, request: Request, env: dict):
        api_host = env.get("API_HOST")
        return f"API Host: {api_host}"

```

--------------------------------

### Text Generation with Mistral-Small-3.1-24b-instruct using Python

Source: https://developers.cloudflare.com/workers/-ai/models/mistral-small-3

This Python code snippet demonstrates how to use the Mistral-Small-3.1-24b-instruct model for text generation with Cloudflare Workers. It requires the `cloudflare` Python library and assumes you have your Cloudflare API credentials configured.

```python
from workers_ai import AiClient

client = AiClient("YOUR_CLOUDFLARE_API_TOKEN")

input_message = {
    "messages": [
        {"role": "user", "content": "What is the weather like in San Francisco?"}
    ]
}

response = client.run(
    "@cf/mistralai/mistral-small-3.1-24b-instruct",
    body=input_message,
    stream=True
)

for chunk in response.chunks:
    print(chunk.delta.content, end="")

```

--------------------------------

### Embed Text using curl

Source: https://developers.cloudflare.com/workers/-ai/models/embeddinggemma-300m

This snippet provides a command-line interface example using curl to interact with the EmbeddingGemma-300M model. It sends a JSON payload containing the input text and displays the resulting embedding data.

```bash
curl "@cf/google/embeddinggemma-300m" \
  -X POST \
  -H "Content-Type: application/json" \
  -d '{ "text": "Input text to embed." }'
```

--------------------------------

### Update Wrangler with npm

Source: https://developers.cloudflare.com/workers/wrangler/install-and-update

Updates the Wrangler CLI to the latest version within your project using npm. It's recommended to keep Wrangler updated for the latest features and bug fixes.

```bash
npm update wrangler
```

--------------------------------

### Cloudflare Workers No-Op Console Methods

Source: https://developers.cloudflare.com/workers/runtime-apis/console

Shows examples of console methods that are no-operations (no-ops) in Cloudflare Workers. These methods can be called but perform no action, ensuring compatibility with libraries.

```javascript
console.assert(false, "Assertion failed"); // No-op
console.countReset(); // No-op
console.dir({}); // No-op
console.dirxml(<xml>test</xml>); // No-op
console.groupCollapsed(); // No-op
console.groupEnd(); // No-op
console.profile(); // No-op
console.profileEnd(); // No-op
console.time("timer"); // No-op
console.timeEnd("timer"); // No-op
console.timeLog("timer"); // No-op
console.timeStamp("event"); // No-op
```

--------------------------------

### Configure build paths with includes and excludes

Source: https://developers.cloudflare.com/workers/ci-cd/builds/build-watch-paths

This example demonstrates how to configure build watch paths to include all changes within specific directories. It sets include paths to 'project-a/*' and 'packages/*' while leaving exclude paths empty.

```bash
Include paths: project-a/*, packages/*
Exclude paths: 
```

--------------------------------

### Upload image via URL API

Source: https://developers.cloudflare.com/workers/tutorials/generate-youtube-thumbnails-with-workers-and-images

This example demonstrates how to upload an image to Cloudflare Images using the Upload via URL API. It requires an account ID, API token with Images permission, and the URL of the image to upload.

```Shell
curl -X POST \
-H "Authorization: Bearer $API_TOKEN" \
-d 'url=$PATH_TO_IMAGE' \
https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/images/v2/direct_upload
```

--------------------------------

### Example Usage of @cf/aisingapore/gemma-sea-lion-v4-27b-it

Source: https://developers.cloudflare.com/workers/-ai/changelog

This fine-tuned model supports multiple South East Asian languages for various NLP tasks. It is available on Workers AI for regional language processing.

```javascript
// Example usage for @cf/aisingapore/gemma-sea-lion-v4-27b-it
// Supports languages like Burmese, English, Indonesian, Khmer, Lao, Malay, Mandarin, Tagalog, Tamil, Thai, and Vietnamese.

const prompt = "Translate the following English text to Thai: Hello, how are you?";

async function translateToThai(prompt) {
  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/aisingapore/gemma-sea-lion-v4-27b-it", {
    method: "POST",
    headers: {
      "Authorization": "Bearer <YOUR_API_TOKEN>",
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      "prompt": prompt
    })
  });
  const data = await response.json();
  return data.result.translated_text; // The exact key might vary, check API response structure
}

translateToThai(prompt).then(translation => {
  console.log("Translation to Thai:", translation);
});

```

--------------------------------

### Stream Text Generation with Worker (Cloudflare)

Source: https://developers.cloudflare.com/workers/-ai/models/gemma-2b-it-lora

Example of how to stream text generation using the Gemma-2B-IT-LoRA model within a Cloudflare Worker. This showcases asynchronous processing and handling of streamed responses.

```javascript
addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  const prompt = 'Write a short poem about a cat.'
  const response = await fetch('https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/google/gemma-2b-it-lora', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer {API_TOKEN}'
    },
    body: JSON.stringify({
      'prompt': prompt,
      'stream': true
    })
  })

  return new Response(response.body, {
    headers: {
      'Content-Type': 'text/plain'
    }
  })
}
```

--------------------------------

### Listing Fine-Tunes

Source: https://developers.cloudflare.com/workers/-ai/features/fine-tunes/loras

Retrieves a list of all fine-tunes created in your account.

```APIDOC
## GET /accounts/{accountId}/ai/v1/finetunes

### Description
Lists all fine-tunes associated with your Cloudflare account.

### Method
GET

### Endpoint
/accounts/{accountId}/ai/v1/finetunes

### Parameters
#### Path Parameters
- **accountId** (string) - Required - Your Cloudflare account ID.

### Response
#### Success Response (200)
- **finetunes** (array) - A list of fine-tune objects.
  - **id** (string) - The unique identifier for the fine-tune.
  - **name** (string) - The name of the fine-tune.
  - **model_id** (string) - The base model ID used for the fine-tune.
  - **status** (string) - The current status of the fine-tune.

#### Response Example
```json
{
  "finetunes": [
    {
      "id": "finetune-abc123xyz",
      "name": "my-lora-finetune",
      "model_id": "@cf/mistral/mistral-7b-instruct-v0.1",
      "status": "active"
    },
    {
      "id": "finetune-def456uvw",
      "name": "another-finetune",
      "model_id": "@cf/meta/llama-2-7b-chat-fp16",
      "status": "pending"
    }
  ]
}
```
```

--------------------------------

### Customizing Bindings with ctx.exports in Cloudflare Workers

Source: https://developers.cloudflare.com/workers/runtime-apis/bindings/worker-loader

This example demonstrates how to customize service bindings for a dynamic Worker using `ctx.exports`. By setting `ctx.props` on loopback bindings, you can pass specific properties to the Worker, further tailoring its environment and access.

```javascript
// In the parent worker
ctx.exports = {
  customService: new LoopbackService(() => new MyWorkerService(), {
    props: { workerId: 'unique-worker-123' }
  })
};

// In the dynamic worker (receiving props)
addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
});

async function handleRequest(request) {
  const workerId = request.props.workerId; // Accessing props passed from parent
  return new Response(`Hello from worker ${workerId}`);
}
```

--------------------------------

### Wrangler Configuration File (TOML)

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/astro

Sets up the Wrangler configuration file using TOML format for deploying to Cloudflare Workers, specifying the entry point and asset directory.

```toml
[build]
command = "npm run build"

[build.upload]
format = "service-worker"

[env.production.routes]
pattern = "*"
zone_name = "example.com"
zone_id = "REPLACE_WITH_ZONE_ID"

[env.production.vars]
MY_VARIABLE = "hello"

[site]
bucket_dir = "./dist"
entry_point = "worker"

```

--------------------------------

### Instantiate OpenAI Client in Cloudflare Worker (JavaScript)

Source: https://developers.cloudflare.com/workers/tutorials/openai-function-calls-workers

This snippet shows how to instantiate the OpenAI client within a Cloudflare Worker's fetch function. It assumes the OpenAI Node.js library is installed and the API key is stored as a secret named OPENAI_API_KEY.

```javascript
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});
```

--------------------------------

### Example Usage of @cf/pfnet/plamo-embedding-1b

Source: https://developers.cloudflare.com/workers/-ai/changelog

This model is used to create embeddings from Japanese text. It is part of the regional models available on Workers AI, supporting local AI labs and sovereignty.

```javascript
// Example usage for @cf/pfnet/plamo-embedding-1b
// Assuming you have a Cloudflare Worker environment set up

const text = "これは日本語のテキストです"; // Japanese text

async function getJapaneseEmbeddings(text) {
  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/pfnet/plamo-embedding-1b", {
    method: "POST",
    headers: {
      "Authorization": "Bearer <YOUR_API_TOKEN>",
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      "text": text
    })
  });
  const data = await response.json();
  return data.result.embeddings;
}

getJapaneseEmbeddings(text).then(embeddings => {
  console.log("Embeddings for Japanese text:", embeddings);
});

```

--------------------------------

### Use Llama Guard with Cloudflare Workers (Streaming)

Source: https://developers.cloudflare.com/workers/-ai/models/llamaguard-7b-awq

This code snippet demonstrates how to use the Llama Guard model with Cloudflare Workers for streaming text generation. It requires no setup or authentication and allows for instant preview and testing.

```javascript
addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  const url = new URL(request.url);
  const prompt = url.searchParams.get('prompt') || 'Hello, world!';

  const response = await fetch('https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/meta/llama-2-7b-chat-fp16', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer {API_TOKEN}',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      prompt: `[INST] ${prompt} [/INST] `,
      stream: true
    })
  });

  return new Response(response.body, {
    headers: {
      'Content-Type': 'text/plain'
    }
  });
}
```

--------------------------------

### Create New RedwoodSDK Project

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/redwoodsdk

Command to create a new RedwoodSDK project. Replace `<project-name>` with your desired project name.

```bash
npm create redwoodsdk@latest <project-name>
```

```bash
yarn create redwoodsdk <project-name>
```

```bash
pnpm create redwoodsdk <project-name>
```

--------------------------------

### Streaming Worker for Llama 3 8B Instruct

Source: https://developers.cloudflare.com/workers/-ai/models/llama-3-8b-instruct

This example illustrates a Cloudflare Worker designed for streaming responses from the Llama 3 8B Instruct model. It utilizes the `ReadableStream` API to send back generated text chunks as they become available, providing a more interactive user experience. Proper handling of the AI model's streaming output and conversion to a client-readable stream is crucial.

```javascript
export default {
  async fetch(request, env, ctx) {
    const API_TOKEN = env.CF_API_TOKEN;
    const ACCOUNT_ID = env.CF_ACCOUNT_ID;
    const modelUrl = `https://api.cloudflare.com/client/v4/accounts/${ACCOUNT_ID}/ai/run/@cf/meta/llama-3-8b-instruct`;

    if (request.method === "POST") {
      const body = await request.json();
      const prompt = body.prompt;

      if (!prompt) {
        return new Response("Prompt is required", { status: 400 });
      }

      const stream = await fetch(modelUrl, {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${API_TOKEN}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          prompt: prompt,
          stream: true, // Indicate streaming is requested
          max_tokens: 100 // Example parameter, adjust as needed
        }),
      });

      if (!stream.ok) {
        const errorBody = await stream.text();
        return new Response(`Error from AI API: ${errorBody}`, { status: stream.status });
      }

      // Return the stream directly to the client
      return new Response(stream.body, {
        headers: {
          "Content-Type": "text/event-stream", // Standard MIME type for Server-Sent Events
        },
      });

    } else {
      return new Response("Method not allowed", { status: 405 });
    }
  },
};
```

--------------------------------

### Wrangler Configuration for SPA Asset Handling

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/react

Configures Wrangler to handle assets for a Single Page Application (SPA). Setting `assets.not_found_handling` to `"single-page-application"` ensures that routes handled by the React SPA are not directed to the Worker.

```json
{
  "main": "worker/index.ts",
  "compatibility_flags": [
    "nodejs_compat"
  ],
  "assets": {
    "src/index.html": "public",
    "not_found_handling": "single-page-application"
  }
}

```

--------------------------------

### Wrangler Docs Command with Search

Source: https://developers.cloudflare.com/workers/wrangler/commands

Opens the Cloudflare developer documentation and performs a search for the specified terms. The `--search` flag allows users to directly find information about specific Wrangler commands or concepts.

```bash
wrangler docs --search "deploy command"

```

--------------------------------

### Worker Text Generation with Llama-2-7b-chat-hf-lora

Source: https://developers.cloudflare.com/workers/-ai/models/llama-2-7b-chat-hf-lora

Example demonstrating how to perform non-streaming text generation using the Llama-2-7b-chat-hf-lora model within a Cloudflare Worker. This is suitable for tasks where a complete response is needed at once.

```javascript
import { generate } from "cloudflare:ai";

export default {
  async fetch(request) {
    const prompt = "Write a short poem about the moon.";

    const response = await generate("@cf/meta-llama/llama-2-7b-chat-hf-lora", {
      prompt: prompt,
    });

    return new Response(response.text);
  },
};
```

--------------------------------

### Example Usage of @cf/ai4bharat/indictrans2-en-indic-1B

Source: https://developers.cloudflare.com/workers/-ai/changelog

This translation model facilitates translation between 22 Indic languages, including low-resourced ones. It's part of the regional models on Workers AI for diverse language support.

```javascript
// Example usage for @cf/ai4bharat/indictrans2-en-indic-1B
// Supports translation between 22 Indic languages.

const textToTranslate = "How are you?"; // English text
const targetLanguage = "hi"; // Hindi

async function translateIndic(text, targetLang) {
  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/ai4bharat/indictrans2-en-indic-1B", {
    method: "POST",
    headers: {
      "Authorization": "Bearer <YOUR_API_TOKEN>",
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      "text": text,
      "target_lang": targetLang
    })
  });
  const data = await response.json();
  return data.result.translated_text; // The exact key might vary
}

translateIndic(textToTranslate, targetLanguage).then(translation => {
  console.log(`Translation to Hindi: ${translation}`);
});

```

--------------------------------

### R2 Bindings: `GetObject` Range Parameter

Source: https://developers.cloudflare.com/workers/platform/changelog/historical-changelog

Ensures R2 GET requests made with the `range` option contain the returned range in the `GetObject`’s `range` parameter.

```JavaScript
// R2 GET requests made with the `range` option now contain the returned range in the `GetObject`’s `range` parameter.
```

--------------------------------

### Upload LoRA Adapter using Wrangler

Source: https://developers.cloudflare.com/workers/-ai/fine-tunes/loras

Commands to create a finetune and upload LoRA adapter files using Wrangler. Requires adapter_model.safetensors and adapter_config.json.

```bash
wrangler finetune create <your-finetune-name>
wrangler finetune upload <your-finetune-name> --file adapter_model.safetensors
wrangler finetune upload <your-finetune-name> --file adapter_config.json
```

--------------------------------

### Stream Text Generation with Cloudflare Workers

Source: https://developers.cloudflare.com/workers/-ai/models/openchat-3

Example of how to use the OpenChat-3.5-0106 model within a Cloudflare Worker to generate text with streaming capabilities. This approach is suitable for real-time responses and dynamic applications.

```typescript
export default {
  async fetch(request: Request): Promise<Response> {
    const prompt = "What is the weather like today?";
    const response = await fetch("https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/openchat/openchat-3.5-0106", {
      method: "POST",
      headers: {
        "Authorization": "Bearer {API_TOKEN}",
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        "prompt": prompt
      })
    });

    if (!response.ok) {
      return new Response("Error from AI API", {
        status: response.status
      });
    }

    const reader = response.body?.getReader();
    if (!reader) {
      return new Response("Failed to get response body reader", {
        status: 500
      });
    }

    const stream = new ReadableStream({
      async pull(controller) {
        const { done, value } = await reader.read();
        if (done) {
          controller.close();
          return;
        }
        controller.enqueue(value);
      }
    });

    return new Response(stream, {
      headers: {
        "Content-Type": "text/plain"
      }
    });
  }
}
```

--------------------------------

### docs Command

Source: https://developers.cloudflare.com/workers/wrangler/commands

Opens the Cloudflare developer documentation in your default browser, with optional search functionality.

```APIDOC
## `docs` Command

Open the Cloudflare developer documentation in your default browser.

### Method

`wrangler docs`

### Parameters

#### Query Parameters

- `--search` (string) - Optional - Enter search terms (e.g. the wrangler command) you want to know more about
- `--yes` (boolean) - Optional, alias: `--y` - Takes you to the docs, even if search fails

#### Global Flags

- `--v` (boolean) alias: `--version` - Show version number
- `--cwd` (string) - Run as if Wrangler was started in the specified directory instead of the current working directory
- `--config` (string) alias: `--c` - Path to Wrangler configuration file
- `--env` (string) alias: `--e` - Environment to use for operations, and for selecting .env and .dev.vars files
- `--env-file` (string) - Path to an .env file to load - can be specified multiple times - values from earlier files are overridden by values in later files
- `--experimental-remote-bindings` (boolean) aliases: `--x-remote-bindings` default: true - Experimental: Enable Remote Bindings
- `--experimental-provision` (boolean) aliases: `--x-provision` - Experimental: Enable automatic resource provisioning

### Request Example

```bash
wrangler docs --search "kv namespace"
wrangler docs -y
```

### Response

This command opens a URL in the default browser and does not produce a direct command-line response other than potential error messages.
```

--------------------------------

### Generate Text with llama-2-7b-chat-fp16 using cURL

Source: https://developers.cloudflare.com/workers/-ai/models/llama-2-7b-chat-fp16

Example of how to use cURL to send a request to the llama-2-7b-chat-fp16 model. This is useful for testing the API endpoint directly from the command line or in shell scripts.

```bash
curl -X POST \
  https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/meta/llama-2-7b-chat-fp16 \
  -H "Authorization: Bearer <CLOUDFLARE_API_TOKEN>" \
  -H "Content-Type: application/json" \
  -d '{ "prompt": "What is the capital of France?" }'
```

--------------------------------

### Embed Japanese Text with curl

Source: https://developers.cloudflare.com/workers/-ai/models/plamo-embedding-1b

Shows how to use the `curl` command-line tool to send Japanese text to the PLaMo-Embedding-1B model API. This example details the necessary headers, including authorization and content type, and the JSON payload structure for embedding text.

```bash
curl "https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/pfnet/plamo-embedding-1b" \
     -X POST \
     -H "Authorization: Bearer {API_TOKEN}" \
     -H "Content-Type: application/json" \
     -d '{ "text": "これはテストです" }'
```

--------------------------------

### Generate Image with Cloudflare Workers (TypeScript)

Source: https://developers.cloudflare.com/workers/-ai/models/stable-diffusion-xl-base-1

Example of using the Stable Diffusion XL 1.0 model with Cloudflare Workers in TypeScript. It demonstrates sending a prompt to the model and handling the resulting image stream.

```typescript
import { StabilityAI } from "@cloudflare/ai";

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const prompt = "A majestic cat wearing a crown, digital art";
    const ai = new StabilityAI(env.AI);

    const imageStream = await ai.generate("stabilityai/stable-diffusion-xl-base-1.0", [
      {
        prompt: prompt,
        width: 1024,
        height: 1024,
      },
    ]);

    return new Response(imageStream, {
      headers: {
        "content-type": "image/jpeg",
      },
    });
  },
};

interface Env {
  AI: any;
}
```

--------------------------------

### Worker - Streaming Text Generation with OpenHermes-2.5-Mistral-7B-AWQ

Source: https://developers.cloudflare.com/workers/-ai/models/openhermes-2

Example demonstrating how to use the OpenHermes-2.5-Mistral-7B-AWQ model within a Cloudflare Worker for streaming text generation. This typically involves making an HTTP POST request to the model's endpoint with the desired prompt and parameters. No external libraries are strictly required for basic usage within the Worker environment, as Cloudflare's runtime provides fetch capabilities.

```javascript
addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  const url = new URL(request.url)
  const prompt = url.searchParams.get('prompt') || 'Tell me a story.'

  const response = await fetch('https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@hf/thebloke/openhermes-2.5-mistral-7b-awq', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer <API_TOKEN>`, 
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      prompt: prompt,
      stream: true
    })
  })

  return new Response(response.body, {
    headers: {
      'Content-Type': 'text/plain'
    }
  })
}
```

--------------------------------

### Get ReadableStream Reader

Source: https://developers.cloudflare.com/workers/runtime-apis/streams/readablestream

Retrieves a ReadableStreamDefaultReader or ReadableStreamBYOBReader for the stream, locking the stream to the reader. The 'mode' option can be used to specify the reader type.

```javascript
readableStream.getReader(optionsObject)
```

--------------------------------

### Access Cloudflare Bindings in SolidJS

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/solid

Integrate Cloudflare platform primitives, including bindings, within your SolidJS application. Access environment variables and other Cloudflare services using `getRequestEvent().nativeEvent.context.cloudflare.env`.

```javascript
getRequestEvent().nativeEvent.context.cloudflare.env
```

--------------------------------

### Stream Text Generation with Gemma 7B IT using cURL

Source: https://developers.cloudflare.com/workers/-ai/models/gemma-7b-it

Example of how to generate text using the Gemma 7B IT model with Cloudflare Workers via cURL. This command-line snippet shows how to interact with the API for streaming text generation without needing a full programming environment.

```bash
curl https://api.cloudflare.com/client/v4/accounts/$CLOUDFLARE_ACCOUNT_ID/ai/v1/run/@hf/google/gemma-7b-it \
  -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{ "messages": [ { "role": "user", "content": "Explain the concept of recursion." } ], "stream": true }' \
  --no-buffer
```

--------------------------------

### Example Usage of @cf/deepgram/aura-1 (Text-to-Speech)

Source: https://developers.cloudflare.com/workers/-ai/changelog

This text-to-speech model from Deepgram allows users to input text and generate speech with customizable voices. It's available on Workers AI with WebSocket support.

```javascript
// Example usage for @cf/deepgram/aura-1 (Text-to-Speech)
// WebSocket support is available for audio models.

const textToSpeak = "Hello from Cloudflare Workers AI!";
const voice = "aura-1-native-en-us-male-1"; // Example voice, check Deepgram docs for available voices

async function textToSpeechAura1(text, voice) {
  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/deepgram/aura-1", {
    method: "POST",
    headers: {
      "Authorization": "Bearer <YOUR_API_TOKEN>",
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      "text": text,
      "voice": voice
    })
  });
  const audioBlob = await response.blob();
  return audioBlob; // Returns an AudioBlob
}

textToSpeechAura1(textToSpeak, voice).then(audioBlob => {
  // You can then create an audio element or process the blob further
  console.log("Audio blob generated:", audioBlob);
});

```

--------------------------------

### Integration Test using `SELF` Fetcher (TypeScript)

Source: https://developers.cloudflare.com/workers/testing/vitest-integration/write-your-first-test

Write an integration test in TypeScript using the `SELF` fetcher provided by `cloudflare:test`. This enables testing the Worker's `fetch` handler in an integrated environment.

```typescript
import { describe, it, expect } from 'vitest';

describe('Integration Test', () => {
  it('can call the Worker using SELF', async () => {
    // 'SELF' is a service binding to the default export defined in the main Worker
    const response = await SELF.fetch('http://localhost/');
    expect(response.status).toBe(200);
    expect(await response.text()).toBe('Hello World!');
  });
});
```

--------------------------------

### Cloudflare Worker Backend API Example

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/vue

A basic Cloudflare Worker script that serves as a backend API. It includes a single endpoint `/api/` that returns a text response, which can be fetched by the Vue frontend.

```typescript
import { Hono } from 'hono';
import { serveStatic } from 'hono/serve-static';

type Bindings = {
  // Define your bindings here
  // MY_KV_NAMESPACE: KVNamespace;
};

const app = new Hono<{ Bindings: Bindings }>();

app.get('/', serveStatic({ root: './' }));

app.get('/api/', async (c) => {
  const message = 'Hello from Cloudflare Worker!';
  return c.text(message);
});

app.get('*', serveStatic({ root: './' }));

export default {
  fetch: app.fetch,
};

```

--------------------------------

### Translate Text using curl

Source: https://developers.cloudflare.com/workers/-ai/models/m2m100-1

Provides a command-line example using curl to interact with the m2m100-1.2b translation model deployed on Cloudflare Workers. It shows how to send translation requests via HTTP POST.

```bash
# Single translation
curl "YOUR_WORKER_URL/run/@cf/meta/m2m100-1.2b" \
  -X POST \
  -H "Content-Type: application/json" \
  -d '{ "text": "Hello, world!", "source_lang": "en", "target_lang": "es" }'

# Batch translation
curl "YOUR_WORKER_URL/run/@cf/meta/m2m100-1.2b" \
  -X POST \
  -H "Content-Type: application/json" \
  -d '{ "requests": [ { "text": "Hello, world!", "source_lang": "en", "target_lang": "es" }, { "text": "How are you?", "source_lang": "en", "target_lang": "fr" } ] }'
```

--------------------------------

### Cloudflare Workers API Input Structure Example

Source: https://developers.cloudflare.com/workers/-ai/models/llamaguard-7b-awq

This JSON structure outlines the expected input format for Cloudflare Workers API requests, likely for text generation or similar AI-driven tasks. It includes placeholders for parameters and the core request content.

```json
{
  "input": {},
  "output": {}
}
```

--------------------------------

### Create KV Namespace with Wrangler

Source: https://developers.cloudflare.com/workers/tutorials/build-a-jamstack-app

This command creates a new Cloudflare Workers KV namespace named 'TODOS'. You can use the `--preview` flag to interact with a preview namespace instead of a production one.

```bash
wrangler kv namespace create TODOS
```

--------------------------------

### Vite Configuration for Cloudflare

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/hono

This `vite.config.ts` file configures Vite for your project, integrating it with the Cloudflare Vite plugin. This setup ensures your application runs in the Cloudflare Workers runtime locally, providing an environment close to production and enabling access to local binding emulations.

```typescript
import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';
import { vitePlugin } from '@cloudflare/vite-plugin-cloudflare';

export default defineConfig({
  plugins: [
    vitePlugin({ 
      // The Vite plugin for Cloudflare Workers
      // See https://developers.cloudflare.com/workers/plugins/vite/
    }),
    react(),
  ],
  server: {
    // Enable HMR (Hot Module Replacement)
    hmr: {
      protocol: 'ws',
      host: 'localhost',
    },
  },
});

```

--------------------------------

### Vite Configuration for Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/vue

Configure Vite to use the Cloudflare Vite plugin for local development and building. This setup ensures the application runs within the Cloudflare Workers runtime.

```typescript
import { defineConfig } from 'vite';
import vue from '@vitejs/plugin-vue';
import { viteStaticCopy } from 'vite-plugin-static-copy';
import { cloudflare } from '@cloudflare/vite-plugin-cloudflare';

export default defineConfig({
  plugins: [
    vue(),
    cloudflare({ 
      // Optional: Configure your Worker's bindings here
      // bindings: {
      //   MY_KV_NAMESPACE: {
      //     type: 'kv_namespace',
      //     id: 'MY_KV_NAMESPACE_ID',
      //   },
      // }, 
    }),
    viteStaticCopy({
      targets: [
        {
          src: 'public',
          dest: './'
        }
      ]
    })
  ],
});

```

--------------------------------

### Tail Worker Example (JavaScript)

Source: https://developers.cloudflare.com/workers/observability/logs/tail-workers

This JavaScript code demonstrates a basic Tail Worker that captures events from a producer Worker and sends them to a specified HTTP endpoint. It utilizes the `tail()` handler to process incoming event data.

```javascript
export default {
  async tail(event) {
    // event is an object containing information about the producer Worker's execution
    // For example: event.logs, event.exceptions, event.outcome

    // Send the event data to an HTTP endpoint
    await fetch('YOUR_HTTP_ENDPOINT', {
      method: 'POST',
      body: JSON.stringify(event),
      headers: {
        'Content-Type': 'application/json'
      }
    });
  }
};
```

--------------------------------

### Image Captioning with uform-gen2-qwen-500m in Workers (TypeScript)

Source: https://developers.cloudflare.com/workers/-ai/models/uform-gen2-qwen-500m

Demonstrates how to use the uform-gen2-qwen-500m model within Cloudflare Workers using TypeScript for image captioning. It requires image data and an optional prompt for guiding the generation. Ensure the image data is correctly formatted as a binary string.

```typescript
import { Ai } from "@cloudflare/ai";

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const ai = new Ai(env.AI);

    // Assuming you have image data as a binary string
    const imageData = await request.arrayBuffer();
    const imageBinaryString = Buffer.from(imageData).toString("binary");

    const messages = [
      {
        role: "user",
        content: [
          { type: "text", text: "Describe this image." },
          { type: "image", image: imageBinaryString },
        ],
      }
    ];

    const response = await ai.run(
      "@cf/unum/uform-gen2-qwen-500m",
      {
        messages,
        stream: false, // Set to true for streaming responses
      }
    );

    return new Response(JSON.stringify(response), {
      headers: {
        "content-type": "application/json",
      },
    });
  },
};

// Define your Env interface if not already defined
interface Env {
  AI: any;
}
```

--------------------------------

### Object Detection with detr-resnet-50 using Workers (TypeScript)

Source: https://developers.cloudflare.com/workers/-ai/models/detr-resnet-50

Example of how to perform object detection using the detr-resnet-50 model within a Cloudflare Worker using TypeScript. It demonstrates sending an image for detection and processing the results.

```typescript
export default {
  async fetch(request: Request): Promise<Response> {
    const image = await request.arrayBuffer();

    const res = await fetch("https://api.cloudflare.com/client/v4/accounts/<account_id>/ai/run/@cf/facebook/detr-resnet-50", {
      method: "POST",
      headers: {
        "Authorization": "Bearer <api_token>",
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        "data": [
          image
        ]
      })
    });

    const data = await res.json();

    return new Response(JSON.stringify(data), {
      headers: {"content-type": "application/json"}
    });
  }
}
```

--------------------------------

### Curl Usage for bge-reranker-base

Source: https://developers.cloudflare.com/workers/-ai/models/bge-reranker-base

This example demonstrates how to invoke the bge-reranker-base model using curl. It specifies the POST request method, necessary headers including authorization and content type, and the JSON payload containing the query, top_k, and contexts for reranking.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/baai/bge-reranker-base" \
     -H "Authorization: Bearer {API_TOKEN}" \
     -H "Content-Type: application/json" \
     -d '{ "query": "What is the capital of France?", "top_k": 3, "contexts": [ { "text": "France is a country in Europe." }, { "text": "The capital of France is Paris." }, { "text": "The Eiffel Tower is in Paris." } ] }'
```

--------------------------------

### Start Remote Proxy Session for Cloudflare Workers Bindings

Source: https://developers.cloudflare.com/workers/development-testing

Initiates a proxy session to interact with remote Cloudflare bindings. Requires Cloudflare account ID and API token for authentication. Returns an object with session control functions and connection string.

```typescript
import {
  startRemoteProxySession,
  StartDevWorkerInput
} from "wrangler";

async function setupRemoteSession() {
  const session = await startRemoteProxySession({
    bindings: { /* your bindings */ } as StartDevWorkerInput['bindings'],
    auth: {
      accountId: "YOUR_CLOUDFLARE_ACCOUNT_ID",
      apiToken: "YOUR_CLOUDFLARE_API_TOKEN"
    }
  });

  await session.ready;
  console.log("Session ready!");

  // To stop the session later:
  // await session.dispose();

  // To update bindings:
  // await session.updateBindings({ /* new bindings */ });

  // Use session.remoteProxyConnectionString with Miniflare
  console.log(session.remoteProxyConnectionString);
}
```

--------------------------------

### Exclude specific directories from builds

Source: https://developers.cloudflare.com/workers/ci-cd/builds/build-watch-paths

This example shows how to trigger builds for any changes but exclude modifications within a specific directory, such as 'docs/'. It includes all paths by default and excludes the 'docs/*' directory.

```bash
Include paths: *
Exclude paths: docs/*
```

--------------------------------

### Upload User Worker to Dispatch Namespace (curl)

Source: https://developers.cloudflare.com/workers/platform/infrastructure-as-code

Example of uploading a User Worker to a dispatch namespace using `curl`. The API endpoint differs for Workers for Platforms, targeting a specific dispatch namespace and script name.

```Bash
curl -X PUT "https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/workers/dispatch/namespaces/$DISPATCH_NAMESPACE/scripts/$SCRIPT_NAME" \
     -H "Authorization: Bearer YOUR_API_TOKEN" \
     -H "Content-Type: application/javascript" \
     --data-binary @my-platform-worker.mjs
```

--------------------------------

### Deploy Worker with Wrangler CLI

Source: https://developers.cloudflare.com/workers/ci-cd/external-cicd/gitlab-cicd

This snippet shows the command to deploy a Cloudflare Worker using the Wrangler CLI within a CI/CD script. It assumes Wrangler is installed and configured.

```bash
npx wrangler deploy
```

--------------------------------

### Worker Streaming Text Generation with Llama-2-7b-chat-hf-lora

Source: https://developers.cloudflare.com/workers/-ai/models/llama-2-7b-chat-hf-lora

Example demonstrating how to perform streaming text generation using the Llama-2-7b-chat-hf-lora model within a Cloudflare Worker. This is useful for real-time responses in chat applications.

```javascript
import { stream } from "cloudflare:ai";

export default {
  async fetch(request) {
    const prompt = "What is the speed of light?";

    const response = await stream("@cf/meta-llama/llama-2-7b-chat-hf-lora", {
      prompt: prompt,
    });

    return new Response(response.toReadableStream(), {
      headers: {"content-type": "text/event-stream"},
    });
  },
};
```

--------------------------------

### Python Worker for Llama 3 8B Instruct

Source: https://developers.cloudflare.com/workers/-ai/models/llama-3-8b-instruct

Example of a Python Cloudflare Worker to process requests for the Llama 3 8B Instruct model. This code snippet outlines the basic structure for handling incoming requests, extracting data, and making a call to the AI model API. It requires the `requests` library and assumes an environment where Cloudflare Workers can execute Python.

```python
import requests
import os

# Retrieve Cloudflare API credentials from environment variables
ACCOUNT_ID = os.environ.get("CF_ACCOUNT_ID")
API_TOKEN = os.environ.get("CF_API_TOKEN")

MODEL_URL = f"https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/meta/llama-3-8b-instruct"

def generate_text(prompt):
    headers = {
        "Authorization": f"Bearer {API_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {
        "prompt": prompt,
        "max_tokens": 100 # Example parameter, adjust as needed
    }
    
    try:
        response = requests.post(MODEL_URL, headers=headers, json=payload)
        response.raise_for_status() # Raise an exception for bad status codes
        return response.json()
    except requests.exceptions.RequestException as e:
        return {"error": str(e)}

# Example usage (within a Cloudflare Worker context):
# async def onRequest(request):
#     data = await request.json()
#     prompt = data.get("prompt")
#     if not prompt:
#         return new Response("Prompt is required", status=400)
#     result = generate_text(prompt)
#     return new Response(json.dumps(result), headers={"Content-Type": "application/json"})

```

--------------------------------

### Create a new Worker project from an existing Git repository

Source: https://developers.cloudflare.com/workers/get-started/guide

Create a new Cloudflare Worker project by cloning an existing Git repository. C3 supports various Git source formats, including GitHub, Bitbucket, and GitLab.

```bash
npx c3 create <SOURCE>
```

--------------------------------

### Example of Incorrect Header Logging in JavaScript

Source: https://developers.cloudflare.com/workers/examples/logging-headers

Demonstrates common incorrect methods for logging Headers objects in JavaScript, which result in an empty object '{}' being displayed in the console due to the opaque nature of Headers objects.

```JavaScript
console.log(request.headers);
```

```JavaScript
console.log(JSON.stringify(request.headers));
```

--------------------------------

### Console Logging Limit in Cloudflare Workers

Source: https://developers.cloudflare.com/workers/platform/limits

This example shows how `console.log()` statements contribute to the overall log size limit per request. Exceeding the 256 KB limit will result in truncated logs.

```javascript
console.log("This is a log message.");
// Ensure total log output per request does not exceed 256 KB.
```

--------------------------------

### Wrangler Commands Overview

Source: https://developers.cloudflare.com/workers/wrangler/commands

A list of available Wrangler commands and their general purpose.

```APIDOC
## Wrangler Commands Overview

Wrangler offers a number of commands to manage your Cloudflare Workers.

* `docs` - Open this page in your default browser.
* `init` - Create a new project from a variety of web frameworks and templates.
* `containers` - Interact with Containers.
* `d1` - Interact with D1.
* `vectorize` - Interact with Vectorize indexes.
* `hyperdrive` - Manage your Hyperdrives.
* `deploy` - Deploy your Worker to Cloudflare.
* `dev` - Start a local server for developing your Worker.
* `delete` - Delete your Worker from Cloudflare.
* `kv namespace` - Manage Workers KV namespaces.
* `kv key` - Manage key-value pairs within a Workers KV namespace.
* `kv bulk` - Manage multiple key-value pairs within a Workers KV namespace in batches.
* `r2 bucket` - Manage Workers R2 buckets.
* `r2 object` - Manage Workers R2 objects.
* `r2 sql` - Query tables in R2 Data Catalog with R2 SQL.
* `secret` - Manage the secret variables for a Worker.
* `secret bulk` - Manage multiple secret variables for a Worker.
* `secrets-store secret` - Manage account secrets within a secrets store.
* `secrets-store store` - Manage your store within secrets store.
* `workflows` - Manage and configure Workflows.
* `tail` - Start a session to livestream logs from a deployed Worker.
* `pages` - Configure Cloudflare Pages.
* `pipelines` - Configure Cloudflare Pipelines.
* `queues` - Configure Workers Queues.
* `login` - Authorize Wrangler with your Cloudflare account using OAuth.
* `logout` - Remove Wrangler’s authorization for accessing your account.
* `whoami` - Retrieve your user information and test your authentication configuration.
* `versions` - Retrieve details for recent versions.
* `deployments` - Retrieve details for recent deployments.
* `rollback` - Rollback to a recent deployment.
* `dispatch-namespace` - Interact with a dispatch namespace.
* `mtls-certificate` - Manage certificates used for mTLS connections.
* `cert` - Manage certificates used for mTLS and Certificate Authority (CA) chain connections.
* `types` - Generate types from bindings and module rules in configuration.
* `telemetry` - Configure whether Wrangler can collect anonymous usage data.
* `check` - Validate your Worker.
```

--------------------------------

### R2 Bindings: Conditional Uploads with `onlyIf`

Source: https://developers.cloudflare.com/workers/platform/changelog/historical-changelog

Adds an `onlyIf` field to R2 `put` bindings options, similar to `get`, enabling conditional uploads based on specific criteria.

```JavaScript
// R2 `put` bindings options can now have an `onlyIf` field similar to `get` that does a conditional upload.
```

--------------------------------

### Local Development with Wrangler

Source: https://developers.cloudflare.com/workers/languages/python/how-python-workers-work

This snippet illustrates the configuration for local development of Python Workers using Wrangler. It shows how Wrangler determines the Pyodide version, creates a V8 isolate, and injects Pyodide to serve Python code.

```JavaScript
npx wrangler@latest dev
```

--------------------------------

### Split Text into Chunks (JavaScript)

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/build-a-retrieval-augmented-generation-ai

This code demonstrates how to use the `RecursiveCharacterTextSplitter` from `@langchain/textsplitters` to break down large text into smaller, manageable chunks. This is beneficial for LLMs with limited context windows and improves RAG workflows. Requires installation of the package.

```javascript
import { RecursiveCharacterTextSplitter } from '@langchain/textsplitters';

// Inside your POST /notes route handler or similar

const splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 1000, // Adjust chunk size as needed
  chunkOverlap: 200, // Adjust overlap as needed
});

const textToSplit = "Your long text content goes here...";
const chunks = await splitter.splitText(textToSplit);

// Iterate over chunks and process each one
for (const chunk of chunks) {
  // Embed the chunk and store it in Vectorize
  // ... your embedding and Vectorize storage logic ...
}

```

--------------------------------

### Local Development Server for Vue with Cloudflare Vite Plugin

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/vue

Start a local development server to preview your Vue application during development. The Cloudflare Vite plugin ensures the local environment closely matches the production Cloudflare Workers runtime.

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
```

--------------------------------

### Run Inference with Public LoRA (cURL)

Source: https://developers.cloudflare.com/workers/-ai/features/fine-tunes/public-loras

Example using cURL to run inference with a specified public LoRA adapter. Replace placeholders with your actual account ID, API token, and desired LoRA name and prompt.

```bash
curl https://api.cloudflare.com/client/v4/accounts/:account_id/ai/run/:model \
  -X POST \
  -H "Authorization: Bearer YOUR_API_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{ "lora": "cf-public-magicoder", "prompt": "Write a python function to calculate fibonacci sequence." }'
```

--------------------------------

### Calling another Worker using ctx.exports and RPC

Source: https://developers.cloudflare.com/workers/runtime-apis/context

This JavaScript example shows how a default fetch handler in one Worker can call another Worker's export (`Greeter`) using RPC. `ctx.exports` automatically provides a Service Binding for top-level exports that extend `WorkerEntrypoint`, eliminating the need for manual configuration.

```javascript
import { Greeter } from './greeter';

export default {
  async fetch(request, env, ctx) {
    // Call the Greeter export over RPC
    const greeter = ctx.exports.Greeter;
    return await greeter.fetch(request);
  }
};
```

--------------------------------

### Getting High Resolution Time with performance.now()

Source: https://developers.cloudflare.com/workers/runtime-apis/web-standards

The performance.now() method returns a DOMHighResTimeStamp representing the number of milliseconds elapsed since performance.timeOrigin. In Cloudflare Workers, performance.now() equals Date.now().

```JavaScript
console.log(`Time origin: ${performance.timeOrigin}`);
console.log(`Current time: ${performance.now()}`);
console.log(`Date.now(): ${Date.now()}`);
```

--------------------------------

### Rust Worker entrypoint with fetch event

Source: https://developers.cloudflare.com/workers/languages/rust

This Rust code snippet demonstrates the basic structure of a Cloudflare Worker using the `workers-rs` crate. It defines an entrypoint for handling incoming HTTP requests using the `fetch` event macro.

```rust
#[event(fetch)]
async fn main(req: Request, env: Env, ctx: Context) -> Result<Response> {
    // Your Worker logic here
    Ok(Response::ok("Hello from Worker!"))
}
```

--------------------------------

### Set Environment Variables for Staging in .env.staging

Source: https://developers.cloudflare.com/workers/development-testing/environment-variables

Provides an example of defining environment-specific variables for a 'staging' environment using the `.env.staging` file. This enables granular control over configurations for different deployment stages.

```dotenv
STAGING_VARIABLE="staging value"
API_KEY="staging_api_key"
```

--------------------------------

### Text Generation Parameters

Source: https://developers.cloudflare.com/workers/-ai/models/openhermes-2

Parameters for controlling text generation, including penalties for repetition and the introduction of new topics.

```APIDOC
## Text Generation Parameters

### Description
Parameters for controlling text generation, including penalties for repetition and the introduction of new topics.

### Parameters
#### Query Parameters
- **frequency_penalty** (number) - min -2 max 2 - Decreases the likelihood of the model repeating the same lines verbatim.
- **presence_penalty** (number) - min -2 max 2 - Increases the likelihood of the model introducing new topics.
```

--------------------------------

### Generate Image using Phoenix 1.0 (TypeScript)

Source: https://developers.cloudflare.com/workers/-ai/models/phoenix-1

Example of how to generate an image using the Phoenix 1.0 model within a Cloudflare Worker using TypeScript. This snippet demonstrates setting up the request with required and optional parameters.

```typescript
import { Ai } from "@cloudflare/ai";

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const API_URL = `https://api.cloudflare.com/client/v4/accounts/${env.ACCOUNT_ID}/ai/run/@cf/leonardo/phoenix-1.0`;
    const ai = new Ai(env.AI);

    const prompt = "A majestic dragon soaring over a fantasy castle";
    const guidance = 7;
    const seed = 12345;
    const height = 1024;
    const width = 1024;
    const num_steps = 30;
    const negative_prompt = "low quality, blurry, distorted";

    const response = await ai.run({
      model: "@cf/leonardo/phoenix-1.0",
      prompt: prompt,
      guidance: guidance,
      seed: seed,
      height: height,
      width: width,
      num_steps: num_steps,
      negative_prompt: negative_prompt,
    });

    // The response will contain a ReadableStream of the image data
    return new Response(response as any, {
      headers: {
        "Content-Type": "image/jpeg", // Or 'image/png' depending on model output
      },
    });
  },
};

interface Env {
  AI: any;
  ACCOUNT_ID: string;
}
```

--------------------------------

### Text Generation with Cloudflare Workers (Python)

Source: https://developers.cloudflare.com/workers/-ai/models/deepseek-coder-6

Provides a Python example for interacting with the Deepseek Coder model via Cloudflare Workers. This typically involves making an HTTP POST request to the Worker endpoint with the desired prompt.

```python
import requests

worker_url = "<YOUR_WORKER_URL>"
prompt = "Write a Python function to calculate the factorial of a number."

response = requests.post(worker_url, json={'prompt': prompt})

if response.status_code == 200:
    print(response.text)
else:
    print(f"Error: {response.status_code}")
    print(response.text)
```

--------------------------------

### Profile Worker Startup Performance with Wrangler CLI

Source: https://developers.cloudflare.com/workers/wrangler/commands

Generates a CPU profile of your Worker's startup phase for performance analysis. The profile can be imported into Chrome DevTools or VSCode. Customizable using --args to match deployment arguments and --worker to provide a specific bundle. The --pages flag can be used for Pages projects without a Wrangler config file.

```bash
wrangler check startup
```

```bash
wrangler check startup --args="--no-bundle"
```

```bash
wrangler check startup --worker /path/to/worker/bundle
```

```bash
wrangler check startup --pages
```

--------------------------------

### Generate Image with Stable Diffusion Inpainting (curl)

Source: https://developers.cloudflare.com/workers/-ai/models/stable-diffusion-v1-5-inpainting

This example shows how to invoke the Stable Diffusion Inpainting model using a curl command. It requires specifying the account ID, API token, and providing the necessary input parameters in a JSON payload. The output will be the generated image data.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/runwayml/stable-diffusion-v1-5-inpainting" \
     -H "Authorization: Bearer YOUR_API_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{ 
         "prompt": "A futuristic cityscape at sunset.", 
         "negative_prompt": "dystopian, pollution", 
         "height": 1024, 
         "width": 1024, 
         "num_steps": 25, 
         "guidance": 8.0, 
         "strength": 0.9, 
         "seed": 67890 
     }'
```

--------------------------------

### Cloudflare Workers Durable Object Storage: startAfter Option

Source: https://developers.cloudflare.com/workers/platform/changelog/historical-changelog

The `list()` method in the Durable Object storage API now includes a `startAfter` option, allowing for cursor-based pagination of stored keys.

```JavaScript
const listResult = await myDO.storage.list({
  prefix: "user:",
  startAfter: "user:123"
});
```

--------------------------------

### JavaScript Example: Using Neon Serverless Driver

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/neon

This JavaScript code snippet shows how to connect to a Neon database from a Cloudflare Worker using the '@neondatabase/serverless' driver. It assumes the Neon database connection string is configured as a secret in your Worker.

```javascript
import neon from '@neondatabase/serverless';

export default {
  async fetch(request, env) {
    const neonClient = neon(env.NEON_DATABASE_URL);
    const result = await neonClient.query('SELECT * FROM elements');
    return new Response(JSON.stringify(result.rows));
  },
};
```

--------------------------------

### Scaffold New Astro Project with create-cloudflare CLI

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/astro

This command scaffolds a new Astro project using the create-cloudflare CLI (C3), setting it up for Cloudflare Workers. It allows template selection and offers immediate deployment options.

```npm
npm create cloudflare@latest -- --astro
```

```yarn
yarn create cloudflare --astro
```

```pnpm
pnpm create cloudflare --astro
```

--------------------------------

### Upload Worker using Cloudflare REST API (curl)

Source: https://developers.cloudflare.com/workers/platform/infrastructure-as-code

Example of uploading a Worker script and managing versions/deployments using `curl` with the Cloudflare REST API. Supports ES Modules, Python Workers, and Rust Workers. Requires an account ID and API token.

```Bash
curl -X PUT "https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/workers/scripts/my-worker" \
     -H "Authorization: Bearer YOUR_API_TOKEN" \
     -H "Content-Type: application/javascript" \
     --data-binary @my-script.mjs
```

--------------------------------

### Add Child Routes with Hono

Source: https://developers.cloudflare.com/workers/tutorials/build-a-slackbot

Demonstrates how to use Hono's `app.route()` function to add child applications (routes) to a parent application. This is useful for organizing larger applications into modular components.

```TypeScript
import { Hono } from 'hono'

const app = new Hono()

const apiRoutes = new Hono()
apiRoutes.get('/posts', (c) => c.text('Posts!'))

app.route('/api/v1', apiRoutes)

export default app
```

--------------------------------

### ResNet-50 Image Classification with Cloudflare Workers (TypeScript)

Source: https://developers.cloudflare.com/workers/-ai/models/resnet-50

Example of how to use the ResNet-50 model for image classification within Cloudflare Workers using TypeScript. This snippet demonstrates sending an image for classification and handling the response.

```typescript
interface InputImage {
  image: Uint8Array;
}

interface OutputLabel {
  score: number;
  label: string;
}

export default {
  async fetch(request: Request): Promise<Response> {
    const imageBuffer = await request.arrayBuffer();
    const imageArray = new Uint8Array(imageBuffer);

    const resnet50 = await Cloudflare.ai.run(
      "@cf/microsoft/resnet-50",
      { image: imageArray } as InputImage
    );

    const output: OutputLabel[] = resnet50 as OutputLabel[];

    return Response.json(output);
  },
};
```

--------------------------------

### Wrangler Configuration File

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/astro

Sets up the Wrangler configuration file for deploying to Cloudflare Workers, specifying the entry point and asset directory.

```json
{
  "main": "./.wrangler/tmp/pages/server/index.mjs",
  "compatibility_date": "2023-10-25",
  "build": {
    "command": "npm run build",
    "cwd": "."
  },
  "assets": {
    "directory": "./dist"
  }
}
```

--------------------------------

### Cloudflare Workers API Input Schema Example

Source: https://developers.cloudflare.com/workers/-ai/models/falcon-7b-instruct

This JSON schema represents the input structure for a Cloudflare Workers API request, likely for text generation. It specifies required fields such as `response` and includes optional parameters for controlling generation like `frequency_penalty` and `presence_penalty`.

```json
{
  "response": "string",
  "frequency_penalty": -1.0,
  "presence_penalty": 0.5
}
```

--------------------------------

### cURL - Text Generation with OpenHermes-2.5-Mistral-7B-AWQ

Source: https://developers.cloudflare.com/workers/-ai/models/openhermes-2

This cURL command demonstrates how to make a request to the OpenHermes-2.5-Mistral-7B-AWQ model API. It specifies the endpoint URL, HTTP method (POST), necessary headers including authorization, and the JSON payload containing the prompt. This is a command-line approach suitable for scripting or quick testing without writing a full program.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@hf/thebloke/openhermes-2.5-mistral-7b-awq" \
     -H "Authorization: Bearer <API_TOKEN>" \
     -H "Content-Type: application/json" \
     -d '{ 
       "prompt": "Explain the concept of recursion in programming.", 
       "stream": false 
     }'
```

--------------------------------

### Authenticate with Turso CLI

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/turso

Authenticates the Turso CLI with your GitHub account, which is required before creating your first Turso database.

```bash
turso auth github
```

--------------------------------

### Trigger builds for specific file types

Source: https://developers.cloudflare.com/workers/ci-cd/builds/build-watch-paths

This example illustrates how to configure build watch paths to trigger builds only for files with a specific extension, like '.md'. It includes all '.md' files and has no exclude paths.

```bash
Include paths: *.md
Exclude paths: 
```

--------------------------------

### Write Event Data with Workers Analytics Engine

Source: https://developers.cloudflare.com/workers/prompt

This example shows how to use the Workers Analytics Engine to write event data. It demonstrates binding an Analytics Engine dataset, writing data points with associated metadata like paths and user IDs, and querying the data using SQL. The `writeDataPoint` method is non-blocking.

```typescript
interface Env {
 USER_EVENTS: AnalyticsEngineDataset;
}

export default {
async fetch(req: Request, env: Env): Promise<Response> {
let url = new URL(req.url);
let path = url.pathname;
let userId = url.searchParams.get("userId");

     // Write a datapoint for this visit, associating the data with
     // the userId as our Analytics Engine 'index'
     env.USER_EVENTS.writeDataPoint({
      // Write metrics data: counters, gauges or latency statistics
      doubles: [],
      // Write text labels - URLs, app names, event_names, etc
      blobs: [path],
      // Provide an index that groups your data correctly.
      indexes: [userId],
     });

     return Response.json({
      hello: "world",
     });
    ,

};


```

--------------------------------

### Scaffold Hono App with React SPA using yarn

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/hono

This command scaffolds a new full-stack application using Hono, a React Single Page Application (SPA), and the Cloudflare Vite plugin. It sets up the project structure for rapid development on Cloudflare Workers.

```bash
yarn create cloudflare --template react-hono my-hono-app
```

--------------------------------

### Configure Vite for Cloudflare Workers (TypeScript)

Source: https://developers.cloudflare.com/workers/vite-plugin

This TypeScript example shows the configuration of `vite.config.ts` to include the Cloudflare Vite plugin. It's essential for projects using TypeScript to ensure the plugin is correctly integrated for building and deploying to Cloudflare Workers.

```typescript
import { defineConfig } from 'vite';
import cloudflareWorkers from '@cloudflare/vite-plugin-cloudflare-workers';

export default defineConfig({
  plugins: [
    cloudflareWorkers({
      // Options for the plugin
    }),
  ],
});
```

--------------------------------

### Workers: Return Image Data URI - TypeScript

Source: https://developers.cloudflare.com/workers/-ai/models/flux-1-schnell

Example of how to use the FLUX.1 model in Cloudflare Workers to return a generated image as a data URI. This snippet demonstrates setting up the request with a prompt and handling the response.

```typescript
import { Ai } from "@cloudflare/ai";

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const API_URL = `https://${env.ACCOUNT_ID}.cloudflare.workers-ai.com/v1/run/@cf/black-forest-labs/flux-1-schnell`;
    const prompt = "A cat wearing a hat";

    try {
      const response = await fetch(API_URL, {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${env.API_TOKEN}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          prompt: prompt,
          steps: 4
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`API Error: ${response.status} - ${errorText}`);
      }

      const data = await response.json();
      return new Response(JSON.stringify({ image: data.image }), {
        headers: {
          "Content-Type": "application/json"
        }
      });

    } catch (error) {
      console.error("Error generating image:", error);
      return new Response("Error generating image", {
        status: 500
      });
    }
  }
};
```

--------------------------------

### Stream Text Generation with Cloudflare Worker

Source: https://developers.cloudflare.com/workers/-ai/models/zephyr-7b-beta-awq

Example of how to use the Zephyr 7B Beta AWQ model for streaming text generation within a Cloudflare Worker. This involves setting up the worker script to handle requests and stream responses from the LLM.

```javascript
addEventListener("fetch", (event) => {
  event.respondWith(handleRequest(event.request));
});

async function handleRequest(request) {
  const url = new URL(request.url);
  const prompt = url.searchParams.get("prompt");

  if (!prompt) {
    return new Response("Please provide a prompt parameter.", {
      status: 400,
    });
  }

  const response = await fetch("https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@hf/thebloke/zephyr-7b-beta-awq", {
    method: "POST",
    headers: {
      "Authorization": "Bearer YOUR_API_TOKEN",
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      prompt: prompt,
      stream: true
    }),
  });

  return new Response(response.body, {
    headers: {
      "Content-Type": "text/plain",
    },
  });
}
```

--------------------------------

### Deploy Durable Object Migrations with Cloudflare CLI

Source: https://developers.cloudflare.com/workers/configuration/versions-and-deployments/gradual-deployments

This command deploys Durable Object migrations. Migrations should be deployed independently of other code changes to minimize the blast radius. Ensure you have the Cloudflare CLI installed and configured.

```bash
wrangler deploy --migrations
```

--------------------------------

### Build and Deploy Docusaurus Project

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/more-web-frameworks/docusaurus

Command to build and deploy a Docusaurus project to Cloudflare Workers. This can be done from a local machine or a CI/CD system.

```bash
npm run deploy
# or
yarn deploy
# or
pnpm deploy
```

--------------------------------

### Manage `waitUntil` with `createExecutionContext`

Source: https://developers.cloudflare.com/workers/testing/vitest-integration/migration-guides/migrate-from-miniflare-2

The `waitUntil` functionality is now managed using `createExecutionContext` and `waitOnExecutionContext`. `waitOnExecutionContext` returns a `Promise<void>` and does not resolve with the results of `waitUntil`ed Promises.

```javascript
import { createExecutionContext, waitOnExecutionContext } from 'cloudflare:test';

// Example usage:
const executionContext = createExecutionContext();
// ... your code that calls waitUntil ...
await waitOnExecutionContext(executionContext);

```

--------------------------------

### Worker Script Handling Matched Routes

Source: https://developers.cloudflare.com/workers/static-assets/routing/single-page-application

This example shows a basic Worker script that handles requests based on advanced routing rules. It demonstrates how to access request data and potentially use the assets binding to serve content.

```JavaScript
/**
 * @param {Request} request
 * @param {Env} env
 * @param {ExecutionContext} ctx
 * @returns {Promise<Response>}
 */
export default {
  async fetch(request, env, ctx) {
    const url = new URL(request.url);

    // Example: Handle API routes specifically
    if (url.pathname.startsWith('/api/')) {
      return new Response(JSON.stringify({ message: 'API endpoint hit' }), {
        headers: {
          'Content-Type': 'application/json',
        },
      });
    }

    // Example: Serve assets using the assets binding if not handled by specific routes
    // This assumes you have an assets binding configured in your wrangler.toml
    // return env.ASSETS.fetch(request);

    // Fallback for other routes, potentially serving index.html or another response
    return new Response('Hello from Worker!', {
      headers: {
        'Content-Type': 'text/plain',
      },
    });
  },
};

```

```TypeScript
interface Env {
  // Example binding for assets
  // ASSETS: Fetcher;
}

export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
    const url = new URL(request.url);

    // Example: Handle API routes specifically
    if (url.pathname.startsWith('/api/')) {
      return new Response(JSON.stringify({ message: 'API endpoint hit' }), {
        headers: {
          'Content-Type': 'application/json',
        },
      });
    }

    // Example: Serve assets using the assets binding if not handled by specific routes
    // return env.ASSETS.fetch(request);

    // Fallback for other routes, potentially serving index.html or another response
    return new Response('Hello from Worker!', {
      headers: {
        'Content-Type': 'text/plain',
      },
    });
  },
};

```

--------------------------------

### KV Namespace Binding Configuration (wrangler.toml)

Source: https://developers.cloudflare.com/workers/reference/migrate-to-module-workers

This TOML configuration file snippet demonstrates how to configure a KV namespace binding named 'TODO' for a Wrangler project.

```toml
[kv_namespaces]
binding = "TODO"
id = "your-kv-namespace-id"
```

--------------------------------

### Workflow Introspector Methods

Source: https://developers.cloudflare.com/workers/testing/vitest-integration/test-apis

Methods available on the `WorkflowIntrospector` object for managing modifications across all Workflow instances created after its initialization. Key methods include `modifyAll`, `get`, and `dispose`.

```typescript
interface WorkflowIntrospector {
  modifyAll(fn: (m: WorkflowInstanceModifier) => Promise<void>): Promise<void>;
  get(): Promise<WorkflowInstanceIntrospector[]>;
  dispose(): Promise<void>;
  [Symbol.asyncDispose](): Promise<void>;
}
```

--------------------------------

### Dynamic Wildcard Imports with esbuild

Source: https://developers.cloudflare.com/workers/wrangler/migration/update-v3-to-v4

This example shows how dynamic wildcard imports are handled differently in esbuild v0.24 (used in Wrangler v4) compared to earlier versions. In v0.24, all matching files are automatically included in the bundle, which may differ from previous behavior where only explicitly referenced files were bundled.

```javascript
// Example of a dynamic wildcard import
// In esbuild v0.24 (Wrangler v4), this might bundle all .json files in './data/'
// Prior to esbuild v0.19, this behavior was different and might not bundle all matches.
import('./data/' + kind + '.json');

// It is recommended to use explicit imports or manage dynamic imports carefully
// to avoid unexpected bundling behavior.
```

--------------------------------

### Text-to-Image Generation with Workers (TypeScript)

Source: https://developers.cloudflare.com/workers/-ai/models/dreamshaper-8-lcm

Example of how to generate an image from a text prompt using the dreamshaper-8-lcm model within a Cloudflare Worker using TypeScript. Requires prompt and optionally accepts negative_prompt, dimensions, and generation parameters.

```typescript
import { Ai } from "@cloudflare/ai";

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const API_URL = env.AI.provideService("@cf/lykon/dreamshaper-8-lcm");
    const ai = new Ai(API_URL);

    const body = await request.json<{ prompt: string, negative_prompt?: string, height?: number, width?: number, num_steps?: number, strength?: number, guidance?: number, seed?: number }>();

    const response = await ai.run({
      prompt: body.prompt,
      negative_prompt: body.negative_prompt,
      height: body.height,
      width: body.width,
      num_steps: body.num_steps,
      strength: body.strength,
      guidance: body.guidance,
      seed: body.seed
    });

    return new Response(response as any);
  }
}
```

--------------------------------

### Build and Deploy RedwoodSDK Project to Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/redwoodsdk

Command to build and deploy your RedwoodSDK project to Cloudflare Workers. This can be done from your local machine or a CI/CD system.

```bash
npm run deploy
```

```bash
yarn deploy
```

```bash
pnpm deploy
```

--------------------------------

### Start Wrangler Dev Server for Integration Tests

Source: https://developers.cloudflare.com/workers/wrangler/api

The `unstable_startWorker` API exposes Wrangler's dev server internals, allowing customization of its runtime. It's useful for running integration tests against your Worker, and can be integrated with any testing framework like Node's built-in `node:test`.

```javascript
import { unstable_startWorker } from 'wrangler';

// Example usage within a testing framework (e.g., node:test)
describe('My Worker', () => {
  let worker;

  beforeAll(async () => {
    worker = await unstable_startWorker({
      // configuration options for the worker
    });
  });

  afterAll(async () => {
    await worker.stop();
  });

  test('should respond correctly', async () => {
    const response = await worker.fetch('/');
    expect(response.status).toBe(200);
  });
});
```

--------------------------------

### Setting a Specific Compatibility Flag in Wrangler

Source: https://developers.cloudflare.com/workers/configuration/compatibility-flags

This example demonstrates how to enable a specific compatibility flag, `formdata_parser_supports_files`, in a Wrangler configuration file. This allows enabling features before they become default or disabling features that have become default.

```jsonc
{
  "compatibility_flags": [
    "formdata_parser_supports_files"
  ],
  "compatibility_date": "2021-09-14"
}
```

```toml
[compatibility]
flags = ["formdata_parser_supports_files"]
date = "2021-09-14"
```

--------------------------------

### Transcribe Audio with Whisper Tiny EN (curl)

Source: https://developers.cloudflare.com/workers/-ai/models/whisper-tiny-en

Example command using curl to send audio data to the Whisper Tiny EN model via an API endpoint. This demonstrates a common way to interact with the model from the command line.

```bash
curl -X POST https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/openai/whisper-tiny-en \
     -H "Authorization: Bearer <API_TOKEN>" \
     -F "audio=@/path/to/your/audio.wav"
```

--------------------------------

### Get Turso Database URL using CLI

Source: https://developers.cloudflare.com/workers/tutorials/connect-to-turso-using-workers

Retrieve the connection string (URL) for your Turso database using the Turso CLI. This URL is required to establish a connection from your Cloudflare Worker.

```bash
turso db show <database_name> --url
```

--------------------------------

### Query Upstash Redis from Cloudflare Worker

Source: https://developers.cloudflare.com/workers/databases/third-party-integrations/upstash

Example demonstrating how to query an Upstash Redis database from a Cloudflare Worker using the @upstash/redis client. Assumes Redis URL and token are configured as Worker secrets.

```javascript
import { Redis } from "@upstash/redis";

export default {
  async fetch(request, env) {
    const redis = new Redis({
      url: env.UPSTASH_REDIS_URL,
      token: env.UPSTASH_REDIS_TOKEN,
    });

    const data = await redis.set("mykey", "myvalue");
    const value = await redis.get("mykey");

    return new Response(JSON.stringify({ data, value }));
  },
};
```

--------------------------------

### Full-Stack Library App with React and Postgres

Source: https://developers.cloudflare.com/workers/get-started/quickstarts

Deploy your own library of books using PostgreSQL as the database and Cloudflare Workers for the backend. This template provides a full-stack solution for managing collections.

```Shell
npm create cloudflare@latest -- --template react-postgres-fullstack-template
# or
yarn create cloudflare --template react-postgres-fullstack-template
# or
pnpm create cloudflare --template react-postgres-fullstack-template
```

--------------------------------

### Text Generation Parameters

Source: https://developers.cloudflare.com/workers/-ai/models/zephyr-7b-beta-awq

This section details parameters that control the text generation process, such as penalties for repetition and topic introduction.

```APIDOC
## Text Generation Parameters

### Description
Parameters to control the text generation model's output, including penalties for repetition and introduction of new topics.

### Parameters
#### Query Parameters
- **frequency_penalty** (number) - Optional - Decreases the likelihood of the model repeating the same lines verbatim. Min: -2, Max: 2.
- **presence_penalty** (number) - Optional - Increases the likelihood of the model introducing new topics. Min: -2, Max: 2.
```

--------------------------------

### Transcribe Audio with Whisper API using cURL

Source: https://developers.cloudflare.com/workers/-ai/models/whisper

This example shows how to transcribe audio using the Whisper API via a cURL command. It sends audio data as an array of integers and retrieves the transcription and associated metadata.

```bash
curl 
  --request POST 
  --url https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/openai/whisper 
  --header 'Authorization: Bearer {YOUR_CLOUDFLARE_API_TOKEN}' 
  --header 'Content-Type: application/json' 
  --data '{ 
    "audio": [
      0, 1, 2, ..., 255 
    ] 
  }'
```

--------------------------------

### Initialize Cloudflare Worker with Hono and OpenAI Client

Source: https://developers.cloudflare.com/workers/tutorials/create-finetuned-chatgpt-ai-models-with-r2

TypeScript code for initializing a Cloudflare Worker using Hono. It includes setting up the Hono app, adding the OpenAI API client as middleware, and defining a basic error handler.

```typescript
import {
  OpenAI
} from "openai";
import {
  PrismaClient
} from "@prisma/client";
import {
  with_openai
} from "./middleware/with_openai";
import {
  with_prisma
} from "./middleware/with_prisma";
import {
  app
} from "./routes";

// Initialize OpenAI client
const openai = new OpenAIApi({
  apiKey: process.env.OPENAI_API_KEY,
});

// Initialize Prisma client
const prisma = new PrismaClient();

// Add OpenAI client to context
app.use(
  "*",
  with_openai({
    openai: openai,
  })
);

// Add Prisma client to context
app.use(
  "*",
  with_prisma({
    prisma: prisma,
  })
);

// Error handler
app.onError((err, c) => {
  console.error(`${err.message} - ${err.stack}`);
  return c.json({ error: "An unexpected error occurred" }, 500);
});

export default app;

```

--------------------------------

### Handle HTTP Requests with Durable Objects-style Addressing

Source: https://developers.cloudflare.com/workers/prompt

Describes Durable Objects-style addressing for agents, allowing control over ID generation and agent invocation. It shows creating a new agent ID, getting the agent, and passing the request to it.

```typescript
		// Durable Objects-style addressing
		// Best for: controlling ID generation, associating IDs with your existing systems,
		// and customizing when/how an Agent is created or invoked
		const id = env.AIAgent.newUniqueId();
		const agent = env.AIAgent.get(id);
		// Pass the incoming request straight to your Agent
		let resp = await agent.fetch(request);

		// return Response.json({ hello: 'visit https://developers.cloudflare.com/agents for more' });
	}
}

export default { fetch } satisfies ExportedHandler<Env>;
```

--------------------------------

### Integration Test using `SELF` Fetcher (JavaScript)

Source: https://developers.cloudflare.com/workers/testing/vitest-integration/write-your-first-test

Write an integration test using the `SELF` fetcher provided by `cloudflare:test`. This allows testing the Worker's `fetch` handler as if it were called externally.

```javascript
import { describe, it, expect } from 'vitest';

describe('Integration Test', () => {
  it('can call the Worker using SELF', async () => {
    // 'SELF' is a service binding to the default export defined in the main Worker
    const response = await SELF.fetch('http://localhost/');
    expect(response.status).toBe(200);
    expect(await response.text()).toBe('Hello World!');
  });
});
```

--------------------------------

### Generate Text with llama-2-7b-chat-fp16 using Workers

Source: https://developers.cloudflare.com/workers/-ai/models/llama-2-7b-chat-fp16

Example of how to use the llama-2-7b-chat-fp16 model for text generation within a Cloudflare Worker. This snippet demonstrates the basic structure for making a request to the model's API.

```javascript
import { Hono } from 'hono'
import { stream } from 'hono/streaming'

const app = new Hono()

app.post('/api/ai/generate', async (c) => {
  const { prompt } = await c.req.json()

  const response = await fetch('https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/meta/llama-2-7b-chat-fp16',
    {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${c.env.CLOUDFLARE_API_TOKEN}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        prompt: prompt
      })
    }
  )

  const data = await response.json()

  return c.json(data)
})

export default app
```

--------------------------------

### Proxying with a Splat

Source: https://developers.cloudflare.com/workers/static-assets/redirects

This example illustrates how to use proxying with a splat. A request to a source path with a splat will be proxied to a destination path, returning a specified status code (e.g., 200 for success). Proxying only supports relative URLs.

```plaintext
/blog/* /news/:splat 200
```

--------------------------------

### Translate Text using curl

Source: https://developers.cloudflare.com/workers/-ai/models/indictrans2-en-indic-1B

Command-line example for translating text using the IndicTrans2 model via curl. It shows how to send a POST request with JSON payload containing the text and target language to the API endpoint.

```bash
curl -X POST "https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/run/@cf/ai4bharat/indictrans2-en-indic-1B" \
     -H "Authorization: Bearer YOUR_API_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{ 
       "text": "Hello, how are you?", 
       "target_language": "hin_Deva" 
     }'
```

--------------------------------

### Create and Upload LoRA Adapters via REST API

Source: https://developers.cloudflare.com/workers/-ai/features/fine-tunes/loras

Examples of using the Cloudflare REST API to create a fine-tune and upload LoRA adapter files. Requires a Cloudflare API Token with 'Workers AI: Edit' permissions. Upload each file separately.

```bash
# Create a new fine-tune
curl -X POST "https://api.cloudflare.com/client/v4/accounts/<account_id>/workers/ai/finetune" \
     -H "Authorization: Bearer <cloudflare_api_token>" \
     -H "Content-Type: application/json" \
     --data '{"name": "<your-finetune-name>"}'

# Upload adapter weights
curl -X POST "https://api.cloudflare.com/client/v4/accounts/<account_id>/workers/ai/finetune/<finetune_name_or_id>/upload" \
     -H "Authorization: Bearer <cloudflare_api_token>" \
     -F "file=@./adapter_model.safetensors"

# Upload adapter config
curl -X POST "https://api.cloudflare.com/client/v4/accounts/<account_id>/workers/ai/finetune/<finetune_name_or_id>/upload" \
     -H "Authorization: Bearer <cloudflare_api_token>" \
     -F "file=@./adapter_config.json"
```

--------------------------------

### Accessing KV Namespace from Python Worker

Source: https://developers.cloudflare.com/workers/languages/python/ffi

Demonstrates how to declare a Key-Value (KV) namespace binding in a Python Worker's Wrangler configuration file to enable interaction with Cloudflare's KV store. The example shows the configuration snippet for `wrangler.jsonc` or `wrangler.toml`.

```json
{
  "kv_namespaces": [
    {
      "binding": "MY_KV",
      "id": "your-kv-namespace-id"
    }
  ]
}
```

--------------------------------

### Connect to PostgreSQL with Cloudflare Hyperdrive

Source: https://developers.cloudflare.com/workers/prompt

Connects to and queries a PostgreSQL database using Cloudflare Hyperdrive and the Postgres.js library. It demonstrates setting up Hyperdrive bindings and executing SQL queries.

```typescript
// Postgres.js 3.4.5 or later is recommended
import postgres from "postgres";

export interface Env {
// If you set another name in the Wrangler config file as the value for 'binding',
// replace "HYPERDRIVE" with the variable name you defined.
HYPERDRIVE: Hyperdrive;
}

export default {
async fetch(request, env, ctx): Promise<Response> {
console.log(JSON.stringify(env));
// Create a database client that connects to your database via Hyperdrive.
//
// Hyperdrive generates a unique connection string you can pass to
// supported drivers, including node-postgres, Postgres.js, and the many
// ORMs and query builders that use these drivers.
const sql = postgres(env.HYPERDRIVE.connectionString)

    try {
      // Test query
      const results = await sql`SELECT * FROM pg_tables`;

      // Return result rows as JSON
      return Response.json(results);
    } catch (e) {
      console.error(e);
      return Response.json(
        { error: e instanceof Error ? e.message : e },
        { status: 500 },
      );
    }

},
} satisfies ExportedHandler<Env>;
```

--------------------------------

### Chat Completions API

Source: https://developers.cloudflare.com/workers/-ai/models/deepseek-math-7b-instruct

This endpoint provides chat completions based on a provided conversation history and model configuration. It supports streaming, function calling, and response formatting.

```APIDOC
## POST /v1/chat/completions

### Description
Generates a model response based on the user's prompt and conversation history. Supports streaming, function calling, and various generation parameters.

### Method
POST

### Endpoint
/v1/chat/completions

### Parameters
#### Request Body
- **messages** (array[object]) - Required - An array of message objects representing the conversation history.
  - **role** (string) - Required - The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool').
  - **content** (string) - Required - The content of the message as a string.
- **model** (string) - Required - The ID of the model to use for completions.
- **functions** (array[object]) - Optional - A list of functions the model may call.
  - **name** (string) - Required - The name of the function.
  - **code** (string) - Required - The tool code in string format.
- **tools** (array[object]) - Optional - A list of tools the model may call.
  - **type** (string) - Required - Specifies the type of tool (e.g., 'function').
  - **function** (object) - Required - Details of the function tool.
    - **name** (string) - Required - The name of the function.
    - **description** (string) - Optional - A brief description of what the function does.
    - **parameters** (object) - Required - Schema defining the parameters accepted by the function.
      - **type** (string) - Required - The type of the parameters object (usually 'object').
      - **required** (array[string]) - Optional - List of required parameter names.
      - **properties** (object) - Required - Definitions of each parameter.
        - **additionalProperties** (object) - Required - Defines a parameter.
          - **type** (string) - Required - The data type of the parameter.
          - **description** (string) - Required - A description of the expected parameter.
- **response_format** (object) - Optional - Specifies the format for the response.
  - **type** (string) - Optional - The type of response format (e.g., 'json_object').
  - **json_schema** (object) - Optional - The JSON schema for 'json_object' type.
- **prompt** (string) - Optional - The input text prompt for the model to generate a response.
- **lora** (string) - Optional - Name of the LoRA model to fine-tune the base model.
- **raw** (boolean) - Optional - If true, a chat template is not applied.
- **stream** (boolean) - Optional - If true, the response will be streamed back incrementally using SSE.
- **max_tokens** (integer) - Optional - Default: 256 - The maximum number of tokens to generate in the response.
- **temperature** (number) - Optional - Default: 0.6 - Controls the randomness of the output.
- **top_p** (number) - Optional - Adjusts the creativity of the AI's responses.
- **top_k** (integer) - Optional - Limits the AI to choose from the top 'k' most probable words.
- **seed** (integer) - Optional - Random seed for reproducibility of the generation.
- **repetition_penalty** (number) - Optional - Penalty for repeated tokens; higher values discourage repetition.
- **frequency_penalty** (number) - Optional - Decreases the likelihood of the model repeating the same lines verbatim.
- **presence_penalty** (number) - Optional - Increases the likelihood of the model introducing new topics.

### Request Example
```json
{
  "model": "@cf/meta/llama-2-7b-chat-fp16",
  "messages": [
    {
      "role": "user",
      "content": "Explain the concept of a large language model."
    }
  ],
  "stream": false,
  "max_tokens": 500,
  "temperature": 0.7
}
```

### Response
#### Success Response (200)
- **id** (string) - Unique identifier for the completion.
- **model** (string) - The model used for the completion.
- **choices** (array[object]) - An array of completion choices.
  - **index** (integer) - The index of the choice.
  - **message** (object) - The message content.
    - **role** (string) - The role of the sender ('assistant').
    - **content** (string) - The generated content.
  - **finish_reason** (string) - The reason for finishing the generation (e.g., 'stop', 'length').
- **usage** (object) - Information about token usage.
  - **prompt_tokens** (integer) - Number of tokens in the prompt.
  - **completion_tokens** (integer) - Number of tokens in the completion.
  - **total_tokens** (integer) - Total tokens used.

#### Response Example
```json
{
  "id": "cmpl-xxxxxxxxxxxxxxxxxxxx",
  "model": "@cf/meta/llama-2-7b-chat-fp16",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "A large language model (LLM) is a type of artificial intelligence program that is trained to understand and generate human-like text."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 15,
    "completion_tokens": 20,
    "total_tokens": 35
  }
}
```
```

--------------------------------

### Handle FetchEvent in Cloudflare Workers (Service Worker Syntax)

Source: https://developers.cloudflare.com/workers/reference/migrate-to-module-workers

This example demonstrates the basic structure of a Cloudflare Worker using Service Worker syntax. It includes an event listener for `FetchEvent` and an event handler that responds with a simple text message. The `event.respondWith()` method is used to intercept the request and provide a custom response.

```javascript
addEventListener('fetch', event => {
  const url = new URL(event.request.url);

  if (url.pathname === '/') {
    event.respondWith(new Response('Hello worker!', { 
      headers: { 'content-type': 'text/plain' } 
    }));
  }
});
```

--------------------------------

### Text Generation with Worker (cURL)

Source: https://developers.cloudflare.com/workers/-ai/models/llama-4-scout-17b-16e-instruct

Provides an example of how to use the Llama 4 Scout model for text generation via a Cloudflare Worker using a cURL command. This snippet shows the command-line interface for interacting with the model's API.

```shell
curl "https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/meta/llama-4-scout-17b-16e-instruct" \
     -X POST \
     -H "Authorization: Bearer <API_TOKEN>" \
     -H "Content-Type: application/json" \
     -d '{"messages": [{"role": "user", "content": "Hello, world!"}]}'
```

--------------------------------

### Transcribe Audio with Whisper Tiny EN (TypeScript)

Source: https://developers.cloudflare.com/workers/-ai/models/whisper-tiny-en

Example of how to transcribe audio using the Whisper Tiny EN model in a Cloudflare Worker with TypeScript. It shows how to format the audio input and handle the transcription output.

```typescript
import { Ai } from "@cloudflare/ai";

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const ai = new Ai(env.AI);
    const audioData = new Uint8Array(/* ... your audio data ... */);

    const result = await ai.run(
      "@cf/openai/whisper-tiny-en",
      { audio: audioData }
    );

    return Response.json(result);
  },
};

interface Env {
  AI: any;
}
```

--------------------------------

### Worker - Non-Streaming Text Generation with llama-2-7b-chat-int8

Source: https://developers.cloudflare.com/workers/-ai/models/llama-2-7b-chat-int8

Example of how to use the llama-2-7b-chat-int8 model within a Cloudflare Worker for non-streaming text generation. This method is suitable for scenarios where immediate full response is preferred over gradual streaming.

```typescript
import { Ai } from "@cloudflare/ai";

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const ai = new Ai(env.AI);
    const prompt = "Write a short poem about the moon.";

    const response = await ai.run(
      "@cf/meta/llama-2-7b-chat-int8",
      {
        prompt: prompt,
        stream: false
      }
    );

    return new Response(JSON.stringify(response));
  },
};

```

--------------------------------

### Element Handler: Manipulating Attributes

Source: https://developers.cloudflare.com/workers/runtime-apis/html-rewriter

Shows how to use an element handler to interact with an HTML element's attributes. This includes getting attribute values, checking for attribute existence, setting attributes, and removing attributes.

```javascript
rewriter.on('div', {
  element(element) {
    // Get attribute value
    const id = element.getAttribute('id');

    // Check if attribute exists
    if (element.hasAttribute('data-custom')) {
      // Attribute exists
    }

    // Set an attribute
    element.setAttribute('class', 'new-class');

    // Remove an attribute
    element.removeAttribute('data-old');
  }
});

```

--------------------------------

### Explore Image-to-Text Models with Workers AI SDK

Source: https://developers.cloudflare.com/workers/-ai/guides/tutorials/explore-workers-ai-models-using-a-jupyter-notebook

This Python code shows how to utilize the Workers AI SDK for image-to-text tasks. It involves sending an image (likely as a file path or bytes) to a designated model and receiving a textual description. This is useful for image captioning or analysis. Ensure the model supports this task and the image is correctly formatted.

```python
# This is a conceptual example using a hypothetical Workers AI SDK.
# Replace with actual SDK calls and model names.

# from workers_ai_sdk import WorkersAIClient

# client = WorkersAIClient(account_id=account_id, api_token=api_token)

# model_name = "@stabilityai/stable-diffusion-2-1"
# image_path = "path/to/your/image.jpg"

# try:
#     with open(image_path, 'rb') as f:
#         image_data = f.read()
#     response = client.analyze(model=model_name, image=image_data)
#     print(response)
# except Exception as e:
#     print(f"An error occurred: {e}")

print("# Conceptual example for Image-to-Text Analysis")
print("# Replace with actual SDK calls.")
print("response = {'description': 'A vibrant display of colorful lava lamps.'}")

```

--------------------------------

### Streaming Text Generation with Worker (Python)

Source: https://developers.cloudflare.com/workers/-ai/models/llama-4-scout-17b-16e-instruct

Demonstrates how to perform streaming text generation using the Llama 4 Scout model within a Cloudflare Worker using Python. It outlines the necessary setup and API calls for interacting with the model.

```Python
from cloudflare.workers import Ai

async def stream_text(request):
    ai = Ai()
    prompt = "Hello, world!"
    response = await ai.run("@cf/meta/llama-4-scout-17b-16e-instruct", {
        "messages": [{"role": "user", "content": prompt}],
        "stream": True
    })
    return response
```

--------------------------------

### Create Vue Project with Cloudflare Workers

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/vue

Use the create-cloudflare CLI (C3) to initialize a new Vue project configured for Cloudflare Workers Assets. This command sets up the project structure and provides options for instant deployment.

```bash
npm create cloudflare@latest my-vue-app -- --template vue
# or
yarn create cloudflare my-vue-app --template vue
# or
pnpm create cloudflare my-vue-app --template vue
```

--------------------------------

### List Public LoRAs via API (JavaScript)

Source: https://developers.cloudflare.com/workers/-ai/features/fine-tunes/public-loras

Provides a JavaScript example to list public LoRA adapters using the Cloudflare API. Ensure you have the necessary API token permissions (Workers AI Write or Workers AI Read).

```javascript
async function listPublicLorases(accountId, apiToken) {
  const response = await fetch(`https://api.cloudflare.com/client/v4/accounts/${accountId}/ai/beta/loras`, {
    headers: {
      Authorization: `Bearer ${apiToken}`
    }
  });
  const data = await response.json();
  console.log(data);
  return data;
}
```

--------------------------------

### Handle HTTP Requests with Routed Addressing

Source: https://developers.cloudflare.com/workers/prompt

Explains how to handle incoming HTTP requests using routed addressing in Cloudflare Workers. It demonstrates routing requests to agents and provides a fallback response for unmatched routes.

```typescript
	export default {
	async fetch(request, env, ctx): Promise<Response> {
		// Routed addressing
		// Automatically routes HTTP requests and/or WebSocket connections to /agents/:agent/:name
		// Best for: connecting React apps directly to Agents using useAgent from @cloudflare/agents/react
		return (await routeAgentRequest(request, env)) || Response.json({ msg: 'no agent here' }, { status: 404 });
	}
}

export default { fetch } satisfies ExportedHandler<Env>;
```

--------------------------------

### Alias 'node-fetch' to Workers' Built-in Fetch API

Source: https://developers.cloudflare.com/workers/wrangler/configuration

This configuration example demonstrates aliasing imports of 'node-fetch' to the Workers runtime's built-in `fetch` API. This is useful for ensuring compatibility and avoiding issues with Node.js-specific APIs.

```json
{
  "alias": {
    "node-fetch": "./node_modules/undici/index.js"
  }
}
```

--------------------------------

### Update Wrangler to v4+

Source: https://developers.cloudflare.com/workers/prompts/pages-to-workers

Installs or updates the Wrangler CLI to version 4 or later, which is required for modern Workers deployment commands. This command should be run using your project's package manager (npm, pnpm, yarn, or bun).

```bash
npm install --save-dev wrangler@^4.0.0
```

```bash
pnpm add --save-dev wrangler@^4.0.0
```

```bash
yarn add --dev wrangler@^4.0.0
```

```bash
bun add --dev wrangler@^4.0.0
```

--------------------------------

### Specifying ctx.props for ctx.exports in TypeScript

Source: https://developers.cloudflare.com/workers/runtime-apis/context

This TypeScript example shows how to specify `ctx.props` when invoking a Service Binding derived from `ctx.exports`. It highlights the type safety provided by TypeScript when defining the props interface for the Worker entrypoint.

```typescript
interface MyWorkerProps {
  customData: string;
}

export class MyWorker extends WorkerEntrypoint<Env, MyWorkerProps> {
  async fetch(request: Request, env: Env, ctx: ExecutionContext<MyWorkerProps>): Promise<Response> {
    const customData = ctx.props.customData;
    // Use customData
    return new Response(`Received: ${customData}`);
  }
}

// In another worker:
const myWorker = ctx.exports.MyWorker;
await myWorker.fetch(request, {
  props: {
    customData: "typescript value"
  }
});
```

--------------------------------

### Query MySQL Database from Cloudflare Worker

Source: https://developers.cloudflare.com/workers/tutorials/mysql

Implement database querying logic within your Cloudflare Worker using the `mysql2` driver and a Hyperdrive connection. This example demonstrates creating a connection instance and executing a SQL query to fetch data from a MySQL database.

```typescript
import { connect } from '@planetscale/database';

export default {
  async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
    const connection = connect({
      url: env.MY_HYPERDRIVE_BINDING_NAME,
    });

    const results = await connection.execute('SELECT * FROM products');
    return new Response(JSON.stringify(results));
  },
};
```

--------------------------------

### Alias Module Imports in Wrangler Configuration

Source: https://developers.cloudflare.com/workers/wrangler/configuration

This example shows how to alias module imports in Wrangler. It demonstrates aliasing the 'foo' module to another specified module path, useful for dependency management or providing alternative implementations.

```json
{
  "alias": {
    "foo": "./lib/alternative-foo.js"
  }
}
```

--------------------------------

### Add wranglerjs-compat-webpack-plugin as a devDependency (pnpm)

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/eject-webpack

This command installs the `wranglerjs-compat-webpack-plugin` as a development dependency using pnpm. This is part of the migration process for users who rely on custom webpack configurations with Cloudflare Workers and are moving from Wrangler v1 to v2.

```bash
pnpm add -D wranglerjs-compat-webpack-plugin
```

--------------------------------

### Manage Remote Proxy Session with maybeStartOrUpdateProxySession

Source: https://developers.cloudflare.com/workers/development-testing

A convenience function to simplify the starting or updating of a remote proxy session. It intelligently determines whether a session is needed based on provided arguments and existing session details.

```typescript
import {
  maybeStartOrUpdateRemoteProxySession,
  StartRemoteProxySessionResult
} from "wrangler";

async function manageSession() {
  let currentSessionDetails: StartRemoteProxySessionResult | null = null;

  // Example 1: Using Wrangler config path and environment
  currentSessionDetails = await maybeStartOrUpdateRemoteProxySession({
    configPath: "wrangler.toml",
    environment: "production"
  }, currentSessionDetails, {
    accountId: "YOUR_CLOUDFLARE_ACCOUNT_ID",
    apiToken: "YOUR_CLOUDFLARE_API_TOKEN"
  });

  if (currentSessionDetails) {
    console.log("Proxy session started or updated:", currentSessionDetails);
    // Use currentSessionDetails.remoteProxyConnectionString with Miniflare
  } else {
    console.log("No proxy session needed.");
  }

  // Example 2: Using Worker name and bindings (if not using config)
  // currentSessionDetails = await maybeStartOrUpdateRemoteProxySession({
  //   workerName: "my-worker",
  //   bindings: { /* explicit bindings */ }
  // }, currentSessionDetails, {
  //   accountId: "YOUR_CLOUDFLARE_ACCOUNT_ID",
  //   apiToken: "YOUR_CLOUDFLARE_API_TOKEN"
  // });

  // To clean up later if a session was started:
  // if (currentSessionDetails) {
  //   await currentSessionDetails.dispose();
  // }
}
```

--------------------------------

### Get Data from KV Store and Handle Missing Data

Source: https://developers.cloudflare.com/workers/tutorials/build-a-jamstack-app

This JavaScript code retrieves data from the KV store. If the data does not exist, it uses a default data object and writes it to the cache for future use. This ensures data is available even on the first run.

```javascript
async function getTodos() {
  let todos = await TODOS.get('todos');
  if (!todos) {
    const defaultData = {
      todos: [
        { text: "Learn Cloudflare Workers", done: false },
        { text: "Build a todo app", done: false },
      ],
    };
    await TODOS.put('todos', JSON.stringify(defaultData));
    return defaultData;
  }
  return JSON.parse(todos);
}
```

--------------------------------

### Text Generation API

Source: https://developers.cloudflare.com/workers/-ai/models/openhermes-2

This endpoint allows for direct text generation using AI models, with parameters to control output length, creativity, and reproducibility.

```APIDOC
## POST /v1/text/completions

### Description
Generates a text completion response from an AI model.

### Method
POST

### Endpoint
/v1/text/completions

### Parameters
#### Request Body
- **prompt** (string) - Required - The input text prompt for the model to generate a response. Min: 1.
- **lora** (string) - Optional - Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model.
- **response_format** (object) - Optional - Specifies the desired response format.
  - **type** (string)
  - **json_schema**
- **raw** (boolean) - Optional - If true, a chat template is not applied and you must adhere to the specific model's expected formatting.
- **stream** (boolean) - Optional - If true, the response will be streamed back incrementally using SSE, Server Sent Events.
- **max_tokens** (integer) - Optional - The maximum number of tokens to generate in the response. Default: 256.
- **temperature** (number) - Optional - Controls the randomness of the output; higher values produce more random results. Default: 0.6. Min: 0, Max: 5.
- **top_p** (number) - Optional - Adjusts the creativity of the AI's responses. Min: 0.001, Max: 1.
- **top_k** (integer) - Optional - Limits the AI to choose from the top 'k' most probable words. Min: 1, Max: 50.
- **seed** (integer) - Optional - Random seed for reproducibility of the generation. Min: 1, Max: 9999999999.
- **repetition_penalty** (number) - Optional - Penalty for repeated tokens; higher values discourage repetition. Min: 0, Max: 2.

### Request Example
```json
{
  "prompt": "Write a short story about a robot exploring a new planet.",
  "max_tokens": 150,
  "temperature": 0.7
}
```

### Response
#### Success Response (200)
- **choices** (array) - An array of completion choices.
  - **items** (object)
    - **text** (string) - The generated text.
    - **finish_reason** (string) - The reason the model stopped generating tokens.
- **usage** (object) - Information about token usage.
  - **prompt_tokens** (integer) - Number of tokens in the prompt.
  - **completion_tokens** (integer) - Number of tokens in the completion.
  - **total_tokens** (integer) - Total tokens used.

#### Response Example
```json
{
  "choices": [
    {
      "text": "Unit 734 landed softly on the crimson soil of Kepler-186f. Its optical sensors scanned the alien landscape, cataloging bizarre flora and geological formations. A faint, rhythmic pulse echoed from the horizon...",
      "finish_reason": "length"
    }
  ],
  "usage": {
    "prompt_tokens": 15,
    "completion_tokens": 150,
    "total_tokens": 165
  }
}
```
```

--------------------------------

### Inspect and Modify HTML End Tags with HTMLRewriter

Source: https://developers.cloudflare.com/workers/platform/changelog/historical-changelog

The `HTMLRewriter` class has been updated to support inspecting and modifying HTML end tags, in addition to start tags. This provides more comprehensive control over HTML document transformation.

```JavaScript
new HTMLRewriter()
  .on('div', {
    enter: (element) => element.setInnerContent('New Content'),
    exit: (element) => element.setOuterHTML('<p>Replaced</p>')
  })
  .transform(response);
```

--------------------------------

### Develop Cloudflare Workers Templates with CLI

Source: https://developers.cloudflare.com/workers/get-started/quickstarts

A command-line interface (CLI) tool designed to streamline the development process for Cloudflare Workers templates. It simplifies the creation and management of new projects.

```Shell
npm create cloudflare@latest -- --template cli
# or
yarn create cloudflare --template cli
# or
pnpm create cloudflare --template cli
```

--------------------------------

### Generate Text Embeddings with Python

Source: https://developers.cloudflare.com/workers/-ai/models/bge-base-en-v1

This example shows how to generate text embeddings using the BAAI model with Python. It sends a request to the embedding model, specifying the text and pooling strategy. The function returns the embedding data and shape.

```python
import os

import httpx


API_KEY = os.environ.get("API_KEY")


API_BASE_URL = "https://api.cloudflare.com/client/v4"


headers = {
    "Authorization": f"Bearer {API_KEY}",
}


client = httpx.Client(base_url=API_BASE_URL, headers=headers)


def generate_embeddings(text: str, pooling: str = "mean") -> dict:
    """Generate embeddings for a given text.

    Args:
        text: The text to embed.
        pooling: The pooling method to use ('mean' or 'cls').

    Returns:
        A dictionary containing the embedding data, shape, and pooling method.
    """
    response = client.post(
        "/accounts/{}/workers/ai/run/@cf/baai/bge-base-en-v1.5",
        json={"text": text, "pooling": pooling},
    )
    response.raise_for_status()
    return response.json()
```

--------------------------------

### Test and Preview Next.js with Cloudflare Adapter

Source: https://developers.cloudflare.com/workers/framework-guides/web-apps/nextjs

Test and preview your Next.js application using the Cloudflare adapter. This command uses `wrangler dev` to run your application in the `workerd` runtime, providing an accurate preview of the deployed environment.

```bash
npm run preview
```

```bash
yarn preview
```

```bash
pnpm preview
```

--------------------------------

### Generate Text Embeddings with curl

Source: https://developers.cloudflare.com/workers/-ai/models/bge-small-en-v1

This snippet shows how to generate text embeddings using the baai/bge-small-en-v1.5 model via a curl command. It includes examples for both single text inputs and batch requests, specifying the pooling method.

```bash
# Single text input
curl -X POST "https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/baai/bge-small-en-v1.5" \
     -H "Authorization: Bearer <API_TOKEN>" \
     -H "Content-Type: application/json" \
     -d '{"text": "The quick brown fox jumps over the lazy dog"}'

# Batch text input
curl -X POST "https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/baai/bge-small-en-v1.5" \
     -H "Authorization: Bearer <API_TOKEN>" \
     -H "Content-Type: application/json" \
     -d '{"text": ["The quick brown fox jumps over the lazy dog", "Another sentence for embedding"]}'

# Batch text input with 'cls' pooling
curl -X POST "https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/ai/run/@cf/baai/bge-small-en-v1.5" \
     -H "Authorization: Bearer <API_TOKEN>" \
     -H "Content-Type: application/json" \
     -d '{"text": ["The quick brown fox jumps over the lazy dog", "Another sentence for embedding"], "pooling": "cls"}'

```

--------------------------------

### Embed Text using Python

Source: https://developers.cloudflare.com/workers/-ai/models/embeddinggemma-300m

This example shows how to call the EmbeddingGemma-300M model using Python. It sends a POST request with the text to be embedded and processes the JSON response containing embedding vectors and shape information.

```python
import requests

url = "@cf/google/embeddinggemma-300m"
data = {
    "text": "Input text to embed."
}

response = requests.post(url, json=data)
result = response.json()
```

--------------------------------

### Get Value from KV Namespace

Source: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/commands

Reads a single value from a Cloudflare Workers KV namespace by its key. Requires the key and either a binding name or a namespace ID. Supports environment-specific operations and preview namespaces.

```bash
wrangler kv:get <KEY> --binding <YOUR_NAMESPACE_BINDING>
wrangler kv:get <KEY> --namespace-id <YOUR_NAMESPACE_ID>
wrangler kv:get <KEY> --namespace-id <YOUR_NAMESPACE_ID> --preview
wrangler kv:get <KEY> --binding <YOUR_NAMESPACE_BINDING> --env staging
```

--------------------------------

### Redirect Worker (ES Modules Syntax)

Source: https://developers.cloudflare.com/workers/reference/migrate-to-module-workers

This JavaScript code shows the equivalent of the Service Worker redirect example, but implemented using the ES Modules format. It uses a default export object instead of addEventListener.

```javascript
export default {
  async fetch(request, env, ctx) {
    return new Response('Hello World!', {
      headers: {
        'content-type': 'text/plain',
      },
    })
  },
}
```

--------------------------------

### Handling Inactive Request Context Errors

Source: https://developers.cloudflare.com/workers/runtime-apis/request

Attempting to use APIs like `fetch()` or access the Request context during script startup, before a request is received, will throw an exception. This example shows code that would cause such an error.

```javascript
// This code would throw an error during script startup
// const request = new Request('https://example.com'); // Incorrect usage outside fetch handler
// fetch(request); // Incorrect usage outside fetch handler

addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
});

async function handleRequest(request) {
  // Correct usage within the fetch handler
  const response = await fetch(request);
  return response;
}
```

--------------------------------

### Text Generation Parameters

Source: https://developers.cloudflare.com/workers/-ai/models/qwen2

Parameters to control the text generation process, such as penalties for repetition and topic introduction.

```APIDOC
## Text Generation API

### Description
This section describes parameters that influence the text generation model's behavior, including penalties for repeating tokens and introducing new topics.

### Method
N/A (Descriptive section, not a specific endpoint)

### Endpoint
N/A

### Parameters
#### Query Parameters
- **frequency_penalty** (number) - Optional - Decreases the likelihood of the model repeating the same lines verbatim. Range: 0 to 2.
- **presence_penalty** (number) - Optional - Increases the likelihood of the model introducing new topics. Range: 0 to 2.

### Request Example
```json
{
  "prompt": "Write a story about a brave knight.",
  "frequency_penalty": 0.5,
  "presence_penalty": 0.3
}
```

### Response
#### Success Response (200)
- **response** (string) - Required - The generated text response from the model.
- **usage** (object) - Usage statistics for the inference request.
  - **prompt_tokens** (number) - Total number of tokens in input.
  - **completion_tokens** (number) - Total number of tokens in output.
  - **total_tokens** (number) - Total number of input and output tokens.
- **tool_calls** (array) - An array of tool calls requests made during the response generation.
  - **items** (object) - Represents a single tool call.
    - **arguments** (object) - The arguments passed to be passed to the tool call request.
    - **name** (string) - The name of the tool to be called.

#### Response Example
```json
{
  "response": "Once upon a time, in a land far away, lived a brave knight named Sir Reginald...",
  "usage": {
    "prompt_tokens": 15,
    "completion_tokens": 50,
    "total_tokens": 65
  },
  "tool_calls": [
    {
      "arguments": {
        "search_query": "brave knight"
      },
      "name": "web_search"
    }
  ]
}
```
```

--------------------------------

### Store API Token in Cloudflare Worker Secrets (.dev.vars)

Source: https://developers.cloudflare.com/workers/tutorials/send-emails-with-postmark

This example shows how to securely store sensitive information like API tokens for local development using a `.dev.vars` file. This file mimics environment variables and is automatically loaded by the Worker.

```javascript
# .dev.vars
POSTMARK_API_TOKEN=YOUR_POSTMARK_API_TOKEN

```

--------------------------------

### Defining Text Content for Cloudflare Workers

Source: https://developers.cloudflare.com/workers/runtime-apis/bindings/worker-loader

This example shows how to define an importable string value for a dynamic Worker. The module type is specified as `text`, allowing the string content to be imported and used directly within the Worker.

```javascript
{
  "myTextFile": { "text": "This is the content of the text file." }
}
```

--------------------------------

### Generate Image using Workers (TypeScript)

Source: https://developers.cloudflare.com/workers/-ai/models/stable-diffusion-xl-lightning

Example of how to use the SDXL-Lightning model for text-to-image generation within a Cloudflare Worker using TypeScript. This snippet demonstrates making a POST request to the model's API endpoint with necessary parameters.

```typescript
import { Ai } from "@cloudflare/ai";

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const ai = new Ai(env.AI);
    const image = await ai.run("@cf/bytedance/stable-diffusion-xl-lightning", {
      prompt: "A majestic cat wearing a crown, digital art",
      negative_prompt: "blurry, low quality, distorted",
      height: 1024,
      width: 1024,
      num_steps: 20,
      guidance: 7.5,
      seed: 12345
    });
    return new Response(image, {
      headers: {
        "content-type": "image/jpeg",
      },
    });
  },
};

interface Env {
  AI: any;
}
```

--------------------------------

### List Fine-tunes using Cloudflare REST API

Source: https://developers.cloudflare.com/workers/-ai/fine-tunes/loras

A command to list all fine-tunes created in your Cloudflare account using the REST API. Requires 'Workers AI Write' or 'Workers AI Read' permissions.

```bash
curl -X GET "https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/v1/finetunes" \
     -H "Authorization: Bearer {API_TOKEN}"
```

--------------------------------

### Create and Upload LoRA Adapters via Wrangler

Source: https://developers.cloudflare.com/workers/-ai/features/fine-tunes/loras

Commands to create a new fine-tune and upload LoRA adapter files using the Wrangler CLI tool. Ensure you have the `adapter_model.safetensors` and `adapter_config.json` files ready.

```bash
wrangler finetune create <your-finetune-name>
wrangler finetune upload <your-finetune-name> --file=./adapter_model.safetensors
wrangler finetune upload <your-finetune-name> --file=./adapter_config.json
```

--------------------------------

### Translate Text using Workers - TypeScript

Source: https://developers.cloudflare.com/workers/-ai/models/m2m100-1

Example of how to perform text translation using the m2m100-1.2b model within a Cloudflare Worker written in TypeScript. It shows how to structure the request body for single or batched translations.

```typescript
import { text } from "stream/consumers";

// Example for single translation
const result = await cf.run({
  model: "@cf/meta/m2m100-1.2b",
  data: {
    text: "Hello, world!",
    source_lang: "en",
    target_lang: "es"
  }
});

// Example for batch translation
const batchResult = await cf.run({
  model: "@cf/meta/m2m100-1.2b",
  data: {
    requests: [
      {
        text: "Hello, world!",
        source_lang: "en",
        target_lang: "es"
      },
      {
        text: "How are you?",
        source_lang: "en",
        target_lang: "fr"
      }
    ]
  }
});

console.log(result.translated_text);
console.log(batchResult);
```

--------------------------------

### List All Pywrangler Commands

Source: https://developers.cloudflare.com/workers/languages/python/packages

This command displays all available commands supported by the Pywrangler CLI, including those inherited from the underlying wrangler tool. This is useful for exploring Pywrangler's full functionality.

```bash
uv run pywrangler --help

```

--------------------------------

### Configuring Browser Rendering Remote Binding in wrangler.jsonc

Source: https://developers.cloudflare.com/workers/development-testing

Configure a remote binding for Browser Rendering in wrangler.jsonc. Since there's no local simulation for Browser Rendering, this setup ensures your Worker interacts with a real headless browser instance during local development.

```json
{
  "compatibilityDate": "2023-09-01",
  "browser_rendering": {
    "binding": "BROWSER",
    "remote": true
  }
}
```

--------------------------------

### Text Generation Parameters

Source: https://developers.cloudflare.com/workers/-ai/models/falcon-7b-instruct

This section describes parameters that control the text generation behavior of the model, including penalties for repetition and the introduction of new topics.

```APIDOC
## Text Generation Parameters

### Description
These parameters influence the model's output by adjusting the likelihood of repeating content or introducing new subjects.

### Parameters
#### `frequency_penalty`
- **frequency_penalty** (number) - min -2 max 2 - Decreases the likelihood of the model repeating the same lines verbatim.

#### `presence_penalty`
- **presence_penalty** (number) - min -2 max 2 - Increases the likelihood of the model introducing new topics.

### Request Body Example
```json
{
  "prompt": "Write a poem about the sea.",
  "frequency_penalty": 0.5,
  "presence_penalty": 0.2
}
```

### Response Example (Success)
```json
{
  "response": "The ocean whispers secrets deep,
Where ancient mariners did sleep.
Waves crash upon the sandy shore,
Forever calling, evermore.",
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 25,
    "total_tokens": 35
  },
  "tool_calls": []
}
```
```